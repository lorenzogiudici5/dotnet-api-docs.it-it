<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="ns-System.Speech.Recognition.xml" source-language="en-US" target-language="it-IT">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-efd8310" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5a83ea4b-dd12-480b-bfc8-267272ef1864be08311c812e33ac449fae40c2d2494af9dc7fe5.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">be08311c812e33ac449fae40c2d2494af9dc7fe5</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">df6cf590aa3087f6c7c202712eee781c6a3c8f96</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/10/2018</xliffext:ms.lasthandoff>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> namespace contains Windows Desktop Speech technology types for implementing speech recognition.</source>
          <target state="translated">Lo spazio dei nomi <ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> contiene i tipi della tecnologia Windows Desktop Speech per l'implementazione del riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.</source>
          <target state="translated">Il software di Windows Desktop vocale tecnologia offre un'infrastruttura di riconoscimento vocale base che digitalizza segnali acustici e il recupera delle parole e gli elementi di riconoscimento vocale dall'input audio.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications use the <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.</source>
          <target state="translated">Le applicazioni utilizzano il <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> dello spazio dei nomi per accedere ed estendere questa tecnologia di riconoscimento vocale base definendo gli algoritmi per l'identificazione e agisce ai modelli di word o frasi specifiche e gestendo il comportamento di questo discorso runtime infrastruttura.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Create Grammars<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Creare le grammatiche<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input.</source>
          <target state="translated">Creare le grammatiche, costituiti da un set di regole o i vincoli, per definire le parole e frasi che riconosce l'applicazione come input significativo.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using a constructor for the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class, you can create a grammar object at runtime from <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> or <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instances, or from a file, a string, or a stream that contains a definition of a grammar.</source>
          <target state="translated">Utilizzo di un costruttore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> (classe), è possibile creare un oggetto grammatica in fase di esecuzione da <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> o <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> istanze, o da un file, una stringa o un flusso che contiene la definizione di una grammatica.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios.</source>
          <target state="translated">Utilizzo di <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classi, è possibile creare a livello di codice le grammatiche scarsa complessità Media che può essere utilizzato per eseguire il riconoscimento per molti scenari comuni.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>To create grammars programmatically that conform to the <bpt id="p1">[</bpt>Speech Recognition Grammar Specification 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> and take advantage of the authoring flexibility of SRGS, use the types of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> namespace.</source>
          <target state="translated">Per creare le grammatiche conforme al livello di codice che il <bpt id="p1">[</bpt>grammatica specifica 1.0 (SRGS) di riconoscimento vocale<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> e sfruttare la flessibilità di creazione e modifica di SRGS, utilizzare i tipi del <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> dello spazio dei nomi.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can also create XML-format SRGS grammars using any text editor and use the result to create <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , or <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">È possibile creare le grammatiche SRGS formato XML utilizzando il testo dell'editor e il risultato viene utilizzato per creare <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , o <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>In addition, the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> class provides a special-case grammar to support a conventional dictation model.</source>
          <target state="translated">Inoltre, la <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> classe fornisce una grammatica speciale per supportare un modello di dettatura convenzionale.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Create Grammars<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.</source>
          <target state="translated">Vedere <bpt id="p1">[</bpt>creare grammatiche<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> nel <bpt id="p2">[</bpt>sistema vocale Guida alla programmazione per .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> per ulteriori informazioni ed esempi.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Manage Speech Recognition Engines<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Gestire i moduli di riconoscimento vocale<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instances of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> supplied with <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.</source>
          <target state="translated">Le istanze di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> fornito con <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti forniscono l'accesso primario per i riconoscimento vocale della tecnologia di riconoscimento vocale Desktop di Windows.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the <bpt id="p1">**</bpt>Control Panel<ept id="p1">**</ept>.</source>
          <target state="translated">È possibile utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> classe per creare applicazioni client che utilizzano la tecnologia di riconoscimento vocale fornita da Windows, è possibile configurare tramite il <bpt id="p1">**</bpt>Pannello di controllo<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>Such applications accept input through a computer's default audio input mechanism.</source>
          <target state="translated">Tali applicazioni accettano l'input tramite meccanismo di input audio predefinito del computer.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more control over the configuration and type of recognition engine, build an application using <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, which runs in-process.</source>
          <target state="translated">Per un maggiore controllo sulla configurazione e tipo di motore di riconoscimento, creare un'applicazione utilizzando <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, che viene eseguito in-process.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class, you can also dynamically select audio input from devices, files, or streams.</source>
          <target state="translated">Utilizzo di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> (classe), è possibile selezionare anche in modo dinamico da dispositivi, file o flussi di input audio.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Initialize and Manage a Speech Recognition Engine<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">Vedere <bpt id="p1">[</bpt>inizializzare e gestire un motore di riconoscimento vocale<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> nel <bpt id="p2">[</bpt>sistema vocale Guida alla programmazione per .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> per ulteriori informazioni.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Respond to Events<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Rispondere agli eventi<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objects generate events in response to audio input to the speech recognition engine.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> oggetti generano eventi in risposta a input audio per il motore di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> events are raised in response to changes in the incoming signal.</source>
          <target state="translated">Il <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> gli eventi vengono generati in risposta alle modifiche nel segnale in ingresso.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`SpeechDetected`</ph> event is raised when the speech recognition engine identifies incoming audio as speech.</source>
          <target state="translated">Il <ph id="ph1">`SpeechDetected`</ph> evento viene generato quando il motore di riconoscimento vocale identifica audio in ingresso come riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognition engine raises the <ph id="ph1">`SpeechRecognized`</ph> event when it matches speech input to one of its loaded grammars, and raises the <ph id="ph2">`SpeechRecognitionRejected`</ph> when speech input does not match any of its loaded grammars.</source>
          <target state="translated">Il motore di riconoscimento vocale genera il <ph id="ph1">`SpeechRecognized`</ph> evento quando corrisponde a uno dei relativi grammatiche caricate l'input vocale e genera il <ph id="ph2">`SpeechRecognitionRejected`</ph> quando l'input vocale corrisponde a nessuno dei relativi grammatiche caricate.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>Other types of events include the <ph id="ph1">`LoadGrammarCompleted`</ph> event which a speech recognition engine raises when it has loaded a grammar.</source>
          <target state="translated">Includono altri tipi di eventi di <ph id="ph1">`LoadGrammarCompleted`</ph> eventi che un riconoscimento vocale genera quando è caricata una grammatica.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> is exclusive to the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class, which raises the event when the state of Windows Speech Recognition changes.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> è esclusivo per il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> (classe), che genera l'evento quando cambia lo stato di riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can register to be notified for events that the speech recognition engine raises and create handlers using the <ph id="ph1">`EventsArgs`</ph> classes associated with each of these events to program your application's behavior when an event is raised.</source>
          <target state="translated">È possibile registrarsi per ricevere una notifica per eventi che genera il riconoscimento vocale e creare gestori eventi utilizzando il <ph id="ph1">`EventsArgs`</ph> classi associate a ciascuno di questi eventi per programmare un comportamento dell'applicazione quando viene generato un evento.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">Vedere <bpt id="p1">[</bpt>mediante gli eventi di riconoscimento vocale<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> nel <bpt id="p2">[</bpt>sistema vocale Guida alla programmazione per .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> per ulteriori informazioni.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>