<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechRecognitionEngine.xml" source-language="en-US" target-language="it-IT">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac564d271fac7ee774099403cbb7bec467f30d51b3f.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">64d271fac7ee774099403cbb7bec467f30d51b3f</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Provides the means to access and manage an in-process speech recognition engine.</source>
          <target state="translated">Fornisce i mezzi per accedere e gestire un motore di riconoscimento vocale in-process.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>You can create an instance of this class for any of the installed speech recognizers.</source>
          <target state="translated">È possibile creare un'istanza di questa classe per uno qualsiasi del riconoscimento vocale installata.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To get information about which recognizers are installed, use the static <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method.</source>
          <target state="translated">Per ottenere informazioni sui tipi di riconoscimento vengono installati, usare il metodo statico <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This class is for running speech recognition engines in-process, and provides control over various aspects of speech recognition, as follows:</source>
          <target state="translated">Questa classe è per l'esecuzione di comandi vocali riconoscimento motori in-process e consente di controllare vari aspetti del riconoscimento vocale, come indicato di seguito:</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To create an in-process speech recognizer, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt;</ph> constructors.</source>
          <target state="translated">Per creare un riconoscimento vocale in-process, utilizzare uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt;</ph> costruttori.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To manage speech recognition grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;</ph> methods, and the <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">Per gestire le grammatiche riconoscimento vocale, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;</ph> metodi e <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To configure the input to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;</ph>, or <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</ph> method.</source>
          <target state="translated">Per configurare l'input per il riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;</ph>, o <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To perform speech recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per eseguire il riconoscimento vocale, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To modify how recognition handles silence or unexpected input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Per modificare la modalità di gestione di input imprevisto o inattività riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To change the number of alternates the recognizer returns, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</ph> property.</source>
          <target state="translated">Per modificare il numero di alternative restituisce il riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer returns recognition results in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Il riconoscimento restituisce i risultati del riconoscimento in un <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To synchronize changes to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per sincronizzare le modifiche al sistema di riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">Il riconoscimento utilizza più di un thread per eseguire attività.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To emulate input to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Per emulare l'input per il riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object is for the sole use of the process that instantiated the object.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> oggetto è l'unico Usa del processo di cui creare un'istanza dell'oggetto.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> shares a single recognizer with any application that wants to use it.</source>
          <target state="translated">Al contrario, il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> condivide un singolo sistema di riconoscimento con qualsiasi applicazione che si desidera utilizzarlo.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Always call <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt;</ph> before you release your last reference to the speech recognizer.</source>
          <target state="translated">Chiamare sempre il metodo <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt;</ph> prima di rilasciare l'ultimo riferimento a riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">In caso contrario, le risorse utilizzate non vengono liberate finché il garbage collector chiama l'oggetto di riconoscimento <ph id="ph1">`Finalize`</ph> metodo.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Because this example uses the <ph id="ph1">`Multiple`</ph> mode of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> method, it performs recognition until you close the console window or stop debugging.</source>
          <target state="translated">Poiché questo esempio viene utilizzato il <ph id="ph1">`Multiple`</ph> modalità del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> (metodo), esegue il riconoscimento fino a quando non si chiude la finestra della console o interrompere il debug.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> class.</source>
          <target state="translated">Inizializza una nuova istanza della classe <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>You can construct a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance from any of the following:</source>
          <target state="translated">È possibile costruire un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> istanza da uno qualsiasi dei seguenti:</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default speech recognition engine for the system</source>
          <target state="translated">Il motore di riconoscimento vocale predefinito per il sistema</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A specific speech recognition engine that you specify by name</source>
          <target state="translated">Un motore di riconoscimento vocale specifico che si specifica il nome</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default speech recognition engine for a locale that you specify</source>
          <target state="translated">Il motore di riconoscimento vocale predefinito per impostazioni locali specificate</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A specific recognition engine that meets the criteria that you specify in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> object.</source>
          <target state="translated">Un motore di riconoscimento specifico che soddisfa i criteri specificati in un <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Prima di iniziarne il riconoscimento vocale ha il riconoscimento, è necessario caricare la grammatica di riconoscimento almeno vocale e configurare l'input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica, chiamare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Per configurare l'input audio, usare uno dei metodi seguenti:</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> class using the default speech recognizer for the system.</source>
          <target state="translated">Inizializza una nuova istanza della classe <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> utilizzando il riconoscimento vocale predefinito per il sistema.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor">
          <source>Before the speech recognizer can begin speech recognition, you must load at least one recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Prima di iniziarne il riconoscimento vocale ha il riconoscimento vocale, è necessario caricare almeno una grammatica di riconoscimento e configurare l'input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica, chiamare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Per configurare l'input audio, usare uno dei metodi seguenti:</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>The locale that the speech recognizer must support.</source>
          <target state="translated">Le impostazioni locali che il riconoscimento vocale deve supportare.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> class using the default speech recognizer for a specified locale.</source>
          <target state="translated">Inizializza una nuova istanza della classe <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> utilizzando il riconoscimento vocale predefinito per le impostazioni locali specificate.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Microsoft Windows and the System.Speech API accept all valid language-country codes.</source>
          <target state="translated">Microsoft Windows e l'API Speech accettare tutti i codici paese di lingua validi.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>To perform speech recognition using the language specified in the <ph id="ph1">`CultureInfo`</ph> argument, a speech recognition engine that supports that language-country code must be installed.</source>
          <target state="translated">Per eseguire il riconoscimento vocale utilizzando la lingua specificata nel <ph id="ph1">`CultureInfo`</ph> argomento, un motore di riconoscimento vocale che supporta che deve essere installato il codice paese di linguaggio.</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>The speech recognition engines that shipped with Microsoft Windows 7 work with the following language-country codes.</source>
          <target state="translated">I riconoscimento vocale fornita con Microsoft Windows 7 funzionano con i seguenti codici di lingua, paese.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>en-GB.</source>
          <target state="translated">en-GB.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>English (United Kingdom)</source>
          <target state="translated">Inglese (Regno Unito)</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>en-US.</source>
          <target state="translated">en-US.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>English (United States)</source>
          <target state="translated">Inglese (Stati Uniti)</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>de-DE.</source>
          <target state="translated">de-DE.</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>German (Germany)</source>
          <target state="translated">Tedesco (Germania)</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>es-ES.</source>
          <target state="translated">es-ES.</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Spanish (Spain)</source>
          <target state="translated">Spagnolo (Spagna)</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>fr-FR.</source>
          <target state="translated">fr-FR.</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>French (France)</source>
          <target state="translated">Francese (Francia)</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>ja-JP.</source>
          <target state="translated">ja-JP.</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Japanese (Japan)</source>
          <target state="translated">Giapponese (Giappone)</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>zh-CN.</source>
          <target state="translated">zh-CN.</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Chinese (China)</source>
          <target state="translated">Cinese (Cina)</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>zh-TW.</source>
          <target state="translated">zh-TW.</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Chinese (Taiwan)</source>
          <target state="translated">Cinese (Taiwan)</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Two-letter language codes such as "en", "fr", or "es" are also permitted.</source>
          <target state="translated">Codici di lingua di due lettere, ad esempio "en", "fr", o "es" sono inoltre consentiti.</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Prima di iniziarne il riconoscimento vocale ha il riconoscimento, è necessario caricare la grammatica di riconoscimento almeno vocale e configurare l'input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica, chiamare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Per configurare l'input audio, usare uno dei metodi seguenti:</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer for the en-US locale.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base e Inizializza un riconoscimento vocale per le impostazioni locali en-US.</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source>None of the installed speech recognizers support the specified locale, or <ph id="ph1">&lt;paramref name="culture" /&gt;</ph> is the invariant culture.</source>
          <target state="translated">Nessuno dei sistemi di riconoscimento di input vocali installato supporta le impostazioni locali specificate oppure il parametro <ph id="ph1">&lt;paramref name="culture" /&gt;</ph> è la lingua inglese.</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)">
          <source><ph id="ph1">&lt;paramref name="Culture" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Culture" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>The information for the specific speech recognizer.</source>
          <target state="translated">Le informazioni per il riconoscimento vocale specifico.</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> using the information in a <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.RecognizerInfo" /&gt;</ph> object to specify the recognizer to use.</source>
          <target state="translated">Inizializza una nuova istanza dell'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>  utilizzando le informazioni disponibili in un oggetto <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.RecognizerInfo" /&gt;</ph> per specificare il riconoscimento da utilizzare.</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>You can create an instance of this class for any of the installed speech recognizers.</source>
          <target state="translated">È possibile creare un'istanza di questa classe per uno qualsiasi del riconoscimento vocale installata.</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>To get information about which recognizers are installed, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method.</source>
          <target state="translated">Per ottenere informazioni sui tipi di riconoscimento vengono installati, usare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Prima di iniziarne il riconoscimento vocale ha il riconoscimento, è necessario caricare la grammatica di riconoscimento almeno vocale e configurare l'input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica, chiamare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Per configurare l'input audio, usare uno dei metodi seguenti:</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer that supports the English language.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base e Inizializza un riconoscimento vocale che supporta la lingua inglese.</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>The token name of the speech recognizer to use.</source>
          <target state="translated">Il nome del token del riconoscimento vocale da utilizzare.</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> class with a string parameter that specifies the name of the recognizer to use.</source>
          <target state="translated">Inizializza una nuova istanza della classe <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> con una parametro di stringa che specifica il nome del riconoscimento da utilizzare.</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>The token name of the recognizer is the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> object returned by the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</ph> property of the recognizer.</source>
          <target state="translated">Il nome del token di riconoscimento è il valore della <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt;</ph> proprietà del <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> oggetto restituito dal <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</ph> proprietà di riconoscimento.</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>To get a collection of all the installed recognizers, use the static <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method.</source>
          <target state="translated">Per ottenere una raccolta di tutti i riconoscitori installati, usare il metodo statico <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Prima di iniziarne il riconoscimento vocale ha il riconoscimento, è necessario caricare la grammatica di riconoscimento almeno vocale e configurare l'input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>To load a grammar, call the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica, chiamare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Per configurare l'input audio, usare uno dei metodi seguenti:</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition, and creates an instance of the Speech Recognizer 8.0 for Windows (English - US).</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base e crea un'istanza di 8.0 di riconoscimento vocale per Windows (in lingua inglese - Stati Uniti).</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source>No speech recognizer with that token name is installed, or <ph id="ph1">&lt;paramref name="recognizerId" /&gt;</ph> is the empty string ("").</source>
          <target state="translated">Non è installato alcun riconoscimento di input vocale con quel nome di token oppure il parametro <ph id="ph1">&lt;paramref name="recognizerId" /&gt;</ph> è la stringa vuota ("").</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)">
          <source><ph id="ph1">&lt;paramref name="recognizerId" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="recognizerId" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat">
          <source>Gets the format of the audio being received by the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Ottiene il formato dell'audio ricevuto da <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat">
          <source>The format of audio at the input to the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> instance, or <ph id="ph2">&lt;see langword="null" /&gt;</ph> if the input is not configured or set to the null input.</source>
          <target state="translated">Il formato audio dell'input all'istanza di <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> o <ph id="ph2">&lt;see langword="null" /&gt;</ph> se l'input non è configurato o non impostato su input null.</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat">
          <source>To configure the audio input, use one of the following methods:</source>
          <target state="translated">Per configurare l'input audio, usare uno dei metodi seguenti:</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat">
          <source>The example below uses <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat%2A&gt;</ph> to obtain and display audio format data.</source>
          <target state="translated">Nell'esempio seguente viene utilizzato <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat%2A&gt;</ph> per ottenere e visualizzare i dati in formato audio.</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel">
          <source>Gets the level of the audio being received by the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Ottiene il livello dell'audio ricevuto da <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">Livello audio dell'input del riconoscimento vocale, da 0 a 100.</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel">
          <source>The value 0 represents silence, and 100 represents the maximum input volume.</source>
          <target state="translated">Il valore 0 rappresenta inattività 100 rappresenta il volume di input massimo.</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> reports the level of its audio input.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> segnala il livello del relativo input audio.</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises this event multiple times per second.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> genera questo evento più volte al secondo.</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">La frequenza con cui l'evento viene generato varia a seconda del computer in cui è in esecuzione l'applicazione.</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>To get the audio level at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere il livello audio al momento dell'evento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</ph> property.</source>
          <target state="translated">Per ottenere il livello corrente audio di input per il riconoscimento, usare il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>When you create an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated&gt;</ph>, si identifica il metodo con cui gestire l'evento.</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The following example adds a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated&gt;</ph> event to a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object.</source>
          <target state="translated">Nell'esempio seguente aggiunge un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated&gt;</ph> evento da un <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated">
          <source>The handler outputs the new audio level to the console.</source>
          <target state="translated">Il gestore restituisce il nuovo livello audio nella console.</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Ottiene la posizione corrente nel flusso audio generato dal dispositivo che fornisce l'input a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>The current location in the audio stream being generated by the input device.</source>
          <target state="translated">La posizione corrente nel flusso audio generato dal dispositivo di input.</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> proprietà fa riferimento la posizione del dispositivo di input nel proprio flusso audio generato.</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position within its audio input.</source>
          <target state="translated">Al contrario, il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> proprietà fa riferimento la posizione del riconoscimento all'interno di input audio.</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Queste posizioni possono essere diverse.</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Ad esempio, se ha ricevuto il riconoscimento di input per i quali non ha ancora generato un risultato di riconoscimento, il valore del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> proprietà è minore del valore del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>In the following example, the in-process speech recognizer uses a dictation grammar to match speech input.</source>
          <target state="translated">Nell'esempio seguente, il riconoscimento vocale in-process Usa una grammatica dettatura per associare input vocale.</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> event writes to the console the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph>, and  <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</ph> when the speech recognizer detects speech at its input.</source>
          <target state="translated">Un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> evento scrive nella console di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</ph> quando il riconoscimento vocale ha rilevato vocale relativi input.</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> detects a problem in the audio signal.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> rileva un problema nel segnale audio.</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>To get which problem occurred, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere si è verificato il problema, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>When you create an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred&gt;</ph>, si identifica il metodo con cui gestire l'evento.</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred">
          <source>The following example defines an event handler that gathers information about an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred&gt;</ph> event.</source>
          <target state="translated">L'esempio seguente definisce un gestore eventi che raccoglie informazioni su un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState">
          <source>Gets the state of the audio being received by the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Ottiene lo stato dell'audio ricevuto da <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">Lo stato dell'input audio per il riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> property represents the audio state with a member of the <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> proprietà rappresenta lo stato audio con un membro con il <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>Raised when the state changes in the audio being received by the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Generato in seguito alla modifica dello stato nell'audio ricevuto da <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>To get the audio state at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere lo stato audio al momento dell'evento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> property.</source>
          <target state="translated">Per ottenere lo stato corrente di audio di input per il riconoscimento, usare il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>For more information about audio state, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sullo stato audio, vedere il <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>When you create an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph>, si identifica il metodo con cui gestire l'evento.</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged">
          <source>The following example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> event to write the recognizer's new <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> to the console each time it changes, using a member of the <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Nell'esempio seguente viene utilizzato un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> evento da scrivere il riconoscimento del nuovo <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</ph> nella console ogni volta che le modifiche, l'utilizzo di un membro del <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>Gets or sets the time interval during which a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> accepts input containing only background noise, before finalizing recognition.</source>
          <target state="translated">Ottiene o imposta l'intervallo di tempo durante il quale <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> accetta input contenente solo il rumore di fondo, prima di completare il riconoscimento.</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The duration of the time interval.</source>
          <target state="translated">La durata dell'intervallo di tempo.</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Ogni riconoscimento vocale è disponibile un algoritmo per distinguere tra vocale e di inattività.</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The recognizer classifies as background noise any non-silence input that does not match the initial rule of any of the recognizer's loaded and enabled speech recognition grammars.</source>
          <target state="translated">Il riconoscimento classifica come qualsiasi inattività-non di input che non corrispondono alla regola iniziale di uno qualsiasi del riconoscimento del rumore caricati e abilitato le grammatiche riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>If the recognizer receives only background noise and silence within the babble timeout interval, then the recognizer finalizes that recognition operation.</source>
          <target state="translated">Se il riconoscimento riceve solo rumore di fondo e inattività entro l'intervallo di timeout babble, il riconoscimento completa l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>For asynchronous recognition operations, the recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, where the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=nameWithType&gt;</ph> property is <ph id="ph3">`true`</ph>, and the <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType&gt;</ph> property is <ph id="ph5">`null`</ph>.</source>
          <target state="translated">Per le operazioni di riconoscimento asincrona, genera il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento, in cui il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=nameWithType&gt;</ph> proprietà <ph id="ph3">`true`</ph>e il <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType&gt;</ph> proprietà è <ph id="ph5">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>For synchronous recognition operations and emulation, the recognizer returns <ph id="ph1">`null`</ph>, instead of a valid <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</source>
          <target state="translated">Per le operazioni di riconoscimento sincrono e l'emulazione, restituisce il riconoscimento <ph id="ph1">`null`</ph>, anziché un valore valido <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>If the babble timeout period is set to 0, the recognizer does not perform a babble timeout check.</source>
          <target state="translated">Se il periodo di timeout babble è impostato su 0, il riconoscimento non in grado di eseguire un controllo di timeout babble.</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The timeout interval can be any non-negative value.</source>
          <target state="translated">L'intervallo di timeout può essere qualsiasi valore non negativo.</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The default is 0 seconds.</source>
          <target state="translated">Il valore predefinito è 0 secondi.</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>The following example shows part of a console application that demonstrates basic speech recognition that sets the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties of a <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> before initiating speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base che imposta il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> le proprietà di un <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> prima di avviare il riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>Handlers for the speech recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> events output event information to the console to demonstrate how the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties of a <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> affect recognition operations.</source>
          <target state="translated">Gestori per il riconoscimento vocale <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> gli eventi di output delle informazioni di evento nella console per dimostrare come <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> le proprietà di un <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> influiscono sulle operazioni di riconoscimento.</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout">
          <source>This property is set to less than 0 seconds.</source>
          <target state="translated">Questa proprietà è impostata su un valore minore di 0 secondi.</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object.</source>
          <target state="translated">Elimina l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Dispose">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object.</source>
          <target state="translated">Elimina l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> to release both managed and unmanaged resources; <ph id="ph2">&lt;see langword="false" /&gt;</ph> to release only unmanaged resources.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> per rilasciare sia le risorse gestite sia quelle non gestite; <ph id="ph2">&lt;see langword="false" /&gt;</ph> per rilasciare solo le risorse non gestite.</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object and releases resources used during the session.</source>
          <target state="translated">Elimina l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> e rilascia le risorse usate durante la sessione.</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Emulates input to the speech recognizer, using text in place of audio for synchronous speech recognition.</source>
          <target state="translated">Emula l'input al riconoscimento vocale, utilizzando il testo anziché l'audio per il riconoscimento vocale sincrono.</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>These methods bypass the system audio input and provide text to the recognizer as <ph id="ph1">&lt;xref:System.String&gt;</ph> objects or as an array of <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> objects.</source>
          <target state="translated">Questi metodi di ignorare l'input audio di sistema e fornire il testo per il riconoscimento come <ph id="ph1">&lt;xref:System.String&gt;</ph> oggetti o come una matrice di <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Può essere utile quando si desidera testare o il debug di un'applicazione o grammatica.</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>For example, you can use emulation to determine whether a word is in a grammar and what semantics are returned when the word is recognized.</source>
          <target state="translated">Ad esempio, è possibile utilizzare l'emulazione per determinare se una parola in una grammatica e quali semantica viene restituita quando la parola viene riconosciuta.</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph> method to disable audio input to the speech recognition engine during emulation operations.</source>
          <target state="translated">Utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph> per disattivare l'input audio per il motore di riconoscimento vocale durante le operazioni di emulazione.</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Il controllo di riconoscimento vocale genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento delle nuove righe e gli spazi vuoti aggiuntivi vengono ignorati e considera i segni di punteggiatura come valore letterale input.</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the speech recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto generato dal riconoscimento vocale in risposta all'input emulata ha un valore di <ph id="ph2">`null`</ph> per relativo <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To emulate asynchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per emulare un riconoscimento asincrono, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition.</source>
          <target state="translated">Emula l'input di una frase al riconoscimento vocale, utilizzando il testo anziché l'audio per il riconoscimento vocale sincrono.</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Il risultato dell'operazione di riconoscimento o <ph id="ph1">&lt;see langword="null" /&gt;</ph> se l'operazione non riesce o il riconoscimento non è abilitato.</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Il controllo di riconoscimento vocale genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole e caratteri di larghezza quando l'applicazione delle regole di sintassi per la frase di input.</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Per ulteriori informazioni su questo tipo di confronto, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> valori di enumerazione <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> e <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche Ignora le nuove righe e lo spazio vuoto aggiuntivo e considera la punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The code example below is part of a console application that demonstrates emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Esempio di codice seguente fa parte di un'applicazione console in cui viene emulato input, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The example generates the following output.</source>
          <target state="translated">L'esempio genera l'output seguente.</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Nel riconoscimento non sono caricate grammatiche di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> è la stringa vuota ("").</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Matrice di unità di parole che contiene l'input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinazione bit per bit dei valori di enumerazione che descrivono il tipo di confronto da utilizzare per l'operazione di riconoscimento emulato.</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emula l'input di parole specifiche al riconoscimento vocale, utilizzando il testo anziché l'audio per il riconoscimento vocale sincrono, e specifica come il riconoscimento gestisce il confronto Unicode tra le parole e le grammatiche di riconoscimento vocale caricate.</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Il risultato dell'operazione di riconoscimento o <ph id="ph1">&lt;see langword="null" /&gt;</ph> se l'operazione non riesce o il riconoscimento non è abilitato.</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Il controllo di riconoscimento vocale genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Il riconoscimento utilizza <ph id="ph1">`compareOptions`</ph> quando si applica regole grammaticali per la frase di input.</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole se il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> o <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valore è presente.</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer always ignores the character width and never ignores the Kana type.</source>
          <target state="translated">Il riconoscimento Ignora sempre la larghezza del carattere e mai Ignora Katakana / Hiragana.</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento inoltre nuove righe e gli spazi vuoti aggiuntivi vengono ignorati e considera i segni di punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sulla larghezza del carattere e il tipo Kana, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Nel riconoscimento non sono caricate grammatiche di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> contains one or more <ph id="ph2">&lt;see langword="null" /&gt;</ph> elements.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> contiene uno o più elementi <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contains the <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, or <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contiene il flag <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph> o <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Frase di Input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinazione bit per bit dei valori di enumerazione che descrivono il tipo di confronto da utilizzare per l'operazione di riconoscimento emulato.</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emula l'input di una frase al riconoscimento vocale, utilizzando il testo anziché l'audio per il riconoscimento vocale sincrono, e specifica come il riconoscimento gestisce il confronto Unicode tra la frase e le grammatiche di riconoscimento vocale caricate.</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Il risultato dell'operazione di riconoscimento o <ph id="ph1">&lt;see langword="null" /&gt;</ph> se l'operazione non riesce o il riconoscimento non è abilitato.</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Il controllo di riconoscimento vocale genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Il riconoscimento utilizza <ph id="ph1">`compareOptions`</ph> quando si applica regole grammaticali per la frase di input.</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole se il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> o <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valore è presente.</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer always ignores the character width and never ignores the Kana type.</source>
          <target state="translated">Il riconoscimento Ignora sempre la larghezza del carattere e mai Ignora Katakana / Hiragana.</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento inoltre nuove righe e gli spazi vuoti aggiuntivi vengono ignorati e considera i segni di punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sulla larghezza del carattere e il tipo Kana, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Nel riconoscimento non sono caricate grammatiche di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> è la stringa vuota ("").</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contains the <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, or <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contiene il flag <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph> o <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Emulates input to the speech recognizer, using text in place of audio for asynchronous speech recognition.</source>
          <target state="translated">Emula l'input al riconoscimento vocale, utilizzando il testo anziché l'audio per il riconoscimento vocale asincrono.</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>These methods bypass the system audio input and provide text to the recognizer as <ph id="ph1">&lt;xref:System.String&gt;</ph> objects or as an array of <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> objects.</source>
          <target state="translated">Questi metodi di ignorare l'input audio di sistema e fornire il testo per il riconoscimento come <ph id="ph1">&lt;xref:System.String&gt;</ph> oggetti o come una matrice di <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Può essere utile quando si desidera testare o il debug di un'applicazione o grammatica.</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>For example, you can use emulation to determine whether a word is in a grammar and what semantics are returned when the word is recognized.</source>
          <target state="translated">Ad esempio, è possibile utilizzare l'emulazione per determinare se una parola in una grammatica e quali semantica viene restituita quando la parola viene riconosciuta.</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph> method to disable audio input to the speech recognition engine during emulation operations.</source>
          <target state="translated">Utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;</ph> per disattivare l'input audio per il motore di riconoscimento vocale durante le operazioni di emulazione.</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Il controllo di riconoscimento vocale genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Al termine dell'operazione di riconoscimento asincrono il riconoscimento, genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento delle nuove righe e gli spazi vuoti aggiuntivi vengono ignorati e considera i segni di punteggiatura come valore letterale input.</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the speech recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto generato dal riconoscimento vocale in risposta all'input emulata ha un valore di <ph id="ph2">`null`</ph> per relativo <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To emulate synchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> method.</source>
          <target state="translated">Per emulare un riconoscimento sincrono, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition.</source>
          <target state="translated">Emula l'input di una frase al riconoscimento vocale, utilizzando il testo anziché l'audio per il riconoscimento vocale asincrono.</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Il controllo di riconoscimento vocale genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Al termine dell'operazione di riconoscimento asincrono il riconoscimento, genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole e caratteri di larghezza quando l'applicazione delle regole di sintassi per la frase di input.</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Per ulteriori informazioni su questo tipo di confronto, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> valori di enumerazione <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> e <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche Ignora le nuove righe e lo spazio vuoto aggiuntivo e considera la punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The code example below is part of a console application that demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Esempio di codice seguente fa parte di un'applicazione console che illustra l'input emulata asincrona, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The example generates the following output.</source>
          <target state="translated">L'esempio genera l'output seguente.</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Nel riconoscimento non sono caricate grammatiche di riconoscimento vocale, oppure ci sono operazioni di riconoscimento asincrone non ancora complete.</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> è la stringa vuota ("").</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Matrice di unità di parole che contiene l'input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinazione bit per bit dei valori di enumerazione che descrivono il tipo di confronto da utilizzare per l'operazione di riconoscimento emulato.</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the speech recognizer, using an array of <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.RecognizedWordUnit" /&gt;</ph> objects in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emula l'input di parole specifiche al riconoscimento vocale, utilizzando una matrice di oggetti <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.RecognizedWordUnit" /&gt;</ph> anziché l'audio per il riconoscimento vocale asincrono, e specifica come il riconoscimento gestisce il confronto Unicode tra le parole e le grammatiche di riconoscimento vocale caricate.</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Il controllo di riconoscimento vocale genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Al termine dell'operazione di riconoscimento asincrono il riconoscimento, genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Il riconoscimento utilizza <ph id="ph1">`compareOptions`</ph> quando si applica regole grammaticali per la frase di input.</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole se il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> o <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valore è presente.</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Il riconoscimento Ignora sempre la larghezza del carattere e mai Ignora Katakana / Hiragana.</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche Ignora le nuove righe e lo spazio vuoto aggiuntivo e considera la punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sulla larghezza del carattere e il tipo Kana, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Nel riconoscimento non sono caricate grammatiche di riconoscimento vocale, oppure ci sono operazioni di riconoscimento asincrone non ancora complete.</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> contains one or more <ph id="ph2">&lt;see langword="null" /&gt;</ph> elements.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="wordUnits" /&gt;</ph> contiene uno o più elementi <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contains the <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, or <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contiene il flag <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph> o <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Frase di Input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinazione bit per bit dei valori di enumerazione che descrivono il tipo di confronto da utilizzare per l'operazione di riconoscimento emulato.</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emula l'input di una frase al riconoscimento vocale, utilizzando il testo anziché l'audio per il riconoscimento vocale asincrono, e specifica come il riconoscimento gestisce il confronto Unicode tra la frase e le grammatiche di riconoscimento vocale caricate.</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The speech recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Il controllo di riconoscimento vocale genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Al termine dell'operazione di riconoscimento asincrono il riconoscimento, genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Il riconoscimento utilizza <ph id="ph1">`compareOptions`</ph> quando si applica regole grammaticali per la frase di input.</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole se il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> o <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valore è presente.</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Il riconoscimento Ignora sempre la larghezza del carattere e mai Ignora Katakana / Hiragana.</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche Ignora le nuove righe e lo spazio vuoto aggiuntivo e considera la punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sulla larghezza del carattere e il tipo Kana, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Nel riconoscimento non sono caricate grammatiche di riconoscimento vocale, oppure ci sono operazioni di riconoscimento asincrone non ancora complete.</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="inputText" /&gt;</ph> è la stringa vuota ("").</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contains the <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph>, or <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="compareOptions" /&gt;</ph> contiene il flag <ph id="ph2">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" /&gt;</ph>, <ph id="ph3">&lt;see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" /&gt;</ph> o <ph id="ph4">&lt;see cref="F:System.Globalization.CompareOptions.StringSort" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> finalizes an asynchronous recognition operation of emulated input.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> completa un'operazione di riconoscimento asincrona di input emulato.</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> method begins an asynchronous recognition operation.</source>
          <target state="translated">Ogni <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metodo inizia un'operazione asincrona di riconoscimento.</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event when it finalizes the asynchronous operation.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> genera il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento quando completa l'operazione asincrona.</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> operation can raise the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> operazione può generare il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi.</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento è l'ultimo evento di questo tipo che il riconoscimento genera per l'operazione specificata.</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>If emulated recognition was successful, you can access the recognition result using the either of the following:</source>
          <target state="translated">Se il riconoscimento emulato ha avuto esito positivo, è possibile accedere al risultato del riconoscimento utilizzando uno dei seguenti:</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</ph> property in the <ph id="ph2">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ph> object in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</ph> proprietà il <ph id="ph2">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ph> oggetto nel gestore per il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property in the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ph> object in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> proprietà di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ph> oggetto nel gestore per il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>If emulated recognition was not successful, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event is not raised and the <ph id="ph2">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</ph> will be null.</source>
          <target state="translated">Se emulato riconoscimento non è stato completato la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> non viene generato e <ph id="ph2">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</ph> sarà null.</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ph> derives from <ph id="ph2">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ph> deriva da <ph id="ph2">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ph> derives from <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ph> deriva da <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>When you create an <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph>, si identifica il metodo con cui gestire l'evento.</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che viene caricata una grammatica di riconoscimento vocale e input emulata asincrona, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>Gets or sets the interval of silence that the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> will accept at the end of unambiguous input before finalizing a recognition operation.</source>
          <target state="translated">Ottiene o imposta l'intervallo di silenzio che <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> accetterà alla fine dell'input non ambiguo prima di completare un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>The duration of the interval of silence.</source>
          <target state="translated">La durata dell'intervallo di silenzio.</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>The speech recognizer uses this timeout interval when the recognition input is unambiguous.</source>
          <target state="translated">Il riconoscimento vocale utilizza questo intervallo di timeout quando l'input di riconoscimento non è ambiguo.</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Ad esempio, per una grammatica di riconoscimento vocale che supporta il riconoscimento di uno "nuovo gioco." o "nuova partita", "nuovo gioco." è un input non ambiguo, e "nuova partita" è un input ambiguo.</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</source>
          <target state="translated">Questa proprietà determina il tempo di attesa di riconoscimento vocale per l'input aggiuntivi prima di completare un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>The timeout interval can be from 0 seconds to 10 seconds, inclusive.</source>
          <target state="translated">L'intervallo di timeout può essere da 0 a 10 secondi.</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>The default is 150 milliseconds.</source>
          <target state="translated">Il valore predefinito è 150 millisecondi.</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>To set the timeout interval for ambiguous input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> property.</source>
          <target state="translated">Per impostare l'intervallo di timeout per l'input ambiguo, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout">
          <source>This property is set to less than 0 seconds or greater than 10 seconds.</source>
          <target state="translated">Questa proprietà è impostata su un valore inferiore a 0 secondi o maggiore di 10 secondi.</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>Gets or sets the interval of silence that the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> will accept at the end of ambiguous input before finalizing a recognition operation.</source>
          <target state="translated">Ottiene o imposta l'intervallo di silenzio che <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> accetterà alla fine dell'input ambiguo prima di completare un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>The duration of the interval of silence.</source>
          <target state="translated">La durata dell'intervallo di silenzio.</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>The speech recognizer uses this timeout interval when the recognition input is ambiguous.</source>
          <target state="translated">Il riconoscimento vocale utilizza questo intervallo di timeout quando l'input di riconoscimento è ambiguo.</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Ad esempio, per una grammatica di riconoscimento vocale che supporta il riconoscimento di uno "nuovo gioco." o "nuova partita", "nuovo gioco." è un input non ambiguo, e "nuova partita" è un input ambiguo.</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</source>
          <target state="translated">Questa proprietà determina il tempo di attesa di riconoscimento vocale per l'input aggiuntivi prima di completare un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>The timeout interval can be from 0 seconds to 10 seconds, inclusive.</source>
          <target state="translated">L'intervallo di timeout può essere da 0 a 10 secondi.</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>The default is 500 milliseconds.</source>
          <target state="translated">Il valore predefinito è 500 millisecondi.</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>To set the timeout interval for unambiguous input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> property.</source>
          <target state="translated">Per impostare l'intervallo di timeout per l'input non ambiguo, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous">
          <source>This property is set to less than 0 seconds or greater than 10 seconds.</source>
          <target state="translated">Questa proprietà è impostata su un valore inferiore a 0 secondi o maggiore di 10 secondi.</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars">
          <source>Gets a collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that are loaded in this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> instance.</source>
          <target state="translated">Ottiene una raccolta di oggetti <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> caricati in questa istanza di <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars">
          <source>The collection of <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects.</source>
          <target state="translated">Raccolta di oggetti <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars">
          <source>The following example outputs information to the console for each speech recognition grammar that is currently loaded by a speech recognizer.</source>
          <target state="translated">Nell'esempio seguente genera informazioni nella console per ogni grammatica di riconoscimento vocale attualmente caricata da un riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars">
          <source>Copy the grammar collection to avoid errors if the collection is modified while this method enumerates the elements of the collection.</source>
          <target state="translated">Copiare la raccolta di grammatica per evitare errori se la raccolta viene modificata mentre questo metodo enumera gli elementi della raccolta.</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>Gets or sets the time interval during which a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> accepts input containing only silence before finalizing recognition.</source>
          <target state="translated">Ottiene o imposta l'intervallo di tempo durante il quale <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> accetta input contenente solo silenzio, prima di completare il riconoscimento.</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The duration of the interval of silence.</source>
          <target state="translated">La durata dell'intervallo di silenzio.</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Ogni riconoscimento vocale è disponibile un algoritmo per distinguere tra vocale e di inattività.</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>If the recognizer input is silence during the initial silence timeout period, then the recognizer finalizes that recognition operation.</source>
          <target state="translated">Se l'input per il riconoscimento è inattività durante il periodo di timeout di inattività iniziale, il riconoscimento completa l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>For asynchronous recognition operations and emulation, the recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, where the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=nameWithType&gt;</ph> property is <ph id="ph3">`true`</ph>, and the <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType&gt;</ph> property is <ph id="ph5">`null`</ph>.</source>
          <target state="translated">Per le operazioni asincrone di riconoscimento e l'emulazione, genera il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento, in cui il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=nameWithType&gt;</ph> proprietà è <ph id="ph3">`true`</ph>e <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType&gt;</ph> proprietà è <ph id="ph5">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>For synchronous recognition operations and emulation, the recognizer returns <ph id="ph1">`null`</ph>, instead of a valid <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</source>
          <target state="translated">Per le operazioni di riconoscimento sincrono e l'emulazione, restituisce il riconoscimento <ph id="ph1">`null`</ph>, anziché un valore valido <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>If the initial silence timeout interval is set to 0, the recognizer does not perform an initial silence timeout check.</source>
          <target state="translated">Se l'intervallo di timeout di inattività iniziale è impostato su 0, il riconoscimento non in grado di eseguire un controllo di timeout di inattività iniziale.</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The timeout interval can be any non-negative value.</source>
          <target state="translated">L'intervallo di timeout può essere qualsiasi valore non negativo.</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The default is 0 seconds.</source>
          <target state="translated">Il valore predefinito è 0 secondi.</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base.</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>The example sets the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties of a <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> before initiating speech recognition.</source>
          <target state="translated">Nell'esempio viene impostata la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> le proprietà di un <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> prima di avviare il riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>Handlers for the speech recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> events output event information to the console to demonstrate how the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties of a <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> properties affect recognition operations.</source>
          <target state="translated">Gestori per il riconoscimento vocale <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> gli eventi di output delle informazioni di evento nella console per dimostrare come <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> le proprietà di un <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> tali proprietà influiscono sulle operazioni di riconoscimento.</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout">
          <source>This property is set to less than 0 seconds.</source>
          <target state="translated">Questa proprietà è impostata su un valore minore di 0 secondi.</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>Returns information for all of the installed speech recognizers on the current system.</source>
          <target state="translated">Restituisce informazioni per tutti sistemi di riconoscimento vocale installati nel sistema corrente.</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>A read-only collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.RecognizerInfo" /&gt;</ph> objects that describe the installed recognizers.</source>
          <target state="translated">Raccolta di sola lettura di oggetti <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.RecognizerInfo" /&gt;</ph> che descrive i riconoscitori installati.</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>To get information about the current recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</ph> property.</source>
          <target state="translated">Per ottenere informazioni sul riconoscimento corrente, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base.</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers">
          <source>The example uses the collection returned by the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method to find a speech recognizer that supports the English language.</source>
          <target state="translated">Nell'esempio viene utilizzata la raccolta restituita dal <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metodo per trovare un riconoscimento vocale che supporta la lingua inglese.</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar object to load.</source>
          <target state="translated">L'oggetto di grammatica da caricare.</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Synchronously loads a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> object.</source>
          <target state="translated">Carica un oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> in modo sincrono.</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Il riconoscimento genera un'eccezione se il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto è già stato caricato, viene caricato in modo asincrono o non è riuscito a caricare qualsiasi tipo di riconoscimento.</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>You cannot load the same <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object into multiple instances of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>.</source>
          <target state="translated">Non è possibile caricare lo stesso <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto in più istanze di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Instead, create a new <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object for each <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance.</source>
          <target state="translated">In alternativa, creare un nuovo <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> per ciascun <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> istanza.</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Se il riconoscimento è in esecuzione, le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> per sospendere il motore di riconoscimento vocale prima di caricamento, scaricamento, abilitazione o disabilitazione di una grammatica.</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>When you load a grammar, it is enabled by default.</source>
          <target state="translated">Quando si carica una grammatica, viene abilitato per impostazione predefinita.</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To disable a loaded grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">Per disabilitare una grammatica caricata, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To load a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object asynchronously, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> in modo asincrono, utilizzare il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base.</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> and loads it into a speech recognizer.</source>
          <target state="translated">Nell'esempio viene creato un <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> e li carica in un riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is not in a valid state.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> non è uno stato valido.</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">La grammatica di riconoscimento vocale da caricare.</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">Carica in modo asincrono una grammatica di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When the recognizer completes loading a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object, it raises a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> event.</source>
          <target state="translated">Quando il riconoscimento viene completato il caricamento un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> dell'oggetto, viene generato un <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Il riconoscimento genera un'eccezione se il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto è già stato caricato, viene caricato in modo asincrono o non è riuscito a caricare qualsiasi tipo di riconoscimento.</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>You cannot load the same <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object into multiple instances of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>.</source>
          <target state="translated">Non è possibile caricare lo stesso <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto in più istanze di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Instead, create a new <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object for each <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance.</source>
          <target state="translated">In alternativa, creare un nuovo <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> per ciascun <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> istanza.</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Se il riconoscimento è in esecuzione, le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> per sospendere il motore di riconoscimento vocale prima di caricamento, scaricamento, abilitazione o disabilitazione di una grammatica.</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When you load a grammar, it is enabled by default.</source>
          <target state="translated">Quando si carica una grammatica, viene abilitato per impostazione predefinita.</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To disable a loaded grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">Per disabilitare una grammatica caricata, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar synchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica di riconoscimento vocale in modo sincrono, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is not in a valid state.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> non è uno stato valido.</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The asynchronous operation was canceled.</source>
          <target state="translated">Operazione asincrona annullata.</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> finishes the asynchronous loading of a <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> object.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> termina il caricamento asincrono di un oggetto <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method initiates an asynchronous operation.</source>
          <target state="translated">Il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo inizia un'operazione asincrona.</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises this event when it completes the operation.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> genera questo evento quando viene completato l'operazione.</target>       </trans-unit>
        <trans-unit id="426" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>To get the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that the recognizer loaded, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> property of the associated <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto caricato il riconoscimento, usare il <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="427" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>To get the current <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects the recognizer has loaded, use the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">Per ottenere l'oggetto corrente <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti ha caricato il riconoscimento, usare il riconoscimento <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="428" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Se il riconoscimento è in esecuzione, le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> per sospendere il motore di riconoscimento vocale prima di caricamento, scaricamento, abilitazione o disabilitazione di una grammatica.</target>       </trans-unit>
        <trans-unit id="429" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph>, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="430" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="431" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="432" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="433" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The following example creates an in-process speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">Nell'esempio seguente crea un riconoscimento vocale in-process e quindi crea due tipi di grammatiche per il riconoscimento delle parole specifiche e per l'accettazione di dettatura disponibile.</target>       </trans-unit>
        <trans-unit id="434" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>The example constructs a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object from each of the completed speech recognition grammars, then asynchronously loads the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance.</source>
          <target state="translated">Nell'esempio si costruisce un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto da ogni le grammatiche di riconoscimento vocale completata, quindi carica in modo asincrono il <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti per il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> istanza.</target>       </trans-unit>
        <trans-unit id="435" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted">
          <source>Handlers for the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events write to the console the name of the <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that was used to perform the recognition and the text of the recognition result, respectively.</source>
          <target state="translated">Gestori per il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> eventi scrive nella console il nome del <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto utilizzato per eseguire il riconoscimento e il testo del risultato del riconoscimento, rispettivamente.</target>       </trans-unit>
        <trans-unit id="436" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source>Gets or sets the maximum number of alternate recognition results that the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> returns for each recognition operation.</source>
          <target state="translated">Ottiene o imposta il numero massimo di risultati del riconoscimento alternativi che <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> restituisce per ogni operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="437" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source>The number of alternate results to return.</source>
          <target state="translated">Il numero di risultati alternativi da restituire.</target>       </trans-unit>
        <trans-unit id="438" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> class contains the collection of <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent possible interpretations of the input.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> proprietà del <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> classe contiene la raccolta di <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> gli oggetti che rappresentano le interpretazioni possibili dell'input.</target>       </trans-unit>
        <trans-unit id="439" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source>The default value for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</ph> is 10.</source>
          <target state="translated">Il valore predefinito per <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</ph> è 10.</target>       </trans-unit>
        <trans-unit id="440" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates">
          <source><ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates" /&gt;</ph> is set to a value less than 0.</source>
          <target state="translated">La proprietà <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates" /&gt;</ph> è impostata su un valore minore di 0.</target>       </trans-unit>
        <trans-unit id="441" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The name of the setting to return.</source>
          <target state="translated">Nome dell'impostazione da restituire.</target>       </trans-unit>
        <trans-unit id="442" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Returns the values of settings for the recognizer.</source>
          <target state="translated">Restituisce i valori delle impostazioni per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="443" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The value of the setting.</source>
          <target state="translated">Valore dell'impostazione.</target>       </trans-unit>
        <trans-unit id="444" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Recognizer settings can contain string, 64-bit integer, or memory address data.</source>
          <target state="translated">Le impostazioni per il riconoscimento possono contenere una stringa, intero a 64 bit o dati di indirizzo di memoria.</target>       </trans-unit>
        <trans-unit id="445" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The following table describes the settings that are defined for a Microsoft Speech API (SAPI)-compliant recognizer.</source>
          <target state="translated">Nella tabella seguente vengono descritte le impostazioni definite per un riconoscimento vocale API di Microsoft (SAPI)-riconoscimento conformo.</target>       </trans-unit>
        <trans-unit id="446" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The following settings must have the same range for each recognizer that supports the setting.</source>
          <target state="translated">Le seguenti impostazioni devono avere lo stesso intervallo per ogni riconoscimento che supporta l'impostazione.</target>       </trans-unit>
        <trans-unit id="447" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>A SAPI-compliant recognizer is not required to support these settings and can support other settings.</source>
          <target state="translated">Un riconoscimento conformi SAPI non è necessario per supportare queste impostazioni e può supportare altre impostazioni.</target>       </trans-unit>
        <trans-unit id="448" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Name</source>
          <target state="translated">nome</target>       </trans-unit>
        <trans-unit id="449" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Description</source>
          <target state="translated">Descrizione</target>       </trans-unit>
        <trans-unit id="450" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Specifies the recognizer's CPU consumption.</source>
          <target state="translated">Specifica l'utilizzo della CPU del riconoscimento.</target>       </trans-unit>
        <trans-unit id="451" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The range is from 0 to 100.</source>
          <target state="translated">L'intervallo è compreso tra 0 e 100.</target>       </trans-unit>
        <trans-unit id="452" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The default value is 50.</source>
          <target state="translated">Il valore predefinito è 50.</target>       </trans-unit>
        <trans-unit id="453" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Indicates the length of silence at the end of unambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Indica la lunghezza di inattività alla fine dell'input non ambiguo prima che il riconoscimento vocale viene completata un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="454" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The range is from 0 to 10,000 milliseconds (ms).</source>
          <target state="translated">L'intervallo è compreso tra 0 e 10.000 millisecondi (ms).</target>       </trans-unit>
        <trans-unit id="455" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>This setting corresponds to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> property.</source>
          <target state="translated">Questa impostazione corrisponde al riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="456" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Default = 150ms.</source>
          <target state="translated">Predefinito = 150 ms.</target>       </trans-unit>
        <trans-unit id="457" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Indicates the length of silence at the end of ambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Indica la lunghezza di inattività alla fine dell'input ambiguo prima che il riconoscimento vocale viene completata un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="458" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The range is from 0 to 10,000ms.</source>
          <target state="translated">L'intervallo è compreso tra 0 e 10.000 ms.</target>       </trans-unit>
        <trans-unit id="459" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>This setting corresponds to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> property.</source>
          <target state="translated">Questa impostazione corrisponde al riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="460" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Default = 500ms.</source>
          <target state="translated">Predefinito = 500ms.</target>       </trans-unit>
        <trans-unit id="461" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Indicates whether adaptation of the acoustic model is ON (value = <ph id="ph1">`1`</ph>) or OFF (value = <ph id="ph2">`0`</ph>).</source>
          <target state="translated">Indica se l'adattamento del modello acustico è ON (valore = <ph id="ph1">`1`</ph>) o OFF (valore = <ph id="ph2">`0`</ph>).</target>       </trans-unit>
        <trans-unit id="462" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).</source>
          <target state="translated">Il valore predefinito è <ph id="ph1">`1`</ph> (ON).</target>       </trans-unit>
        <trans-unit id="463" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>Indicates whether background adaptation is ON (value = <ph id="ph1">`1`</ph>) or OFF (value = <ph id="ph2">`0`</ph>), and persists the setting in the registry.</source>
          <target state="translated">Indica se l'adattamento è ON (valore = <ph id="ph1">`1`</ph>) o OFF (valore = <ph id="ph2">`0`</ph>), e viene mantenuta l'impostazione del Registro di sistema.</target>       </trans-unit>
        <trans-unit id="464" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).</source>
          <target state="translated">Il valore predefinito è <ph id="ph1">`1`</ph> (ON).</target>       </trans-unit>
        <trans-unit id="465" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>To update a setting for the recognizer, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> methods.</source>
          <target state="translated">Per aggiornare un'impostazione per il riconoscimento, utilizzare uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="466" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che restituisce i valori per un numero di impostazioni definite per il riconoscimento che supporta le impostazioni locali en-US.</target>       </trans-unit>
        <trans-unit id="467" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The example generates the following output.</source>
          <target state="translated">L'esempio genera l'output seguente.</target>       </trans-unit>
        <trans-unit id="468" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="469" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> è la stringa vuota ("").</target>       </trans-unit>
        <trans-unit id="470" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Il riconoscimento non ha un'impostazione con tale nome.</target>       </trans-unit>
        <trans-unit id="471" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Starts a synchronous speech recognition operation.</source>
          <target state="translated">Avvia un'operazione sincrona di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="472" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>These methods perform a single, synchronous recognition operation.</source>
          <target state="translated">Questi metodi eseguono un'operazione di riconoscimento sincrono, singolo.</target>       </trans-unit>
        <trans-unit id="473" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer performs this operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Il riconoscimento esegue questa operazione su relativo grammatiche di riconoscimento vocale caricati e abilitati.</target>       </trans-unit>
        <trans-unit id="474" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Durante una chiamata a questo metodo, il riconoscimento può generare gli eventi seguenti:</target>       </trans-unit>
        <trans-unit id="475" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="476" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Generato quando il riconoscimento rileva l'input che è possibile identificare come riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="477" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="478" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Generato quando l'input viene creata una corrispondenza ambigua con una delle grammatiche attive.</target>       </trans-unit>
        <trans-unit id="479" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="480" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Generato quando il riconoscimento completa un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="481" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event when using one of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods.</source>
          <target state="translated">Il riconoscimento non genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento quando si utilizza uno del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="482" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods return a <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object, or <ph id="ph3">`null`</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> i metodi restituiscono un <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto, o <ph id="ph3">`null`</ph> se l'operazione non è riuscita o non è abilitato il riconoscimento.</target>       </trans-unit>
        <trans-unit id="483" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A synchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Un'operazione di riconoscimento sincrono può non riuscire per i motivi seguenti:</target>       </trans-unit>
        <trans-unit id="484" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties, or for the <ph id="ph3">`initialSilenceTimeout`</ph> parameter of the <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> method.</source>
          <target state="translated">Riconoscimento vocale non viene rilevato prima della scadono gli intervalli di timeout per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> , proprietà o per il <ph id="ph3">`initialSilenceTimeout`</ph> parametro del <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> (metodo).</target>       </trans-unit>
        <trans-unit id="485" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Il motore di riconoscimento vocale rileva, ma non trova corrispondenze in uno dei relativi caricati e abilitati <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="486" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To modify how the recognizer handles the timing of speech or silence with respect to recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Per modificare la modalità di gestione dei tempi di inattività rispetto al riconoscimento o di riconoscimento vocale il riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="487" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> must have at least one <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object loaded before performing recognition.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> deve avere almeno un <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto caricato prima di eseguire il riconoscimento.</target>       </trans-unit>
        <trans-unit id="488" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To load a speech recognition grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica di riconoscimento vocale, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="489" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To perform asynchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Per eseguire il riconoscimento asincrono, utilizzare uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="490" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Performs a synchronous speech recognition operation.</source>
          <target state="translated">Effettua un'operazione sincrona di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="491" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The recognition result for the input, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Il risultato di riconoscimento per l'input, o <ph id="ph1">&lt;see langword="null" /&gt;</ph> se l'operazione non riesce o il riconoscimento non è abilitato.</target>       </trans-unit>
        <trans-unit id="492" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>This method performs a single recognition operation.</source>
          <target state="translated">Questo metodo esegue un'operazione di riconoscimento singolo.</target>       </trans-unit>
        <trans-unit id="493" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The recognizer performs this operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Il riconoscimento esegue questa operazione su relativo grammatiche di riconoscimento vocale caricati e abilitati.</target>       </trans-unit>
        <trans-unit id="494" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Durante una chiamata a questo metodo, il riconoscimento può generare gli eventi seguenti:</target>       </trans-unit>
        <trans-unit id="495" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="496" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Generato quando il riconoscimento rileva l'input che è possibile identificare come riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="497" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="498" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Generato quando l'input viene creata una corrispondenza ambigua con una delle grammatiche attive.</target>       </trans-unit>
        <trans-unit id="499" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="500" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Generato quando il riconoscimento completa un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="501" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The recognizer does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event when using this method.</source>
          <target state="translated">Il riconoscimento non genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento quando si utilizza questo metodo.</target>       </trans-unit>
        <trans-unit id="502" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</ph> method returns a <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object, or <ph id="ph3">`null`</ph> if the operation is not successful.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</ph> metodo restituisce un <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto, o <ph id="ph3">`null`</ph> se l'operazione non è riuscita.</target>       </trans-unit>
        <trans-unit id="503" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>A synchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Un'operazione di riconoscimento sincrono può non riuscire per i motivi seguenti:</target>       </trans-unit>
        <trans-unit id="504" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties.</source>
          <target state="translated">Riconoscimento vocale non viene rilevato prima della scadono gli intervalli di timeout per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="505" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Il motore di riconoscimento vocale rileva, ma non trova corrispondenze in uno dei relativi caricati e abilitati <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="506" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>To perform asynchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Per eseguire il riconoscimento asincrono, utilizzare uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="507" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base.</target>       </trans-unit>
        <trans-unit id="508" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, loads it into an in-process speech recognizer, and performs one recognition operation.</source>
          <target state="translated">Nell'esempio viene creato un <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, li carica in un riconoscimento vocale in-process ed esegue un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="509" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The interval of time a speech recognizer accepts input containing only silence before finalizing recognition.</source>
          <target state="translated">L'intervallo di tempo in cui un riconoscimento vocale accetta l'input contenente solo il silenzio prima di finalizzare il riconoscimento.</target>       </trans-unit>
        <trans-unit id="510" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Performs a synchronous speech recognition operation with a specified initial silence timeout period.</source>
          <target state="translated">Effettua un'operazione sincrona di riconoscimento vocale con un periodo di timeout di inattività iniziale specificato.</target>       </trans-unit>
        <trans-unit id="511" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The recognition result for the input, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Il risultato di riconoscimento per l'input, o <ph id="ph1">&lt;see langword="null" /&gt;</ph> se l'operazione non riesce o il riconoscimento non è abilitato.</target>       </trans-unit>
        <trans-unit id="512" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>If the speech recognition engine detects speech within the time interval specified by <ph id="ph1">`initialSilenceTimeout`</ph> argument, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%28System.TimeSpan%29&gt;</ph> performs a single recognition operation and then terminates.</source>
          <target state="translated">Se il motore di riconoscimento vocale rileva vocale entro l'intervallo di tempo specificato da <ph id="ph1">`initialSilenceTimeout`</ph> argomento, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%28System.TimeSpan%29&gt;</ph> esegue un'operazione di riconoscimento singolo e quindi termina.</target>       </trans-unit>
        <trans-unit id="513" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The <ph id="ph1">`initialSilenceTimeout`</ph> parameter supersedes the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> property.</source>
          <target state="translated">Il <ph id="ph1">`initialSilenceTimeout`</ph> parametro sostituisce il riconoscimento <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="514" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Durante una chiamata a questo metodo, il riconoscimento può generare gli eventi seguenti:</target>       </trans-unit>
        <trans-unit id="515" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="516" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Generato quando il riconoscimento rileva l'input che è possibile identificare come riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="517" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="518" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Generato quando l'input viene creata una corrispondenza ambigua con una delle grammatiche attive.</target>       </trans-unit>
        <trans-unit id="519" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="520" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Generato quando il riconoscimento completa un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="521" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The recognizer does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event when using this method.</source>
          <target state="translated">Il riconoscimento non genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento quando si utilizza questo metodo.</target>       </trans-unit>
        <trans-unit id="522" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</ph> method returns a <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object, or <ph id="ph3">`null`</ph> if the operation is not successful.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</ph> metodo restituisce un <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto, o <ph id="ph3">`null`</ph> se l'operazione non è riuscita.</target>       </trans-unit>
        <trans-unit id="523" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>A synchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Un'operazione di riconoscimento sincrono può non riuscire per i motivi seguenti:</target>       </trans-unit>
        <trans-unit id="524" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or for the <ph id="ph2">`initialSilenceTimeout`</ph> parameter.</source>
          <target state="translated">Riconoscimento vocale non viene rilevato prima della scadono gli intervalli di timeout per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> o per il <ph id="ph2">`initialSilenceTimeout`</ph> parametro.</target>       </trans-unit>
        <trans-unit id="525" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Il motore di riconoscimento vocale rileva, ma non trova corrispondenze in uno dei relativi caricati e abilitati <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="526" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>To perform asynchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Per eseguire il riconoscimento asincrono, utilizzare uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="527" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base.</target>       </trans-unit>
        <trans-unit id="528" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, loads it into an in-process speech recognizer, and performs one recognition operation.</source>
          <target state="translated">Nell'esempio viene creato un <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, li carica in un riconoscimento vocale in-process ed esegue un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="529" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Starts an asynchronous speech recognition operation.</source>
          <target state="translated">Avvia un'operazione asincrona di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="530" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>These methods perform single or multiple, asynchronous recognition operations.</source>
          <target state="translated">Questi metodi eseguono uno o più operazioni asincrone di riconoscimento.</target>       </trans-unit>
        <trans-unit id="531" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer performs each operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Il riconoscimento esegue ogni operazione su relativo grammatiche di riconoscimento vocale caricati e abilitati.</target>       </trans-unit>
        <trans-unit id="532" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Durante una chiamata a questo metodo, il riconoscimento può generare gli eventi seguenti:</target>       </trans-unit>
        <trans-unit id="533" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="534" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Generato quando il riconoscimento rileva l'input che è possibile identificare come riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="535" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="536" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Generato quando l'input viene creata una corrispondenza ambigua con una delle grammatiche attive.</target>       </trans-unit>
        <trans-unit id="537" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="538" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Generato quando il riconoscimento completa un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="539" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="540" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Raised when a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> operation finishes.</source>
          <target state="translated">Eccezione generata quando un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> al termine dell'operazione.</target>       </trans-unit>
        <trans-unit id="541" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Per recuperare il risultato di un'operazione asincrona di riconoscimento, collegare un gestore eventi per il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="542" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">Il riconoscimento ha generato l'evento ogni volta che completata correttamente un'operazione di riconoscimento sincrono o asincrono.</target>       </trans-unit>
        <trans-unit id="543" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If recognition was not successful, the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> property on <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> object, which you can access in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, will be <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Se il riconoscimento non è stato completato la <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> proprietà <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> oggetto, che è possibile accedere nel gestore per il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento, saranno <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="544" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>An asynchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Un'operazione asincrona di riconoscimento può non riuscire per i motivi seguenti:</target>       </trans-unit>
        <trans-unit id="545" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties.</source>
          <target state="translated">Riconoscimento vocale non viene rilevato prima della scadono gli intervalli di timeout per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="546" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Il motore di riconoscimento vocale rileva, ma non trova corrispondenze in uno dei relativi caricati e abilitati <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="547" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> must have at least one <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object loaded before performing recognition.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> deve avere almeno un <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto caricato prima di eseguire il riconoscimento.</target>       </trans-unit>
        <trans-unit id="548" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To load a speech recognition grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica di riconoscimento vocale, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="549" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To modify how the recognizer handles the timing of speech or silence with respect to recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">Per modificare la modalità di gestione dei tempi di inattività rispetto al riconoscimento o di riconoscimento vocale il riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="550" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To perform synchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods.</source>
          <target state="translated">Per eseguire il riconoscimento sincrono, utilizzare uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="551" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Performs a single, asynchronous speech recognition operation.</source>
          <target state="translated">Effettua un'unica operazione asincrona di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="552" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>This method performs a single, asynchronous recognition operation.</source>
          <target state="translated">Questo metodo esegue un'operazione asincrona di riconoscimento.</target>       </trans-unit>
        <trans-unit id="553" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>The recognizer performs the operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Il riconoscimento esegue l'operazione relativa grammatiche di riconoscimento vocale caricati e abilitati.</target>       </trans-unit>
        <trans-unit id="554" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Durante una chiamata a questo metodo, il riconoscimento può generare gli eventi seguenti:</target>       </trans-unit>
        <trans-unit id="555" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="556" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Generato quando il riconoscimento rileva l'input che è possibile identificare come riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="557" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="558" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Generato quando l'input viene creata una corrispondenza ambigua con una delle grammatiche attive.</target>       </trans-unit>
        <trans-unit id="559" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="560" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Generato quando il riconoscimento completa un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="561" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="562" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Raised when a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> operation finishes.</source>
          <target state="translated">Eccezione generata quando un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> al termine dell'operazione.</target>       </trans-unit>
        <trans-unit id="563" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Per recuperare il risultato di un'operazione asincrona di riconoscimento, collegare un gestore eventi per il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="564" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">Il riconoscimento ha generato l'evento ogni volta che completata correttamente un'operazione di riconoscimento sincrono o asincrono.</target>       </trans-unit>
        <trans-unit id="565" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>If recognition was not successful, the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> property on <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> object, which you can access in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, will be <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Se il riconoscimento non è stato completato la <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> proprietà <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> oggetto, che è possibile accedere nel gestore per il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento, saranno <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="566" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>To perform synchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods.</source>
          <target state="translated">Per eseguire il riconoscimento sincrono, utilizzare uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="567" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>The following example shows part of a console application that demonstrates basic asynchronous speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale asincrona di base.</target>       </trans-unit>
        <trans-unit id="568" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, loads it into an in-process speech recognizer, and performs one asynchronous recognition operation.</source>
          <target state="translated">Nell'esempio viene creato un <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, li carica in un riconoscimento vocale in-process e che esegue un'operazione asincrona di riconoscimento.</target>       </trans-unit>
        <trans-unit id="569" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync">
          <source>Event handlers are included to demonstrate the events that the recognizer raises during the operation.</source>
          <target state="translated">I gestori di eventi sono inclusi per illustrare gli eventi generati durante l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="570" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Indicates whether to perform one or multiple recognition operations.</source>
          <target state="translated">Indica se eseguire una o più operazioni di riconoscimento.</target>       </trans-unit>
        <trans-unit id="571" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Performs one or more asynchronous speech recognition operations.</source>
          <target state="translated">Effettua una o più operazioni asincrone di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="572" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>If <ph id="ph1">`mode`</ph> is <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeMode.Multiple&gt;</ph>, the recognizer continues performing asynchronous recognition operations until the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> or <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> method is called.</source>
          <target state="translated">Se <ph id="ph1">`mode`</ph> è <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeMode.Multiple&gt;</ph>, il riconoscimento continua l'esecuzione di operazioni asincrone riconoscimento fino a quando il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> o <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> metodo viene chiamato.</target>       </trans-unit>
        <trans-unit id="573" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>During a call to this method, the recognizer can raise the following events:</source>
          <target state="translated">Durante una chiamata a questo metodo, il riconoscimento può generare gli eventi seguenti:</target>       </trans-unit>
        <trans-unit id="574" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="575" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Generato quando il riconoscimento rileva l'input che è possibile identificare come riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="576" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="577" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Generato quando l'input viene creata una corrispondenza ambigua con una delle grammatiche attive.</target>       </trans-unit>
        <trans-unit id="578" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="579" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Generato quando il riconoscimento completa un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="580" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="581" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Raised when a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> operation finishes.</source>
          <target state="translated">Eccezione generata quando un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> al termine dell'operazione.</target>       </trans-unit>
        <trans-unit id="582" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Per recuperare il risultato di un'operazione asincrona di riconoscimento, collegare un gestore eventi per il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="583" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">Il riconoscimento ha generato l'evento ogni volta che completata correttamente un'operazione di riconoscimento sincrono o asincrono.</target>       </trans-unit>
        <trans-unit id="584" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>If recognition was not successful, the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> property on <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> object, which you can access in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, will be <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Se il riconoscimento non è stato completato la <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</ph> proprietà <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> oggetto, che è possibile accedere nel gestore per il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento, saranno <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="585" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>An asynchronous recognition operation can fail for the following reasons:</source>
          <target state="translated">Un'operazione asincrona di riconoscimento può non riuscire per i motivi seguenti:</target>       </trans-unit>
        <trans-unit id="586" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Speech is not detected before the timeout intervals expire for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> properties.</source>
          <target state="translated">Riconoscimento vocale non viene rilevato prima della scadono gli intervalli di timeout per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="587" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The recognition engine detects speech but finds no matches in any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Il motore di riconoscimento vocale rileva, ma non trova corrispondenze in uno dei relativi caricati e abilitati <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="588" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>To perform synchronous recognition, use one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> methods.</source>
          <target state="translated">Per eseguire il riconoscimento sincrono, utilizzare uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="589" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The following example shows part of a console application that demonstrates basic asynchronous speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale asincrona di base.</target>       </trans-unit>
        <trans-unit id="590" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The example creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, loads it into an in-process speech recognizer, and performs multiple asynchronous recognition operations.</source>
          <target state="translated">Nell'esempio viene creato un <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>, li carica in un riconoscimento vocale in-process e vengono eseguite più operazioni asincrone di riconoscimento.</target>       </trans-unit>
        <trans-unit id="591" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>The asynchronous operations are cancelled after 30 seconds.</source>
          <target state="translated">Le operazioni asincrone vengono annullate dopo 30 secondi.</target>       </trans-unit>
        <trans-unit id="592" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)">
          <source>Event handlers are included to demonstrate the events that the recognizer raises during the operation.</source>
          <target state="translated">I gestori di eventi sono inclusi per illustrare gli eventi generati durante l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="593" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>Terminates asynchronous recognition without waiting for the current recognition operation to complete.</source>
          <target state="translated">Termina il riconoscimento asincrono senza attendere il completamento dell'operazione di riconoscimento corrente.</target>       </trans-unit>
        <trans-unit id="594" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>This method immediately finalizes asynchronous recognition.</source>
          <target state="translated">Questo metodo completa immediatamente riconoscimento asincrono.</target>       </trans-unit>
        <trans-unit id="595" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>If the current asynchronous recognition operation is receiving input, the input is truncated and the operation completes with the existing input.</source>
          <target state="translated">Se l'operazione di riconoscimento asincrona corrente riceve input, l'input viene troncato e il completamento dell'operazione con l'input esistente.</target>       </trans-unit>
        <trans-unit id="596" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>The recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event when an asynchronous operation is canceled, and sets the <ph id="ph3">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;</ph> property of the <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> to <ph id="ph5">`true`</ph>.</source>
          <target state="translated">Genera il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento quando viene annullata un'operazione asincrona e imposta il <ph id="ph3">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;</ph> proprietà del <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> a <ph id="ph5">`true`</ph>.</target>       </trans-unit>
        <trans-unit id="597" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>This method cancels asynchronous operations initiated by the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Questo metodo annulla le operazioni asincrone avviate dal <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="598" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>To stop asynchronous recognition without truncating the input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> method.</source>
          <target state="translated">Per arrestare il riconoscimento asincrono senza troncamento di input, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="599" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>The following example shows part of a console application that demonstrates the use of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> method.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra l'uso del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="600" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it cancels the operation.</source>
          <target state="translated">L'esempio crea e carica una grammatica di riconoscimento vocale, avvia un'operazione di riconoscimento asincrona continua e quindi viene sospesa 2 secondi prima di annullare l'operazione.</target>       </trans-unit>
        <trans-unit id="601" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>The recognizer receives input from the file, c:\temp\audioinput\sample.wav.</source>
          <target state="translated">Il riconoscimento riceve l'input dal file c:\temp\audioinput\sample.wav.</target>       </trans-unit>
        <trans-unit id="602" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel">
          <source>Event handlers are included to demonstrate the events that the recognizer raises during the operation.</source>
          <target state="translated">I gestori di eventi sono inclusi per illustrare gli eventi generati durante l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="603" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>Stops asynchronous recognition after the current recognition operation completes.</source>
          <target state="translated">Arresta il riconoscimento asincrono dopo che l'operazione di riconoscimento corrente è stata completata.</target>       </trans-unit>
        <trans-unit id="604" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>This method finalizes asynchronous recognition without truncating input.</source>
          <target state="translated">Questo metodo completa il riconoscimento asincrono senza troncamento di input.</target>       </trans-unit>
        <trans-unit id="605" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>If the current asynchronous recognition operation is receiving input, the recognizer continues accepting input until the current recognition operation is completed.</source>
          <target state="translated">Se l'operazione di riconoscimento asincrona corrente riceve input, il riconoscimento continua accettare input fino al completamento dell'operazione di riconoscimento corrente.</target>       </trans-unit>
        <trans-unit id="606" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>The recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> event when an asynchronous operation is stopped, and sets the <ph id="ph3">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;</ph> property of the <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> to <ph id="ph5">`true`</ph>.</source>
          <target state="translated">Genera il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</ph> evento quando un'operazione asincrona viene arrestata e imposta il <ph id="ph3">&lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;</ph> proprietà del <ph id="ph4">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> a <ph id="ph5">`true`</ph>.</target>       </trans-unit>
        <trans-unit id="607" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>This method stops asynchronous operations initiated by the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Questo metodo arresta le operazioni asincrone avviate dal <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="608" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>To immediately cancel asynchronous recognition with only the existing input, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> method.</source>
          <target state="translated">Per annullare immediatamente riconoscimento asincrono con solo l'input esistente, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="609" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>The following example shows part of a console application that demonstrates the use of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> method.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra l'uso del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="610" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it stops the operation.</source>
          <target state="translated">L'esempio crea e carica una grammatica di riconoscimento vocale, avvia un'operazione di riconoscimento asincrona continua e quindi viene sospesa 2 secondi prima di interrompere l'operazione.</target>       </trans-unit>
        <trans-unit id="611" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>The recognizer receives input from the file, c:\temp\audioinput\sample.wav.</source>
          <target state="translated">Il riconoscimento riceve l'input dal file c:\temp\audioinput\sample.wav.</target>       </trans-unit>
        <trans-unit id="612" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop">
          <source>Event handlers are included to demonstrate the events that the recognizer raises during the operation.</source>
          <target state="translated">I gestori di eventi sono inclusi per illustrare gli eventi generati durante l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="613" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> finalizes an asynchronous recognition operation.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> completa un'operazione di riconoscimento asincrona.</target>       </trans-unit>
        <trans-unit id="614" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> method initiates an asynchronous recognition operation.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> dell'oggetto <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metodo inizia un'operazione asincrona di riconoscimento.</target>       </trans-unit>
        <trans-unit id="615" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>When the recognizer finalizes the asynchronous operation, it raises this event.</source>
          <target state="translated">Quando il riconoscimento completa l'operazione asincrona, genera questo evento.</target>       </trans-unit>
        <trans-unit id="616" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>Using the handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event, you can access the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> in the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> object.</source>
          <target state="translated">Utilizzando il gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento, è possibile accedere il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> nel <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="617" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>If recognition was not successful, <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> will be <ph id="ph2">`null`</ph>.</source>
          <target state="translated">Se il riconoscimento non è riuscito, <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> sarà <ph id="ph2">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="618" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>To determine whether a timeout or an interruption in audio input caused recognition to fail, you can access the properties for <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt;</ph>, or <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt;</ph>.</source>
          <target state="translated">Per determinare se un timeout o un'interruzione nel input audio ha causato il riconoscimento esito negativo, è possibile accedere alle proprietà per <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt;</ph>, o <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="619" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>See the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph> class for more information.</source>
          <target state="translated">Per ulteriori informazioni, vedere la classe <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="620" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>To obtain details on the best rejected recognition candidates, attach a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> event.</source>
          <target state="translated">Per ottenere informazioni dettagliate sui migliori candidati riconoscimento rifiutati, collegare un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="621" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph>, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="622" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="623" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="624" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="625" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">Nell'esempio seguente riconosce frasi, ad esempio "Visualizzare l'elenco degli artisti nella categoria jazz" o "Gospel album visualizzare".</target>       </trans-unit>
        <trans-unit id="626" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> event to display information about the results of recognition in the console.</source>
          <target state="translated">Nell'esempio viene utilizzato un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> evento per visualizzare informazioni sui risultati del riconoscimento nella console.</target>       </trans-unit>
        <trans-unit id="627" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>Gets the current location of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> in the audio input that it is processing.</source>
          <target state="translated">Ottiene la posizione corrente di <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> nell'input audio in fase di elaborazione.</target>       </trans-unit>
        <trans-unit id="628" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">La posizione del riconoscimento nell'input audio in fase di elaborazione.</target>       </trans-unit>
        <trans-unit id="629" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>The audio position is specific to each speech recognizer.</source>
          <target state="translated">La posizione audio è specifica per ogni riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="630" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>The zero value of an input stream is established when it is enabled.</source>
          <target state="translated">Il valore zero di un flusso di input viene stabilito quando è abilitato.</target>       </trans-unit>
        <trans-unit id="631" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property references the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object's position within its audio input.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> riferimenti alle proprietà di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> la posizione dell'oggetto all'interno di input audio.</target>       </trans-unit>
        <trans-unit id="632" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Al contrario, il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> proprietà fa riferimento la posizione del dispositivo di input nel proprio flusso audio generato.</target>       </trans-unit>
        <trans-unit id="633" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Queste posizioni possono essere diverse.</target>       </trans-unit>
        <trans-unit id="634" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Ad esempio, se ha ricevuto il riconoscimento di input per i quali non ha ancora generato un risultato di riconoscimento, il valore del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> proprietà è minore del valore del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="635" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>Gets information about the current instance of <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</source>
          <target state="translated">Ottiene informazioni sull'istanza corrente di <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="636" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>Information about the current speech recognizer.</source>
          <target state="translated">Informazioni sul riconoscimento vocale corrente.</target>       </trans-unit>
        <trans-unit id="637" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>To get information about all of the installed speech recognizers for the current system, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> method.</source>
          <target state="translated">Per ottenere informazioni su tutti i tipi di riconoscimento vocale installata per il sistema corrente, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="638" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>The following example gets a partial list of data for the current in-process speech recognition engine.</source>
          <target state="translated">Nell'esempio seguente ottiene un elenco parziale dei dati per il motore di riconoscimento vocale nel processo corrente.</target>       </trans-unit>
        <trans-unit id="639" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo">
          <source>For more information, see <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph>.</source>
          <target state="translated">Per ulteriori informazioni, vedere <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="640" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>Raised when a running <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> pauses to accept modifications.</source>
          <target state="translated">Generato quando un oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> in esecuzione viene sospeso per accettare le modifiche.</target>       </trans-unit>
        <trans-unit id="641" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>Applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause a running instance of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> before modifying its settings or its <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> sospendere un'istanza in esecuzione di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> prima di modificare le impostazioni o dai relativi <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="642" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises this event when it is ready to accept modifications.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> genera questo evento quando è pronto per accettare le modifiche.</target>       </trans-unit>
        <trans-unit id="643" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>For example, while the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> is paused, you can load, unload, enable, and disable <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects, and modify values for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> properties.</source>
          <target state="translated">Ad esempio, mentre il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> è sospesa, è possibile caricare, scaricare, abilitare e disabilitare <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti e modificare i valori per il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, e <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="644" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>For more information, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per altre informazioni, vedere il metodo <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="645" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph>, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="646" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="647" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="648" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="649" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">L'esempio seguente illustra un'applicazione console che carica e Scarica <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="650" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">L'applicazione utilizza il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metodo per richiedere il motore di riconoscimento vocale per mettere in pausa per la ricezione di un aggiornamento.</target>       </trans-unit>
        <trans-unit id="651" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">L'applicazione quindi carica o scarica un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="652" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">A ogni aggiornamento, un gestore per <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento scrive il nome e lo stato di attualmente caricato <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti nella console.</target>       </trans-unit>
        <trans-unit id="653" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Come le grammatiche vengono caricate e scaricate, l'applicazione vengono innanzitutto i nomi di animali, i nomi di animali e i nomi di frutti e quindi solo i nomi di frutta.</target>       </trans-unit>
        <trans-unit id="654" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Requests that the recognizer pauses to update its state.</source>
          <target state="translated">Richiede la sospensione del riconoscimento per aggiornarne lo stato.</target>       </trans-unit>
        <trans-unit id="655" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Use this method to synchronize changes to the recognizer.</source>
          <target state="translated">Utilizzare questo metodo per sincronizzare le modifiche al sistema di riconoscimento.</target>       </trans-unit>
        <trans-unit id="656" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event to synchronize your application behavior with the state of the recognizer.</source>
          <target state="translated">Ad esempio, se si carica o scarica una grammatica di riconoscimento vocale mentre il riconoscimento per elaborare l'input, utilizzare questo metodo e <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> eventi per la sincronizzazione del comportamento dell'applicazione con lo stato del sistema di riconoscimento.</target>       </trans-unit>
        <trans-unit id="657" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>When this method is called, the recognizer pauses or completes asynchronous operations and generates a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Quando questo metodo viene chiamato, il riconoscimento viene sospeso o completamento di operazioni asincrone e genera un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="658" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event handler can then modify the state of the recognizer in between recognition operations.</source>
          <target state="translated">Oggetto <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> gestore eventi può quindi modificare lo stato del sistema di riconoscimento tra operazioni di riconoscimento.</target>       </trans-unit>
        <trans-unit id="659" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>When handling <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> events, the recognizer pauses until the event handler returns.</source>
          <target state="translated">Quando si gestiscono <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> eventi, il riconoscimento viene sospeso fino a quando non restituisce il gestore dell'evento.</target>       </trans-unit>
        <trans-unit id="660" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If the input to the recognizer is changed before the recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event, the request is discarded.</source>
          <target state="translated">Se l'input per il riconoscimento viene modificato prima genera il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento, la richiesta viene eliminato.</target>       </trans-unit>
        <trans-unit id="661" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>When this method is called:</source>
          <target state="translated">Quando viene chiamato questo metodo:</target>       </trans-unit>
        <trans-unit id="662" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If the recognizer is not processing input, the recognizer immediately generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Se il riconoscimento non è l'elaborazione di input, viene generato immediatamente il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="663" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Se il riconoscimento è l'elaborazione di input che consiste di inattività o rumore di fondo, il riconoscimento sospende l'operazione di riconoscimento e genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="664" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Se il riconoscimento è l'elaborazione di input che non è costituito inattività o rumore di fondo, il riconoscimento completa l'operazione di riconoscimento e quindi genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="665" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>While the recognizer is handling the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event:</source>
          <target state="translated">Mentre il riconoscimento sta gestendo il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento:</target>       </trans-unit>
        <trans-unit id="666" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer does not process input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property remains the same.</source>
          <target state="translated">Il riconoscimento non elabora l'input e il valore della <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> proprietà rimane invariato.</target>       </trans-unit>
        <trans-unit id="667" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The recognizer continues to collect input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> property can change.</source>
          <target state="translated">Il riconoscimento continua a raccogliere input e il valore di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> proprietà può essere modificata.</target>       </trans-unit>
        <trans-unit id="668" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>Requests that the recognizer pauses to update its state.</source>
          <target state="translated">Richiede la sospensione del riconoscimento per aggiornarne lo stato.</target>       </trans-unit>
        <trans-unit id="669" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> is <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Quando viene generato il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento, il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> proprietà del <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> è <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="670" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>To provide a user token, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per fornire un token dell'utente, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="671" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per specificare un offset di posizione audio, usare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="672" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">L'esempio seguente illustra un'applicazione console che carica e Scarica <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="673" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">L'applicazione utilizza il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metodo per richiedere il motore di riconoscimento vocale per mettere in pausa per la ricezione di un aggiornamento.</target>       </trans-unit>
        <trans-unit id="674" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">L'applicazione quindi carica o scarica un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="675" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">A ogni aggiornamento, un gestore per <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento scrive il nome e lo stato di attualmente caricato <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti nella console.</target>       </trans-unit>
        <trans-unit id="676" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Come le grammatiche vengono caricate e scaricate, l'applicazione vengono innanzitutto i nomi di animali, i nomi di animali e i nomi di frutti e quindi solo i nomi di frutta.</target>       </trans-unit>
        <trans-unit id="677" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informazioni definite dall'utente che contengono informazioni per l'operazione.</target>       </trans-unit>
        <trans-unit id="678" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)">
          <source>Requests that the recognizer pauses to update its state and provides a user token for the associated event.</source>
          <target state="translated">Richiede la sospensione del riconoscimento per aggiornarne lo stato e fornire un token utente per l'evento associato.</target>       </trans-unit>
        <trans-unit id="679" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Quando viene generato il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento, il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> proprietà del <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contiene il valore del <ph id="ph4">`userToken`</ph> parametro.</target>       </trans-unit>
        <trans-unit id="680" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per specificare un offset di posizione audio, usare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="681" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informazioni definite dall'utente che contengono informazioni per l'operazione.</target>       </trans-unit>
        <trans-unit id="682" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The offset from the current <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" /&gt;</ph> to delay the request.</source>
          <target state="translated">L'offset dall'oggetto <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" /&gt;</ph> corrente per ritardare la richiesta.</target>       </trans-unit>
        <trans-unit id="683" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>Requests that the recognizer pauses to update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">Richiede la sospensione del riconoscimento per aggiornarne lo stato e fornire un offset e un token utente per l'evento associato.</target>       </trans-unit>
        <trans-unit id="684" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> equals the current <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> plus <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph>.</source>
          <target state="translated">Il riconoscimento non avvierà la richiesta di aggiornamento per il riconoscimento fino a quando il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> corrente è uguale a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> più <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph>.</target>       </trans-unit>
        <trans-unit id="685" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Quando viene generato il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</ph> evento, il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> proprietà del <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contiene il valore del <ph id="ph4">`userToken`</ph> parametro.</target>       </trans-unit>
        <trans-unit id="686" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The audio input stream.</source>
          <target state="translated">Flusso di input audio.</target>       </trans-unit>
        <trans-unit id="687" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The format of the audio input.</source>
          <target state="translated">Il formato dell'input audio.</target>       </trans-unit>
        <trans-unit id="688" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>Configures the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object to receive input from an audio stream.</source>
          <target state="translated">Configura l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> per ricevere l'input da un flusso audio.</target>       </trans-unit>
        <trans-unit id="689" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Se il riconoscimento raggiunge la fine del flusso di input durante un'operazione di riconoscimento, l'operazione di riconoscimento completa con l'input disponibile.</target>       </trans-unit>
        <trans-unit id="690" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Operazioni successive riconoscimento è possono generare un'eccezione, a meno che non si aggiorna l'input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="691" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base.</target>       </trans-unit>
        <trans-unit id="692" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The example uses input from an audio file, example.wav, that contains the phrases, "testing testing one two three" and "mister cooper", separated by a pause.</source>
          <target state="translated">Nell'esempio viene utilizzato l'input da un file audio, example.wav, che contiene le frasi, "test o test uno due tre" e "vendita cooper", separati da una pausa.</target>       </trans-unit>
        <trans-unit id="693" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)">
          <source>The example generates the following output.</source>
          <target state="translated">L'esempio genera l'output seguente.</target>       </trans-unit>
        <trans-unit id="694" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice">
          <source>Configures the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object to receive input from the default audio device.</source>
          <target state="translated">Configura l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> per ricevere l'input dal dispositivo audio predefinito.</target>       </trans-unit>
        <trans-unit id="695" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice">
          <source>The following example shows part of a console application that demonstrates basic speech recognition.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il riconoscimento vocale base.</target>       </trans-unit>
        <trans-unit id="696" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice">
          <source>The example uses output from the default audio device, performs multiple, asynchronous recognition operations, and exits when a user utters the phrase, "exit".</source>
          <target state="translated">L'esempio utilizza l'output dal dispositivo audio predefinito, vengono eseguite più operazioni di riconoscimento asincrono e viene chiuso quando un utente utters la frase "exit".</target>       </trans-unit>
        <trans-unit id="697" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull">
          <source>Disables the input to the speech recognizer.</source>
          <target state="translated">Disabilita l'input del riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="698" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull">
          <source>Configure the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object for no input when using the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> and <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods, or when taking a recognition engine temporarily off line.</source>
          <target state="translated">Configurare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> oggetto per nessun input quando si utilizza il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph> e <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metodi, o quando si acquisisce un motore di riconoscimento temporaneamente non in linea.</target>       </trans-unit>
        <trans-unit id="699" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>The path of the file to use as input.</source>
          <target state="translated">Percorso del file da utilizzare come input.</target>       </trans-unit>
        <trans-unit id="700" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>Configures the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object to receive input from a Waveform audio format (.wav) file.</source>
          <target state="translated">Configura l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> per ricevere l'input da un file in formato audio Waveform (.wav).</target>       </trans-unit>
        <trans-unit id="701" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>If the recognizer reaches the end of the input file during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Se il riconoscimento raggiunge la fine del file di input durante un'operazione di riconoscimento, l'operazione di riconoscimento completa con l'input disponibile.</target>       </trans-unit>
        <trans-unit id="702" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Operazioni successive riconoscimento è possono generare un'eccezione, a meno che non si aggiorna l'input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="703" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)">
          <source>The following example performs recognition on the audio in a .wav file and writes the recognized text to the console.</source>
          <target state="translated">Nell'esempio seguente esegue il riconoscimento all'audio in un file. wav e scrive il testo riconosciuto nella console.</target>       </trans-unit>
        <trans-unit id="704" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)">
          <source>The stream containing the audio data.</source>
          <target state="translated">Flusso contenente i dati audio.</target>       </trans-unit>
        <trans-unit id="705" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)">
          <source>Configures the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object to receive input from a stream that contains Waveform audio format (.wav) data.</source>
          <target state="translated">Configura l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> per ricevere l'input da un flusso che contiene i dati in formato audio Waveform (.wav).</target>       </trans-unit>
        <trans-unit id="706" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)">
          <source>If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Se il riconoscimento raggiunge la fine del flusso di input durante un'operazione di riconoscimento, l'operazione di riconoscimento completa con l'input disponibile.</target>       </trans-unit>
        <trans-unit id="707" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Operazioni successive riconoscimento è possono generare un'eccezione, a meno che non si aggiorna l'input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="708" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> detects input that it can identify as speech.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> rileva un input identificabile come funzione vocale.</target>       </trans-unit>
        <trans-unit id="709" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Ogni riconoscimento vocale è disponibile un algoritmo per distinguere tra vocale e di inattività.</target>       </trans-unit>
        <trans-unit id="710" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>When the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> performs a speech recognition operation, it raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> event when its algorithm identifies the input as speech.</source>
          <target state="translated">Quando il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> esegue un'operazione di riconoscimento vocale, genera il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> evento quando l'algoritmo identifica l'input come riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="711" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> oggetto indica una posizione nel flusso di input in cui il riconoscimento per rilevata il riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="712" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> event before it raises any of the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>, or <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> events.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> genera il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> evento prima che venga generato uno qualsiasi del <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>, o <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> eventi.</target>       </trans-unit>
        <trans-unit id="713" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Per ulteriori informazioni, vedere il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="714" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph>, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="715" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="716" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="717" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="718" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The following example is part of a console application for choosing origin and destination cities for a flight.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console per la scelta di origine e destinazione città per un volo.</target>       </trans-unit>
        <trans-unit id="719" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The application recognizes phrases such as "I want to fly from Miami to Chicago."</source>
          <target state="translated">L'applicazione riconosce frasi, ad esempio "Desidero entrata da Miami a Chicago."</target>       </trans-unit>
        <trans-unit id="720" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> event to report the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> each time speech is detected.</source>
          <target state="translated">Nell'esempio viene utilizzato il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</ph> evento report il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</ph> viene rilevato il parlato ogni ora.</target>       </trans-unit>
        <trans-unit id="721" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> ha riconosciuto una o più parole che possono essere componenti di più frasi complete in una grammatica.</target>       </trans-unit>
        <trans-unit id="722" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> generates numerous <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> events as it attempts to identify an input phrase.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> genera numerosi <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> eventi perché tenta di identificare una frase di input.</target>       </trans-unit>
        <trans-unit id="723" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>You can access the text of partially recognized phrases in the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ph> object in the handler for the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> event.</source>
          <target state="translated">È possibile accedere al testo di frasi parzialmente riconosciute nel <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> proprietà del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ph> oggetto nel gestore per il <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="724" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>Typically, handling these events is useful only for debugging.</source>
          <target state="translated">In genere, la gestione di questi eventi è utile solo per il debug.</target>       </trans-unit>
        <trans-unit id="725" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ph> derives from <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ph> deriva da <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="726" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> property and the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Per ulteriori informazioni, vedere il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</ph>, e <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="727" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph>, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="728" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="729" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="730" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="731" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category".</source>
          <target state="translated">Nell'esempio seguente riconosce frasi, ad esempio "Visualizza l'elenco degli artisti nella categoria jazz".</target>       </trans-unit>
        <trans-unit id="732" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> event to display incomplete phrase fragments in the console as they are recognized.</source>
          <target state="translated">Nell'esempio viene utilizzato il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</ph> evento per visualizzare i frammenti di frase incompleto nella console di come vengono riconosciuti.</target>       </trans-unit>
        <trans-unit id="733" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> receives input that does not match any of its loaded and enabled <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> riceve input che non corrisponde ad alcun oggetto <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> caricato e abilitato.</target>       </trans-unit>
        <trans-unit id="734" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The recognizer raises this event if it determines that input does not match with sufficient confidence any of its loaded and enabled <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">L'evento viene generato il riconoscimento, se rileva che input non corrisponde con sufficiente sicurezza tutti i relativi caricati e abilitati <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="735" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the rejected <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> proprietà del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contiene il rifiutati <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="736" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>You can use the handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> event to retrieve recognition <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> that were rejected and their <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> scores.</source>
          <target state="translated">È possibile utilizzare il gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> evento per recuperare il riconoscimento <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> che sono stati rifiutati e il loro <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> punteggi.</target>       </trans-unit>
        <trans-unit id="737" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>If your application is using a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance, you can modify the confidence level at which speech input is accepted or rejected with one of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> methods.</source>
          <target state="translated">Se l'applicazione utilizza un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> istanza, è possibile modificare il livello di confidenza quali sintesi e riconoscimento vocale è è accettato o rifiutato con uno degli input di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="738" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>You can modify how the speech recognition responds to non-speech input using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">È possibile modificare una modalità di risposta il riconoscimento vocale non vocale input mediante la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="739" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph>, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="740" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="741" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="742" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="743" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">Nell'esempio seguente riconosce frasi, ad esempio "Visualizzare l'elenco degli artisti nella categoria jazz" o "Gospel album visualizzare".</target>       </trans-unit>
        <trans-unit id="744" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> to produce a successful recognition.</source>
          <target state="translated">Nell'esempio viene utilizzato un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</ph> evento per visualizzare una notifica nella console quando il riconoscimento vocale per l'input non può corrispondere al contenuto della grammatica con sufficienti <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> per produrre un riconoscimento ha esito positivo.</target>       </trans-unit>
        <trans-unit id="745" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected">
          <source>The handler also displays recognition result <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> that were rejected because of low confidence scores.</source>
          <target state="translated">Il gestore visualizza anche i risultati di riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> che sono stati rifiutati a causa di punteggi di confidenza basso.</target>       </trans-unit>
        <trans-unit id="746" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Raised when the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> receives input that matches any of its loaded and enabled <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects.</source>
          <target state="translated">Generato quando <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> riceve input che corrisponde a un oggetto <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> caricato e abilitato.</target>       </trans-unit>
        <trans-unit id="747" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>You can initiate a recognition operation using the one of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">È possibile avviare un'operazione di riconoscimento utilizzando uno del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="748" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event if it determines that input matches one of its loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects with a sufficient level of confidence to constitute recognition.</source>
          <target state="translated">Genera il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento se determina che input corrisponde a uno dei relativi caricato <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti con un livello di confidenza al riconoscimento sufficiente.</target>       </trans-unit>
        <trans-unit id="749" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the accepted <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> proprietà del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contiene accettata <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="750" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Handlers of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> events can obtain the recognized phrase as well as a list of recognition <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> with lower confidence scores.</source>
          <target state="translated">Gestori di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> possono ottenere gli eventi alla frase riconosciuta, nonché un elenco di riconoscimento <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> con punteggi di confidenza inferiore.</target>       </trans-unit>
        <trans-unit id="751" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>If your application is using a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance, you can modify the confidence level at which speech input is accepted or rejected with one of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> methods.</source>
          <target state="translated">Se l'applicazione utilizza un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> istanza, è possibile modificare il livello di confidenza quali sintesi e riconoscimento vocale è è accettato o rifiutato con uno degli input di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="752" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>You can modify how the speech recognition responds to non-speech input using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">È possibile modificare una modalità di risposta il riconoscimento vocale non vocale input mediante la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="753" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>When the recognizer receives input that matches a grammar, the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object can raise its <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Quando il riconoscimento riceve l'input che corrisponde a una grammatica, il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> può generare l'oggetto relativo <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="754" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event is raised prior to the speech recognizer's <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> dell'oggetto <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> evento viene generato prima del riconoscimento vocale <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="755" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Any tasks specific to a particular grammar should always be performed by a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Qualsiasi attività specifiche di una particolare grammatica dovrebbe sempre essere eseguita da un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="756" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>When you create a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> delegate, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="757" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="758" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="759" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="760" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The following example is part of a console application that creates speech recognition grammar, constructs a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object, and loads it into the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> to perform recognition.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che crea la grammatica di riconoscimento vocale, costrutti un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> dell'oggetto e viene caricato il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> per eseguire il riconoscimento.</target>       </trans-unit>
        <trans-unit id="761" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The example demonstrates speech input to a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Nell'esempio viene illustrato l'input vocale per un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="762" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Spoken input such as "I want to fly from Chicago to Miami" will trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Leggere l'input, ad esempio "Desidero entrata da Chicago a Miami" attiverà una <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="763" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Parlando la frase "Entrata me da Houston a Chicago" non attiverà una <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="764" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event to display successfully recognized phrases and the semantics they contain in the console.</source>
          <target state="translated">Nell'esempio viene utilizzato un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> evento per visualizzare correttamente riconosciuto frasi e la semantica contengono nella console.</target>       </trans-unit>
        <trans-unit id="765" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars">
          <source>Unloads all <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects from the recognizer.</source>
          <target state="translated">Scarica tutti gli oggetti <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> dal riconoscimento.</target>       </trans-unit>
        <trans-unit id="766" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars">
          <source>If the recognizer is currently loading a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> asynchronously, this method waits until the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> is loaded, before it unloads all of the <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects from the <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance.</source>
          <target state="translated">Se il riconoscimento sta attualmente caricando un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> in modo asincrono, questo metodo attende fino a quando il <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> viene caricato, prima che venga scaricato tutti il <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti dal <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> istanza.</target>       </trans-unit>
        <trans-unit id="767" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars">
          <source>To unload a specific grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Per scaricare una grammatica specifica, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="768" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars">
          <source>The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il caricamento sincrono e scaricamento di grammatiche riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="769" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar object to unload.</source>
          <target state="translated">L'oggetto di grammatica di cui annullare il caricamento.</target>       </trans-unit>
        <trans-unit id="770" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>Unloads a specified <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> object from the <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> instance.</source>
          <target state="translated">Scarica un oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> specificato dall'istanza <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="771" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> to pause the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instance before loading, unloading,  enabling, or disabling a <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">Se il riconoscimento è in esecuzione, le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</ph> per sospendere il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> istanza prima del caricamento, scaricamento, abilitazione o disabilitazione di un <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="772" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>To unload all <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;</ph> method.</source>
          <target state="translated">Per scaricare tutti <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti, utilizzare il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="773" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.</source>
          <target state="translated">Nell'esempio seguente viene illustrata parte di un'applicazione console che illustra il caricamento sincrono e scaricamento di grammatiche riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="774" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="Grammar" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="775" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar is not loaded in this recognizer, or this recognizer is currently loading the grammar asynchronously.</source>
          <target state="translated">La grammatica non viene caricata nel sistema di riconoscimento o il sistema di riconoscimento sta al momento caricando la grammatica in modo asincrono.</target>       </trans-unit>
        <trans-unit id="776" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Updates the value of a setting for the recognizer.</source>
          <target state="translated">Aggiorna il valore di un'impostazione per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="777" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Recognizer settings can contain string, 64-bit integer, or memory address data.</source>
          <target state="translated">Le impostazioni per il riconoscimento possono contenere una stringa, intero a 64 bit o dati di indirizzo di memoria.</target>       </trans-unit>
        <trans-unit id="778" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The following table describes the settings that are defined for a Microsoft Speech API (SAPI)-compliant recognizer.</source>
          <target state="translated">Nella tabella seguente vengono descritte le impostazioni definite per un riconoscimento vocale API di Microsoft (SAPI)-riconoscimento conformo.</target>       </trans-unit>
        <trans-unit id="779" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The following settings must have the same range for each recognizer that supports the setting.</source>
          <target state="translated">Le seguenti impostazioni devono avere lo stesso intervallo per ogni riconoscimento che supporta l'impostazione.</target>       </trans-unit>
        <trans-unit id="780" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>A SAPI-compliant recognizer is not required to support these settings and can support other settings.</source>
          <target state="translated">Un riconoscimento conformi SAPI non è necessario per supportare queste impostazioni e può supportare altre impostazioni.</target>       </trans-unit>
        <trans-unit id="781" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Name</source>
          <target state="translated">nome</target>       </trans-unit>
        <trans-unit id="782" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Description</source>
          <target state="translated">Descrizione</target>       </trans-unit>
        <trans-unit id="783" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Specifies the recognizer's CPU consumption.</source>
          <target state="translated">Specifica l'utilizzo della CPU del riconoscimento.</target>       </trans-unit>
        <trans-unit id="784" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The range is from 0 to 100.</source>
          <target state="translated">L'intervallo è compreso tra 0 e 100.</target>       </trans-unit>
        <trans-unit id="785" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default value is 50.</source>
          <target state="translated">Il valore predefinito è 50.</target>       </trans-unit>
        <trans-unit id="786" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Indicates the length of silence at the end of unambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Indica la lunghezza di inattività alla fine dell'input non ambiguo prima che il riconoscimento vocale viene completata un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="787" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The range is from 0 to 10,000 milliseconds (ms).</source>
          <target state="translated">L'intervallo è compreso tra 0 e 10.000 millisecondi (ms).</target>       </trans-unit>
        <trans-unit id="788" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This setting corresponds to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> property.</source>
          <target state="translated">Questa impostazione corrisponde al riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="789" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Default = 150ms.</source>
          <target state="translated">Predefinito = 150 ms.</target>       </trans-unit>
        <trans-unit id="790" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Indicates the length of silence in milliseconds (ms) at the end of ambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Indica la lunghezza di inattività in millisecondi (ms) alla fine dell'input ambiguo prima che il riconoscimento vocale viene completata un'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="791" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The range is from 0 to 10,000ms.</source>
          <target state="translated">L'intervallo è compreso tra 0 e 10.000 ms.</target>       </trans-unit>
        <trans-unit id="792" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>This setting corresponds to the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> property.</source>
          <target state="translated">Questa impostazione corrisponde al riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="793" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Default = 500ms.</source>
          <target state="translated">Predefinito = 500ms.</target>       </trans-unit>
        <trans-unit id="794" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Indicates whether adaptation of the acoustic model is ON (value = <ph id="ph1">`1`</ph>) or OFF (value = <ph id="ph2">`0`</ph>).</source>
          <target state="translated">Indica se l'adattamento del modello acustico è ON (valore = <ph id="ph1">`1`</ph>) o OFF (valore = <ph id="ph2">`0`</ph>).</target>       </trans-unit>
        <trans-unit id="795" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).</source>
          <target state="translated">Il valore predefinito è <ph id="ph1">`1`</ph> (ON).</target>       </trans-unit>
        <trans-unit id="796" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>Indicates whether background adaptation is ON (value = <ph id="ph1">`1`</ph>) or OFF (value = <ph id="ph2">`0`</ph>), and persists the setting in the registry.</source>
          <target state="translated">Indica se l'adattamento è ON (valore = <ph id="ph1">`1`</ph>) o OFF (valore = <ph id="ph2">`0`</ph>), e viene mantenuta l'impostazione del Registro di sistema.</target>       </trans-unit>
        <trans-unit id="797" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).</source>
          <target state="translated">Il valore predefinito è <ph id="ph1">`1`</ph> (ON).</target>       </trans-unit>
        <trans-unit id="798" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>To return one of the recognizer's settings, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting%2A&gt;</ph> method.</source>
          <target state="translated">Per restituire una delle impostazioni del riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="799" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> methods remain in effect only for the current instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, after which they revert to their default settings.</source>
          <target state="translated">Ad eccezione di <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, i valori di proprietà impostati mediante il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metodi rimangono valide solo per l'istanza corrente di <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, dopo cui ripristinare le impostazioni predefinite.</target>       </trans-unit>
        <trans-unit id="800" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognitionEngine">
          <source>You can modify how the speech recognition responds to non-speech input using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> properties.</source>
          <target state="translated">È possibile modificare una modalità di risposta il riconoscimento vocale non vocale input mediante la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="801" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The name of the setting to update.</source>
          <target state="translated">Nome dell'impostazione da aggiornare.</target>       </trans-unit>
        <trans-unit id="802" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The new value for the setting.</source>
          <target state="translated">Il nuovo valore per l'impostazione.</target>       </trans-unit>
        <trans-unit id="803" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>Updates the specified setting for the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> with the specified integer value.</source>
          <target state="translated">Aggiorna l'impostazione specificata per <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> con il valore Integer specificato.</target>       </trans-unit>
        <trans-unit id="804" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> method remain in effect only for the current instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, after which they revert to their default settings.</source>
          <target state="translated">Ad eccezione di <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, i valori di proprietà impostati mediante il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metodo rimangono valide solo per l'istanza corrente di <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, dopo cui ripristinare le impostazioni predefinite.</target>       </trans-unit>
        <trans-unit id="805" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>See <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> for descriptions of supported settings.</source>
          <target state="translated">Vedere <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> per le descrizioni delle impostazioni supportate.</target>       </trans-unit>
        <trans-unit id="806" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che restituisce i valori per un numero di impostazioni definite per il riconoscimento che supporta le impostazioni locali en-US.</target>       </trans-unit>
        <trans-unit id="807" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The example updates the confidence level settings, and then queries the recognizer to check the updated values.</source>
          <target state="translated">L'esempio aggiorna le impostazioni del livello di confidenza e successivamente sottoposto a query il riconoscimento per controllare i valori aggiornati.</target>       </trans-unit>
        <trans-unit id="808" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The example generates the following output.</source>
          <target state="translated">L'esempio genera l'output seguente.</target>       </trans-unit>
        <trans-unit id="809" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="810" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> è la stringa vuota ("").</target>       </trans-unit>
        <trans-unit id="811" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Il riconoscimento non ha un'impostazione con tale nome.</target>       </trans-unit>
        <trans-unit id="812" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>The name of the setting to update.</source>
          <target state="translated">Nome dell'impostazione da aggiornare.</target>       </trans-unit>
        <trans-unit id="813" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>The new value for the setting.</source>
          <target state="translated">Il nuovo valore per l'impostazione.</target>       </trans-unit>
        <trans-unit id="814" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>Updates the specified speech recognition engine setting with the specified string value.</source>
          <target state="translated">Aggiorna l'impostazione specificata del motore di riconoscimento vocale con il valore di stringa specificato.</target>       </trans-unit>
        <trans-unit id="815" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> method remain in effect only for the current instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, after which they revert to their default settings.</source>
          <target state="translated">Ad eccezione di <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, i valori di proprietà impostati mediante il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> metodo rimangono valide solo per l'istanza corrente di <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, dopo cui ripristinare le impostazioni predefinite.</target>       </trans-unit>
        <trans-unit id="816" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>See <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> for descriptions of supported settings.</source>
          <target state="translated">Vedere <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</ph> per le descrizioni delle impostazioni supportate.</target>       </trans-unit>
        <trans-unit id="817" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> è <ph id="ph2">&lt;see langword="null" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="818" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;paramref name="settingName" /&gt;</ph> è la stringa vuota ("").</target>       </trans-unit>
        <trans-unit id="819" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Il riconoscimento non ha un'impostazione con tale nome.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>