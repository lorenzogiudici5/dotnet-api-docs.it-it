<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechRecognizer.xml" source-language="en-US" target-language="it-IT">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac5bc77257cd77c3fc2c078698df4cc6e968d3bf09a.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bc77257cd77c3fc2c078698df4cc6e968d3bf09a</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Provides access to the shared speech recognition service available on the Windows desktop.</source>
          <target state="translated">Fornisce l'accesso al servizio condiviso di riconoscimento vocale disponibile sul desktop di Windows.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Applications use the shared recognizer to access Windows Speech Recognition.</source>
          <target state="translated">Applicazioni utilizzano il riconoscimento condiviso per accedere a Windows di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object to add to the Windows speech user experience.</source>
          <target state="translated">Utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> oggetto da aggiungere all'utente di Windows vocale.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This class provides control over various aspects of the speech recognition process:</source>
          <target state="translated">Questa classe è possibile controllare vari aspetti del processo di riconoscimento vocale:</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To manage speech recognition grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</source>
          <target state="translated">Per gestire le grammatiche riconoscimento vocale, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, e <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To get information about current speech recognition operations, subscribe to the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>’s <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">Per ottenere informazioni sul riconoscimento vocale corrente di operazioni di riconoscimento, sottoscrivere il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> eventi.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To view or modify the number of alternate results the recognizer returns, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> property.</source>
          <target state="translated">Per visualizzare o modificare il numero di risultati alternativi restituisce il riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer returns recognition results in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Il riconoscimento restituisce i risultati del riconoscimento in un <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To access or monitor the state of the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> properties and the <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, and <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> events.</source>
          <target state="translated">Per accedere o controllare lo stato di riconoscimento condiviso, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, e <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> proprietà e <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, e <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> eventi.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To synchronize changes to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per sincronizzare le modifiche al sistema di riconoscimento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">Il riconoscimento condiviso utilizza più di un thread per eseguire attività.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate input to the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Per emulare l'input per il riconoscimento condiviso, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The configuration of Windows Speech Recognition is managed by the use of the <bpt id="p1">**</bpt>Speech Properties<ept id="p1">**</ept> dialog in the <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
          <target state="translated">La configurazione del riconoscimento vocale Windows viene gestita dall'uso del <bpt id="p1">**</bpt>proprietà di riconoscimento vocale<ept id="p1">**</ept> nella finestra di dialogo di <bpt id="p2">**</bpt>Pannello di controllo<ept id="p2">**</ept>.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</source>
          <target state="translated">Questa interfaccia viene utilizzata per selezionare il motore di riconoscimento vocale desktop predefinito e lingua, il dispositivo audio di input e il comportamento di sospensione del riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objects.</source>
          <target state="translated">Se viene modificata la configurazione di Windows il riconoscimento vocale mentre è in esecuzione l'applicazione, (ad esempio, se il riconoscimento vocale è disabilitato o modificato la lingua di input), la modifica interesserà tutti <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class.</source>
          <target state="translated">Per creare un riconoscimento in-process che sia indipendente dal riconoscimento vocale Windows, utilizzare la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> classe.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Always call <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> before you release your last reference to the speech recognizer.</source>
          <target state="translated">Chiamare sempre il metodo <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> prima di rilasciare l'ultimo riferimento a riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">In caso contrario, le risorse utilizzate non vengono liberate finché il garbage collector chiama l'oggetto di riconoscimento <ph id="ph1">`Finalize`</ph> metodo.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che viene caricata una grammatica di riconoscimento vocale e input emulata asincrona, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Se il riconoscimento vocale Windows non è in esecuzione, quindi avviare l'applicazione verrà avviata il riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Se il riconoscimento vocale Windows il <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> stato, quindi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> restituisce sempre null.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> class.</source>
          <target state="translated">Inizializza una nuova istanza della classe <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object maintains a separate set of speech recognition grammars.</source>
          <target state="translated">Ogni <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> oggetto gestisce un set separato di grammatiche riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che viene caricata una grammatica di riconoscimento vocale e input emulata asincrona, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Se il riconoscimento vocale Windows non è in esecuzione, quindi avviare l'applicazione verrà avviata il riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Se il riconoscimento vocale Windows il <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> stato, quindi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> restituisce sempre null.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>Gets the format of the audio being received by the speech recognizer.</source>
          <target state="translated">Ottiene il formato dell'audio ricevuto dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>The audio input format for the speech recognizer, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the input to the recognizer is not configured.</source>
          <target state="translated">Il formato di input audio per il riconoscimento vocale o <ph id="ph1">&lt;see langword="null" /&gt;</ph> se l'input al riconoscimento non è configurato.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>Gets the level of the audio being received by the speech recognizer.</source>
          <target state="translated">Ottiene il livello dell'audio ricevuto dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">Livello audio dell'input del riconoscimento vocale, da 0 a 100.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>Occurs when the shared recognizer reports the level of its audio input.</source>
          <target state="translated">Viene generato quando il riconoscimento condiviso segnala il livello del relativo input audio.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The recognizer raises this event multiple times per second.</source>
          <target state="translated">Il riconoscimento ha generato l'evento più volte al secondo.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">La frequenza con cui l'evento viene generato varia a seconda del computer in cui è in esecuzione l'applicazione.</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the audio level at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere il livello audio al momento dell'evento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> property.</source>
          <target state="translated">Per ottenere il livello corrente audio di input per il riconoscimento, usare il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>When you create a delegate for an <ph id="ph1">`AudioLevelUpdated`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">`AudioLevelUpdated`</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The following example adds a handler for the <ph id="ph1">`AudioLevelUpdated`</ph> event to a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object.</source>
          <target state="translated">Nell'esempio seguente aggiunge un gestore per il <ph id="ph1">`AudioLevelUpdated`</ph> evento da un <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The handler outputs the new audio level to the console.</source>
          <target state="translated">Il gestore restituisce il nuovo livello audio nella console.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</source>
          <target state="translated">Ottiene la posizione corrente nel flusso audio generato dal dispositivo che fornisce l'input al riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The current location in the speech recognizer's audio input stream through which it has received input.</source>
          <target state="translated">La posizione corrente nel flusso di input audio del riconoscimento vocale attraverso il quale è stato ricevuto l'input.</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The shared recognizer receives input while the desktop speech recognition is running.</source>
          <target state="translated">Il riconoscimento condiviso riceve l'input mentre è in esecuzione il riconoscimento vocale desktop.</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The <ph id="ph1">`AudioPosition`</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Il <ph id="ph1">`AudioPosition`</ph> proprietà fa riferimento la posizione del dispositivo di input nel proprio flusso audio generato.</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position in processing audio input.</source>
          <target state="translated">Al contrario, il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> proprietà fa riferimento la posizione del riconoscimento nell'elaborazione dell'input audio.</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Queste posizioni possono essere diverse.</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Ad esempio, se ha ricevuto il riconoscimento di input per i quali non ha ancora generato un risultato di riconoscimento, il valore del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> proprietà è minore del valore del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>In the following example, the shared speech recognizer uses a dictation grammar to match speech input.</source>
          <target state="translated">Nell'esempio seguente, il riconoscimento vocale condiviso Usa una grammatica dettatura per associare input vocale.</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event writes to the console the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and  <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> when the speech recognizer detects speech at its input.</source>
          <target state="translated">Un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> evento scrive nella console di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> quando il riconoscimento vocale ha rilevato vocale relativi input.</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>Occurs when the recognizer encounters a problem in the audio signal.</source>
          <target state="translated">Viene generato quando il riconoscimento rileva un problema nel segnale audio.</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To get which problem occurred, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere si è verificato il problema, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>When you create a delegate for an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">`AudioSignalProblemOccurred`</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The following example defines an event handler that gathers information about an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event.</source>
          <target state="translated">L'esempio seguente definisce un gestore eventi che raccoglie informazioni su un <ph id="ph1">`AudioSignalProblemOccurred`</ph> evento.</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>Gets the state of the audio being received by the speech recognizer.</source>
          <target state="translated">Ottiene lo stato dell'audio ricevuto dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">Lo stato dell'input audio per il riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>Occurs when the state changes in the audio being received by the recognizer.</source>
          <target state="translated">Viene generato in seguito alla modifica dello stato nell'audio ricevuto dal riconoscimento.</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the audio state at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere lo stato audio al momento dell'evento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> property.</source>
          <target state="translated">Per ottenere lo stato corrente di audio di input per il riconoscimento, usare il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about audio state, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sullo stato audio, vedere il <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>When you create a delegate for an <ph id="ph1">`AudioStateChanged`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">`AudioStateChanged`</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The following example uses a handler for the <ph id="ph1">`AudioStateChanged`</ph> event to write the recognizer's new <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> to the console each time it changes using a member of the <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Nell'esempio seguente viene utilizzato un gestore per il <ph id="ph1">`AudioStateChanged`</ph> evento da scrivere il riconoscimento del nuovo <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> nella console ogni volta che le modifiche utilizzando un membro del <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Elimina l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Elimina l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> to release both managed and unmanaged resources; <ph id="ph2">&lt;see langword="false" /&gt;</ph> to release only unmanaged resources.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> per rilasciare sia le risorse gestite sia quelle non gestite; <ph id="ph2">&lt;see langword="false" /&gt;</ph> per rilasciare solo le risorse non gestite.</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object and releases resources used during the session.</source>
          <target state="translated">Elimina l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> e rilascia le risorse usate durante la sessione.</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">Emula l'input al riconoscimento vocale condiviso, utilizzando il testo anziché l'audio per il riconoscimento vocale sincrono.</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">Questi metodi richiedono l'input audio di sistema.</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Può essere utile quando si desidera testare o il debug di un'applicazione o grammatica.</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then these methods return <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Se il riconoscimento vocale Windows il <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> stato, quindi questi metodi restituiscono <ph id="ph1">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Genera il riconoscimento condiviso il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento delle nuove righe e gli spazi vuoti aggiuntivi vengono ignorati e considera i segni di punteggiatura come valore letterale input.</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto generato dal riconoscimento condiviso in risposta all'input emulata ha un valore di <ph id="ph2">`null`</ph> per relativo <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate asynchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per emulare un riconoscimento asincrono, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">Emula l'input di una frase al riconoscimento vocale condiviso, utilizzando il testo anziché l'audio per il riconoscimento vocale sincrono.</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Il risultato dell'operazione di riconoscimento o <ph id="ph1">&lt;see langword="null" /&gt;</ph>, se l'operazione non riesce o il riconoscimento vocale di Windows è nello stato <bpt id="p1">**</bpt>Sospeso<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole e caratteri di larghezza quando l'applicazione delle regole di sintassi per la frase di input.</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Per ulteriori informazioni su questo tipo di confronto, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> valori di enumerazione <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> e <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche Ignora le nuove righe e lo spazio vuoto aggiuntivo e considera la punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer.</source>
          <target state="translated">Nell'esempio seguente viene caricata una grammatica di esempio per il riconoscimento condiviso ed emula input per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Se il riconoscimento vocale Windows non è in esecuzione, quindi avviare l'applicazione verrà avviata il riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> always returns null.</source>
          <target state="translated">Se il riconoscimento vocale Windows il <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> stato, quindi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> restituisce sempre null.</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Matrice di unità di parole che contiene l'input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinazione bit per bit dei valori di enumerazione che descrivono il tipo di confronto da utilizzare per l'operazione di riconoscimento emulato.</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emula l'input di parole specifiche al riconoscimento vocale condiviso, utilizzando il testo anziché l'audio per il riconoscimento vocale sincrono, e specifica come il riconoscimento gestisce il confronto Unicode tra le parole e le grammatiche di riconoscimento vocale caricate.</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Il risultato dell'operazione di riconoscimento o <ph id="ph1">&lt;see langword="null" /&gt;</ph>, se l'operazione non riesce o il riconoscimento vocale di Windows è nello stato <bpt id="p1">**</bpt>Sospeso<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">Questo metodo crea un <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto utilizzando le informazioni fornite nel <ph id="ph2">`wordUnits`</ph> parametro.</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Usa il riconoscimento di <ph id="ph1">`compareOptions`</ph> quando si applica regole grammaticali per la frase di input.</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole se il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> o <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valore è presente.</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Il riconoscimento Ignora sempre la larghezza del carattere e mai Ignora Katakana / Hiragana.</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche ignorare le nuove righe e lo spazio vuoto aggiuntivo e considera i segni di punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sulla larghezza del carattere e il tipo Kana, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Frase di Input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinazione bit per bit dei valori di enumerazione che descrivono il tipo di confronto da utilizzare per l'operazione di riconoscimento emulato.</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emula l'input di una frase al riconoscimento vocale condiviso, utilizzando il testo anziché l'audio per il riconoscimento vocale sincrono, e specifica come il riconoscimento gestisce il confronto Unicode tra la frase e le grammatiche di riconoscimento vocale caricate.</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Il risultato dell'operazione di riconoscimento o <ph id="ph1">&lt;see langword="null" /&gt;</ph>, se l'operazione non riesce o il riconoscimento vocale di Windows è nello stato <bpt id="p1">**</bpt>Sospeso<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Usa il riconoscimento di <ph id="ph1">`compareOptions`</ph> quando si applica regole grammaticali per la frase di input.</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole se il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> o <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valore è presente.</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Il riconoscimento Ignora sempre la larghezza del carattere e mai Ignora Katakana / Hiragana.</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche ignorare le nuove righe e lo spazio vuoto aggiuntivo e considera i segni di punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sulla larghezza del carattere e il tipo Kana, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">Emula l'input al riconoscimento vocale condiviso, utilizzando il testo anziché l'audio per il riconoscimento vocale asincrono.</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">Questi metodi richiedono l'input audio di sistema.</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Può essere utile quando si desidera testare o il debug di un'applicazione o grammatica.</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Genera il riconoscimento condiviso il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> eventi come se l'operazione di riconoscimento non è emulata.</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Al termine dell'operazione di riconoscimento asincrono il riconoscimento, genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento delle nuove righe e gli spazi vuoti aggiuntivi vengono ignorati e considera i segni di punteggiatura come valore letterale input.</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then the shared recognizer does not process input and does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> and related events, but still raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Se il riconoscimento vocale Windows è nel <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> stato, quindi il riconoscimento condiviso non elaborare l'input e non genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> e gli eventi correlati, ma ancora genera il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto generato dal riconoscimento condiviso in risposta all'input emulata ha un valore di <ph id="ph2">`null`</ph> per relativo <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate synchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> method.</source>
          <target state="translated">Per emulare un riconoscimento sincrono, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">Emula l'input di una frase al riconoscimento vocale condiviso, utilizzando il testo anziché l'audio per il riconoscimento vocale asincrono.</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole e caratteri di larghezza quando l'applicazione delle regole di sintassi per la frase di input.</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Per ulteriori informazioni su questo tipo di confronto, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> valori di enumerazione <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> e <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche Ignora le nuove righe e lo spazio vuoto aggiuntivo e considera la punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che viene caricata una grammatica di riconoscimento vocale e input emulata asincrona, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Se il riconoscimento vocale Windows non è in esecuzione, quindi avviare l'applicazione verrà avviata il riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Se il riconoscimento vocale Windows il <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> stato, quindi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> restituisce sempre null.</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Matrice di unità di parole che contiene l'input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinazione bit per bit dei valori di enumerazione che descrivono il tipo di confronto da utilizzare per l'operazione di riconoscimento emulato.</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emula l'input di parole specifiche al riconoscimento vocale condiviso, utilizzando il testo anziché l'audio per il riconoscimento vocale asincrono, e specifica come il riconoscimento gestisce il confronto Unicode tra le parole e le grammatiche di riconoscimento vocale caricate.</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">Questo metodo crea un <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto utilizzando le informazioni fornite nel <ph id="ph2">`wordUnits`</ph> parametro.</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Usa il riconoscimento di <ph id="ph1">`compareOptions`</ph> quando si applica regole grammaticali per la frase di input.</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole se il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> o <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valore è presente.</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Il riconoscimento Ignora sempre la larghezza del carattere e mai Ignora Katakana / Hiragana.</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche ignorare le nuove righe e lo spazio vuoto aggiuntivo e considera i segni di punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sulla larghezza del carattere e il tipo Kana, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Frase di Input per l'operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinazione bit per bit dei valori di enumerazione che descrivono il tipo di confronto da utilizzare per l'operazione di riconoscimento emulato.</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emula l'input di una frase al riconoscimento vocale condiviso, utilizzando il testo anziché l'audio per il riconoscimento vocale asincrono, e specifica come il riconoscimento gestisce il confronto Unicode tra la frase e le grammatiche di riconoscimento vocale caricate.</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Usa il riconoscimento di <ph id="ph1">`compareOptions`</ph> quando si applica regole grammaticali per la frase di input.</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Il riconoscimento forniti con Vista e Windows 7 Ignora maiuscole / minuscole se il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> o <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valore è presente.</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Il riconoscimento Ignora sempre la larghezza del carattere e mai Ignora Katakana / Hiragana.</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Il riconoscimento anche ignorare le nuove righe e lo spazio vuoto aggiuntivo e considera i segni di punteggiatura come input letterale.</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Per ulteriori informazioni sulla larghezza del carattere e il tipo Kana, vedere il <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumerazione.</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</source>
          <target state="translated">Viene generato quando il riconoscimento condiviso completa un'operazione di riconoscimento asincrona per l'input emulato.</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method begins an asynchronous recognition operation.</source>
          <target state="translated">Ogni <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metodo inizia un'operazione asincrona di riconoscimento.</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The recognizer raises the <ph id="ph1">`EmulateRecognizeCompleted`</ph> event when it finalizes the asynchronous operation.</source>
          <target state="translated">Genera il riconoscimento di <ph id="ph1">`EmulateRecognizeCompleted`</ph> eventi quando completa l'operazione asincrona.</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The asynchronous recognition operation can raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">L'operazione di riconoscimento asincrono può generare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> eventi.</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> evento è l'ultimo evento di questo tipo che il riconoscimento genera per l'operazione specificata.</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>When you create a delegate for an <ph id="ph1">`EmulateRecognizeCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">`EmulateRecognizeCompleted`</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che viene caricata una grammatica di riconoscimento vocale e input emulata asincrona, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Se il riconoscimento vocale Windows non è in esecuzione, quindi avviare l'applicazione verrà avviata il riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> mode, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Se il riconoscimento vocale Windows il <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> modalità, quindi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> restituisce sempre null.</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Gets or sets a value that indicates whether this <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is ready to process speech.</source>
          <target state="translated">Ottiene o imposta un valore che indica se l'oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> è pronto per l'elaborazione vocale.</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is performing speech recognition; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> se l'oggetto <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> esegue il riconoscimento vocale; in caso contrario, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Changes to this property do not affect other instances of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class.</source>
          <target state="translated">Le modifiche a questa proprietà non influiscono le altre istanze del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> classe.</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>By default, the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property is <ph id="ph2">`true`</ph> for a newly instantiated instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</source>
          <target state="translated">Per impostazione predefinita, il valore di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> proprietà <ph id="ph2">`true`</ph> per un'istanza appena creata un'istanza di <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</source>
          <target state="translated">Anche se il riconoscimento è disabilitato, nessuna delle grammatiche di riconoscimento del riconoscimento vocale sono disponibile per le operazioni di riconoscimento.</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Setting the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property has no effect on the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">Impostazione del riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> proprietà ha effetto sul riconoscimento <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>Gets a collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that are loaded in this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> instance.</source>
          <target state="translated">Ottiene una raccolta di oggetti <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> caricati in questa istanza di <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>A collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that the application loaded into the current instance of the shared recognizer.</source>
          <target state="translated">Raccolta di oggetti <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> che l'applicazione ha caricato nell'istanza corrente del riconoscitore condiviso.</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>This property does not return any speech recognition grammars loaded by another application.</source>
          <target state="translated">Questa proprietà non restituisce alcun riconoscimento vocale grammatiche riconoscimento caricate da un'altra applicazione.</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.</source>
          <target state="translated">Nell'esempio seguente genera informazioni nella console per ogni grammatica di riconoscimento vocale caricato il riconoscimento vocale condiviso.</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">La grammatica di riconoscimento vocale da caricare.</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Loads a speech recognition grammar.</source>
          <target state="translated">Carica una grammatica di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Il riconoscimento condiviso genera un'eccezione se la grammatica di riconoscimento vocale è già stata caricata, viene caricata in modo asincrono o non è riuscito a caricare qualsiasi tipo di riconoscimento.</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Se il riconoscimento è in esecuzione, le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> per sospendere il motore di riconoscimento vocale prima di caricamento, scaricamento, abilitazione o disabilitazione di una grammatica.</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar asynchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica di riconoscimento vocale in modo asincrono, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che viene caricata una grammatica di riconoscimento vocale e input emulata asincrona, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Se il riconoscimento vocale Windows non è in esecuzione, quindi avviare l'applicazione verrà avviata il riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Se il riconoscimento vocale Windows il <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> stato, quindi <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> restituisce sempre null.</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">La grammatica di riconoscimento vocale da caricare.</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">Carica in modo asincrono una grammatica di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When the recognizer completes this asynchronous operation, it raises a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> event.</source>
          <target state="translated">Al termine dell'operazione asincrona il riconoscimento, genera un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Il riconoscimento genera un'eccezione se la grammatica di riconoscimento vocale è già stata caricata, viene caricata in modo asincrono o non è riuscito a caricare qualsiasi tipo di riconoscimento.</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Se il riconoscimento è in esecuzione, le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> per sospendere il motore di riconoscimento vocale prima di caricamento, scaricamento, abilitazione o disabilitazione di una grammatica.</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar synchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Per caricare una grammatica di riconoscimento vocale in modo sincrono, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</source>
          <target state="translated">Viene generato quando il riconoscimento termina il caricamento asincrono di una grammatica del riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method initiates an asynchronous operation.</source>
          <target state="translated">Il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> metodo inizia un'operazione asincrona.</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer raises the <ph id="ph1">`LoadGrammarCompleted`</ph> event when it completes the operation.</source>
          <target state="translated">Genera il riconoscimento di <ph id="ph1">`LoadGrammarCompleted`</ph> evento dopo il completamento dell'operazione.</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that the recognizer loaded, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> property of the associated <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto caricato il riconoscimento, usare il <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the current <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects the recognizer has loaded, use the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">Per ottenere l'oggetto corrente <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti ha caricato il riconoscimento, usare il riconoscimento <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>When you create a delegate for a <ph id="ph1">`LoadGrammarCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">`LoadGrammarCompleted`</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">Nell'esempio seguente viene creato un riconoscimento vocale condiviso e quindi crea due tipi di grammatiche per il riconoscimento delle parole specifiche e per l'accettazione di dettatura disponibile.</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">Nell'esempio viene caricato in modo asincrono tutte le grammatiche create per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Handlers for the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.</source>
          <target state="translated">Gestori per il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> eventi scrive nella console il nome della grammatica che è stato utilizzato per eseguire il riconoscimento e il testo del risultato del riconoscimento, rispettivamente.</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</source>
          <target state="translated">Ottiene o imposta il numero massimo di risultati del riconoscimento alternativi che il riconoscimento condiviso restituisce per ogni operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The maximum number of alternate results that the speech recognizer returns for each recognition operation.</source>
          <target state="translated">Il numero massimo di risultati alternativi che il riconoscimento vocale restituisce per ogni operazione di riconoscimento.</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> class contains the collection of <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent other candidate interpretations of the input.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> proprietà del <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> classe contiene la raccolta di <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> gli oggetti che rappresentano altri interpretazioni candidato dell'input.</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The default value for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> is 10.</source>
          <target state="translated">Il valore predefinito per <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> è 10.</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event.</source>
          <target state="translated">Ottiene o imposta un valore che indica se il riconoscimento condiviso sospende le operazioni di riconoscimento quando un'applicazione gestisce un evento <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if the shared recognizer waits to process input while any application is handling the <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> se il riconoscimento condiviso attende l'input del processo mentre un'applicazione gestisce l'evento <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> ; in caso contrario, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Set this property to <ph id="ph1">`true`</ph>, if within the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</source>
          <target state="translated">Impostare questa proprietà su <ph id="ph1">`true`</ph>, se all'interno di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> gestore eventi dell'applicazione è necessario modificare lo stato del servizio di riconoscimento vocale o modificare le grammatiche di riconoscimento vocale caricato o attivato prima che il servizio di riconoscimento vocale processi più input.</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Setting the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> property to <ph id="ph2">`true`</ph> causes each <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler in every application to block the Windows speech recognition service.</source>
          <target state="translated">L'impostazione di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> proprietà <ph id="ph2">`true`</ph> , ognuna <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> gestore dell'evento in ogni applicazione di bloccare il servizio di riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To synchronize the changes to the shared recognizer with your application state, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per sincronizzare le modifiche per il riconoscimento condiviso con lo stato dell'applicazione, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>When <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> is <ph id="ph2">`true`</ph>, during the execution of the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> handler the speech recognition service pauses and buffers new audio input as it arrives.</source>
          <target state="translated">Quando <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> è <ph id="ph2">`true`</ph>, durante l'esecuzione del <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> gestore del servizio di riconoscimento vocale sospende e memorizza nel buffer di input audio di nuovo quando arriva.</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Once the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</source>
          <target state="translated">Una volta il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> il gestore eventi, il riconoscimento servizio riprende il riconoscimento e inizia l'elaborazione delle informazioni dal buffer di input.</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To enable or disable the speech recognition service, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">Per abilitare o disabilitare il servizio di riconoscimento vocale, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>Gets the current location of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Ottiene la posizione corrente del riconoscimento nell'input audio in fase di elaborazione.</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">La posizione del riconoscimento nell'input audio in fase di elaborazione.</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The <ph id="ph1">`RecognizerAudioPosition`</ph> property references the recognizer's position in processing its audio input.</source>
          <target state="translated">Il <ph id="ph1">`RecognizerAudioPosition`</ph> proprietà fa riferimento la posizione del riconoscimento l'elaborazione del proprio input audio.</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Al contrario, il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> proprietà fa riferimento la posizione del dispositivo di input nel proprio flusso audio generato.</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Queste posizioni possono essere diverse.</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Ad esempio, se ha ricevuto il riconoscimento di input per i quali non ha ancora generato un risultato di riconoscimento, il valore del <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> proprietà è minore del valore del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Gets information about the shared speech recognizer.</source>
          <target state="translated">Ottiene informazioni sul riconoscimento vocale condiviso.</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Information about the shared speech recognizer.</source>
          <target state="translated">Informazioni sul riconoscimento vocale condiviso.</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>This property returns information about the speech recognizer in use by Windows Speech Recognition.</source>
          <target state="translated">Questa proprietà restituisce informazioni su riconoscimento vocale in uso dal riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>The following example sends information about the shared recognizer to the console.</source>
          <target state="translated">Nell'esempio seguente invia informazioni il riconoscimento condiviso nella console.</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Occurs when the recognizer pauses to synchronize recognition and other operations.</source>
          <target state="translated">Viene generato quando il riconoscimento viene sospeso per sincronizzare il riconoscimento e altre operazioni.</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause a running instance of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> before modifying its <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> sospendere un'istanza in esecuzione di <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> prima di modificare il relativo <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For example, while the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> is paused, you can load, unload, enable, and disable <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Ad esempio, mentre il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> è sospesa, è possibile caricare, scaricare, abilitare e disabilitare <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> raises this event when it is ready to accept modifications.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> genera questo evento quando è pronto per accettare le modifiche.</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">L'esempio seguente illustra un'applicazione console che carica e Scarica <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">L'applicazione utilizza il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metodo per richiedere il motore di riconoscimento vocale per mettere in pausa per la ricezione di un aggiornamento.</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">L'applicazione quindi carica o scarica un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">A ogni aggiornamento, un gestore per <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento scrive il nome e lo stato di attualmente caricato <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti nella console.</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Come le grammatiche vengono caricate e scaricate, l'applicazione vengono innanzitutto i nomi di animali, i nomi di animali e i nomi di frutti e quindi solo i nomi di frutta.</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">Richiede la sospensione del riconoscimento condiviso e l'aggiornamento dello stato.</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use this method to synchronize changes to the shared recognizer.</source>
          <target state="translated">Utilizzare questo metodo per sincronizzare le modifiche per il riconoscimento condiviso.</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event to synchronize your application behavior with the state of the recognizer.</source>
          <target state="translated">Ad esempio, se si carica o scarica una grammatica di riconoscimento vocale mentre il riconoscimento per elaborare l'input, utilizzare questo metodo e <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> eventi per la sincronizzazione del comportamento dell'applicazione con lo stato del sistema di riconoscimento.</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called, the recognizer pauses or completes asynchronous operations and generates a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Quando questo metodo viene chiamato, il riconoscimento viene sospeso o completamento di operazioni asincrone e genera un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event handler can then modify the state of the recognizer in between recognition operations.</source>
          <target state="translated">Oggetto <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> gestore eventi può quindi modificare lo stato del sistema di riconoscimento tra operazioni di riconoscimento.</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called:</source>
          <target state="translated">Quando viene chiamato questo metodo:</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is not processing input, the recognizer immediately generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Se il riconoscimento non è l'elaborazione di input, viene generato immediatamente il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Se il riconoscimento è l'elaborazione di input che consiste di inattività o rumore di fondo, il riconoscimento sospende l'operazione di riconoscimento e genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Se il riconoscimento è l'elaborazione di input che non è costituito inattività o rumore di fondo, il riconoscimento completa l'operazione di riconoscimento e quindi genera il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>While the recognizer is handling the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event:</source>
          <target state="translated">Mentre il riconoscimento sta gestendo il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento:</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer does not process input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property remains the same.</source>
          <target state="translated">Il riconoscimento non elabora l'input e il valore della <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> proprietà rimane invariato.</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer continues to collect input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property can change.</source>
          <target state="translated">Il riconoscimento continua a raccogliere input e il valore di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> proprietà può essere modificata.</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To change whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> property.</source>
          <target state="translated">Per modificare la modalità di operazioni di riconoscimento viene sospeso il riconoscimento condiviso, mentre un'applicazione gestisce un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> evento, utilizzare il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">L'esempio seguente illustra un'applicazione console che carica e Scarica <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti.</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">L'applicazione utilizza il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metodo per richiedere il motore di riconoscimento vocale per mettere in pausa per la ricezione di un aggiornamento.</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">L'applicazione quindi carica o scarica un <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">A ogni aggiornamento, un gestore per <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento scrive il nome e lo stato di attualmente caricato <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetti nella console.</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Come le grammatiche vengono caricate e scaricate, l'applicazione vengono innanzitutto i nomi di animali, i nomi di animali e i nomi di frutti e quindi solo i nomi di frutta.</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">Richiede la sospensione del riconoscimento condiviso e l'aggiornamento dello stato.</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> is <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Quando viene generato il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento, il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> proprietà del <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> è <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To provide a user token, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per fornire un token dell'utente, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per specificare un offset di posizione audio, usare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informazioni definite dall'utente che contengono informazioni per l'operazione.</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</source>
          <target state="translated">Richiede la sospensione del riconoscimento condiviso, l'aggiornamento dello stato e la fornitura di un token utente per l'evento associato.</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Quando viene generato il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento, il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> proprietà del <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contiene il valore del <ph id="ph4">`userToken`</ph> parametro.</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Per specificare un offset di posizione audio, usare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informazioni definite dall'utente che contengono informazioni per l'operazione.</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The offset from the current <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> to delay the request.</source>
          <target state="translated">L'offset dall'oggetto <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> corrente per ritardare la richiesta.</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">Richiede la sospensione del riconoscimento condiviso, l'aggiornamento dello stato e la fornitura di un offset e un token utente per l'evento associato.</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> equals the current <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus the value of the <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> parameter.</source>
          <target state="translated">Il riconoscimento non avvierà la richiesta di aggiornamento per il riconoscimento fino a quando il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> corrente è uguale a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> sommato al valore del <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> parametro.</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Quando viene generato il riconoscimento di <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> evento, il <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> proprietà del <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contiene il valore del <ph id="ph4">`userToken`</ph> parametro.</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>Occurs when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Viene generato quando il riconoscimento rileva un input identificabile come funzione vocale.</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The shared recognizer can raise this event in response to input.</source>
          <target state="translated">Il riconoscimento condiviso può generare questo evento in risposta all'input.</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> oggetto indica una posizione nel flusso di input in cui il riconoscimento per rilevata il riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> properties and the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Per ulteriori informazioni, vedere il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> proprietà e <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> e <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metodi.</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The following example is part of a console application for choosing origin and destination cities for a flight.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console per la scelta di origine e destinazione città per un volo.</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The application recognizes phrases such as "I want to fly from Miami to Chicago."</source>
          <target state="translated">L'applicazione riconosce frasi, ad esempio "Desidero entrata da Miami a Chicago."</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event to report the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> each time speech is detected.</source>
          <target state="translated">Nell'esempio viene utilizzato il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> evento report il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> viene rilevato il parlato ogni ora.</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">Viene generato quando il riconoscimento ha riconosciuto le parole che possono essere componenti di più frasi complete in una grammatica.</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The shared recognizer can raise this event when the input is ambiguous.</source>
          <target state="translated">Il riconoscimento condiviso può generare questo evento quando l'input è ambiguo.</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Ad esempio, per una grammatica di riconoscimento vocale che supporta il riconoscimento di uno "nuovo gioco." o "nuova partita", "nuovo gioco." è un input non ambiguo, e "nuova partita" è un input ambiguo.</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category".</source>
          <target state="translated">Nell'esempio seguente riconosce frasi, ad esempio "Visualizza l'elenco degli artisti nella categoria jazz".</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event to display incomplete phrase fragments in the console as they are recognized.</source>
          <target state="translated">Nell'esempio viene utilizzato il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> evento per visualizzare i frammenti di frase incompleto nella console di come vengono riconosciuti.</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</source>
          <target state="translated">Viene generato quando il riconoscimento riceve un input che non corrisponde ad alcuna grammatica di riconoscimento vocale caricata.</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</source>
          <target state="translated">Se determina che input non corrisponde con sufficiente sicurezza qualsiasi le grammatiche di riconoscimento vocale caricato, il riconoscimento condiviso genera questo evento.</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the rejected <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> proprietà del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contiene il rifiutati <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">Le soglie di probabilità per il riconoscimento condiviso, gestito da <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, sono associati a un profilo utente e archiviati nel Registro di sistema Windows.</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">Le applicazioni non scrivere le modifiche al Registro di sistema per le proprietà di riconoscimento condiviso.</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">Nell'esempio seguente riconosce frasi, ad esempio "Visualizzare l'elenco degli artisti nella categoria jazz" o "Gospel album visualizzare".</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.</source>
          <target state="translated">Nell'esempio viene utilizzato un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> evento per visualizzare una notifica nella console quando il riconoscimento vocale per l'input non è possibile associare al contenuto della grammatica confidenza sufficiente per generare un riconoscimento ha esito positivo.</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Occurs when the recognizer receives input that matches one of its speech recognition grammars.</source>
          <target state="translated">Viene generato quando il riconoscimento riceve un input che corrisponde a una delle relative grammatiche di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The recognizer raises the <ph id="ph1">`SpeechRecognized`</ph> event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</source>
          <target state="translated">Genera il riconoscimento di <ph id="ph1">`SpeechRecognized`</ph> eventi se si determina con sufficiente sicurezza che input corrisponda a uno le grammatiche di riconoscimento vocale caricati e abilitati.</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the accepted <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> proprietà del <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contiene accettata <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> oggetto.</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">Le soglie di probabilità per il riconoscimento condiviso, gestito da <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, sono associati a un profilo utente e archiviati nel Registro di sistema Windows.</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">Le applicazioni non scrivere le modifiche al Registro di sistema per le proprietà di riconoscimento condiviso.</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When the recognizer receives input that matches a grammar, the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object can raise the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Quando il riconoscimento riceve l'input che corrisponde a una grammatica, il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> oggetto può generare il <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event is raised prior to the speech recognizer's <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> dell'oggetto <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> evento viene generato prima del riconoscimento vocale <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">Nell'esempio seguente fa parte di un'applicazione console che carica una grammatica di riconoscimento vocale e viene illustrato l'input vocale per il riconoscimento condiviso, i risultati di riconoscimento associati e gli eventi associati generati dal riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Se il riconoscimento vocale Windows non è in esecuzione, quindi avviare l'applicazione verrà avviata il riconoscimento vocale Windows.</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Spoken input such as "I want to fly from Chicago to Miami" will trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Leggere l'input, ad esempio "Desidero entrata da Chicago a Miami" attiverà una <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Parlando la frase "Entrata me da Houston a Chicago" non attiverà una <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> evento.</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event to display successfully recognized phrases and the semantics they contain in the console.</source>
          <target state="translated">Nell'esempio viene utilizzato un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> evento per visualizzare correttamente riconosciuto frasi e la semantica contengono nella console.</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>Gets the state of a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Ottiene lo stato di un oggetto <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>The state of the <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Stato dell'oggetto <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>This read-only property indicates whether the shared recognizer resident in Windows is in the <ph id="ph1">`Stopped`</ph> or the <ph id="ph2">`Listening`</ph> state.</source>
          <target state="translated">Questa proprietà di sola lettura indica se il riconoscimento condiviso residente in Windows è nel <ph id="ph1">`Stopped`</ph> o <ph id="ph2">`Listening`</ph> stato.</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>For more information, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> enumeration.</source>
          <target state="translated">Per altre informazioni, vedere l'enumerazione <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</source>
          <target state="translated">Viene generato quando lo stato di esecuzione del motore di riconoscimento della tecnologia Windows Desktop Speech viene modificato.</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The shared recognizer raises this event when the state of Windows Speech Recognition changes to the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> state.</source>
          <target state="translated">Il riconoscimento condiviso genera questo evento quando cambia lo stato di riconoscimento vocale Windows per il <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> o <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> stato.</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the state of the shared recognizer at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Per ottenere lo stato di sistema condiviso di riconoscimento al momento dell'evento, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> proprietà dell'oggetto associato <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the current state of the shared recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">Per ottenere lo stato corrente del riconoscimento condiviso, usare il riconoscimento <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Quando si crea un delegato per un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> evento, si identifica il metodo che gestirà l'evento.</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Per associare l'evento al gestore eventi in uso, aggiungere all'evento un'istanza del delegato.</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Il gestore eventi viene chiamato ogni volta che si verifica l'evento, a meno che non venga rimosso il delegato.</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Per ulteriori informazioni sui delegati del gestore eventi, vedere <bpt id="p1">[</bpt>eventi e delegati<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">Nell'esempio seguente viene creato un riconoscimento vocale condiviso e quindi crea due tipi di grammatiche per il riconoscimento delle parole specifiche e per l'accettazione di dettatura disponibile.</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">Nell'esempio viene caricato in modo asincrono tutte le grammatiche create per il riconoscimento.</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event uses the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method to put Windows Recognition in "listening" mode.</source>
          <target state="translated">Un gestore per il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> evento utilizza il <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> metodo per inserire il riconoscimento di Windows in modalità "ascolto".</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>Unloads all speech recognition grammars from the shared recognizer.</source>
          <target state="translated">Scarica tutte le grammatiche di riconoscimento vocale dal riconoscimento condiviso.</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</source>
          <target state="translated">Se il riconoscimento sta caricando una grammatica in modo asincrono, questo metodo attende fino a quando non viene caricata la grammatica, prima che venga scaricato tutte le grammatiche del riconoscimento.</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>To unload a specific grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Per scaricare una grammatica specifica, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> metodo.</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar to unload.</source>
          <target state="translated">La grammatica di cui annullare il caricamento.</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>Unloads a specified speech recognition grammar from the shared recognizer.</source>
          <target state="translated">Scarica una grammatica di riconoscimento vocale specificata dal riconoscimento condiviso.</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Se il riconoscimento è in esecuzione, le applicazioni devono utilizzare <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> per sospendere il motore di riconoscimento vocale prima di caricamento, scaricamento, abilitazione o disabilitazione di una grammatica.</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>To unload all grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> method.</source>
          <target state="translated">Per scaricare tutte le grammatiche, utilizzare il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> metodo.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>