<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="AudioState.xml" source-language="en-US" target-language="it-IT">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac5c25020d12cfa99f187a1ed73cc6b5083cfbc0240.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">c25020d12cfa99f187a1ed73cc6b5083cfbc0240</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.AudioState">
          <source>Contains a list of possible states for the audio input to a speech recognition engine.</source>
          <target state="translated">Contiene un elenco di possibili stati dell'input audio in un motore di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.AudioState">
          <source>You can obtain the audio input state of the speech recognition engine with the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A?displayProperty=nameWithType&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A?displayProperty=nameWithType&gt;</ph> properties.</source>
          <target state="translated">È possibile ottenere lo stato di input audio del motore di riconoscimento vocale con il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A?displayProperty=nameWithType&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A?displayProperty=nameWithType&gt;</ph> proprietà.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.AudioState">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged?displayProperty=nameWithType&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged?displayProperty=nameWithType&gt;</ph> events are raised when the audio input state of a speech recognition engine changes.</source>
          <target state="translated">Il <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged?displayProperty=nameWithType&gt;</ph> e <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged?displayProperty=nameWithType&gt;</ph> eventi vengono generati quando l'audio di input dello stato di un modifiche di motore di riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.AudioState">
          <source>The following example demonstrates an event handler that handles the changing audio state of a speech recognizer.</source>
          <target state="translated">Nell'esempio seguente viene illustrato un gestore eventi che gestisce lo stato di audio modifica di un riconoscimento vocale.</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" uid="F:System.Speech.Recognition.AudioState.Silence">
          <source>Receiving silence or non-speech background noise.</source>
          <target state="translated">Assenza di suoni o ricezione di rumore di fondo non vocale.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" uid="F:System.Speech.Recognition.AudioState.Speech">
          <source>Receiving speech input.</source>
          <target state="translated">Ricezione di input vocale.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" uid="F:System.Speech.Recognition.AudioState.Stopped">
          <source>Not processing audio input.</source>
          <target state="translated">Mancata elaborazione dell'input audio.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>