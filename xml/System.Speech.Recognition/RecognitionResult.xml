<Type Name="RecognitionResult" FullName="System.Speech.Recognition.RecognitionResult">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="46b1281659c02ab99ba0f8f96c6774896c39f5a0" />
    <Meta Name="ms.sourcegitcommit" Value="5a49536d99d2d0b54e4cb7280870903e043272df" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="it-IT" />
    <Meta Name="ms.lasthandoff" Value="07/03/2018" />
    <Meta Name="ms.locfileid" Value="37610538" />
  </Metadata>
  <TypeSignature Language="C#" Value="public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable sealed beforefieldinit RecognitionResult extends System.Speech.Recognition.RecognizedPhrase implements class System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognitionResult" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class RecognitionResult&#xA;Inherits RecognizedPhrase&#xA;Implements ISerializable" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognitionResult sealed : System::Speech::Recognition::RecognizedPhrase, System::Runtime::Serialization::ISerializable" />
  <TypeSignature Language="F#" Value="type RecognitionResult = class&#xA;    inherit RecognizedPhrase&#xA;    interface ISerializable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognizedPhrase</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.Runtime.Serialization.ISerializable</InterfaceName>
    </Interface>
  </Interfaces>
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Contiene informazioni dettagliate sull'input che è stato riconosciuto dalle istanze di <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> o di <see cref="T:System.Speech.Recognition.SpeechRecognizer" />.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Questa classe deriva da <xref:System.Speech.Recognition.RecognizedPhrase> e vengono fornite informazioni dettagliate su riconoscimento vocale, inclusi i seguenti:  
  
-   Il <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> riferimenti a proprietà di <xref:System.Speech.Recognition.Grammar> che il riconoscimento consente di identificare il parlato.  
  
-   Il <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> proprietà contiene il testo normalizzato per la frase. Per altre informazioni sulla normalizzazione del testo, vedere <xref:System.Speech.Recognition.ReplacementText>.  
  
-   Il <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> le informazioni semantiche contenute nel risultato fa riferimento a proprietà. Le informazioni semantiche sono un dizionario di dati semantici associati e i nomi delle chiavi.  
  
-   Il <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> proprietà contiene una raccolta di <xref:System.Speech.Recognition.RecognizedPhrase> gli oggetti che rappresentano altri interpretazioni candidato dell'input audio. Per altre informazioni, vedere <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>.  
  
-   Il <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> proprietà contiene una raccolta ordinata di <xref:System.Speech.Recognition.RecognizedWordUnit> riconosciuto di oggetti che rappresentano ogni parola nell'input. Ogni <xref:System.Speech.Recognition.RecognizedWordUnit> contiene formato di visualizzazione, formato lessicale e pronuncia informazioni per la parola corrispondente.  
  
 Alcuni membri del <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, e <xref:System.Speech.Recognition.Grammar> classi possono generare un <xref:System.Speech.Recognition.RecognitionResult>. Per altre informazioni, vedere i seguenti metodi ed eventi.  
  
-   Metodi ed eventi del <xref:System.Speech.Recognition.SpeechRecognitionEngine> classe:  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>  
  
-   Metodi ed eventi del <xref:System.Speech.Recognition.SpeechRecognizer> classe:  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>  
  
-   Il <xref:System.Speech.Recognition.Grammar.SpeechRecognized> eventi del <xref:System.Speech.Recognition.Grammar> classe.  
  
 Per altre informazioni sugli eventi di riconoscimento, vedere [mediante gli eventi di riconoscimento vocale](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).  
  
   
  
## Examples  
 Nell'esempio seguente viene illustrato un gestore per il `SpeechRecognized` eventi di un <xref:System.Speech.Recognition.SpeechRecognitionEngine> oppure <xref:System.Speech.Recognition.SpeechRecognizer> oggetto e alcune informazioni sull'oggetto associato <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
  </Docs>
  <Members>
    <Member MemberName="Alternates">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Alternates { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Alternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Alternates As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Alternates { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Alternates : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;" Usage="System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ottiene la raccolta di possibili corrispondenze per l'input del riconoscimento vocale.</summary>
        <value>Raccolta di sola lettura delle alternative di riconoscimento.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Riconoscimento <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> vengono ordinati in base ai valori della loro <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> proprietà. Il valore di probabilità di una frase specifica indica la probabilità che la frase corrispondente all'input. L'utilizzo con il valore di confidenza più elevato è la frase che molto probabilmente corrisponde all'input.  
  
 Ciascuna <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> valore deve essere valutato singolarmente e senza riferimento ai valori di altri confidenza <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>. Le proprietà che la <xref:System.Speech.Recognition.RecognitionResult> eredita da <xref:System.Speech.Recognition.RecognizedPhrase> forniscono informazioni dettagliate sulla frase con il punteggio di confidenza più elevato.  
  
 È possibile utilizzare il <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> viene raccolta per la correzione degli errori automatizzata. Ad esempio, quando si progetta una finestra di dialogo di directory, un'applicazione potrebbe richiedere all'utente per verificare se l'applicazione ha le informazioni corrette da un evento di riconoscimento, come in "detto che 'Anna'?" Se l'utente indica "no", quindi l'applicazione è stato possibile cercare l'utente su qualsiasi alternative con nome che aveva un sufficientemente elevato <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> punteggio.  
  
 Per altre informazioni sul riconoscimento vocale e l'uso di alternative di riconoscimento, vedere [riconoscimento vocale](http://msdn.microsoft.com/library/6a7dc524-07fc-4862-8d48-8c10dc64b919) e [mediante gli eventi di riconoscimento vocale](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).  
  
   
  
## Examples  
 Nell'esempio seguente viene illustrato un gestore per il `SpeechRecognized` evento e alcune informazioni sull'oggetto associato <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
      </Docs>
    </Member>
    <Member MemberName="Audio">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio Audio { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizedAudio Audio" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Audio As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizedAudio ^ Audio { System::Speech::Recognition::RecognizedAudio ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Audio : System.Speech.Recognition.RecognizedAudio" Usage="System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ottiene l'audio associato al risultato del riconoscimento.</summary>
        <value>L'audio associato al risultato del riconoscimento o <see langword="null" /> se il sistema di riconoscimento ha generato il risultato da una chiamata al metodo <see langword="EmulateRecognize" /> o <see langword="EmulateRecognizeAsync" /> di un'istanza di <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> o di <see cref="T:System.Speech.Recognition.SpeechRecognizer" />.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Per ottenere una sezione dell'audio associata a un intervallo specifico di parole nel risultato del riconoscimento, usare il <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> (metodo).  
  
   
  
## Examples  
 Nell'esempio seguente viene illustrato un gestore per il **SpeechRecognized** evento e alcune informazioni sull'oggetto associato <xref:System.Speech.Recognition.RecognitionResult>.  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
      Console.WriteLine("Audio for result:");  
      Console.WriteLine("  Start time: "+ e.Result.Audio.StartTime);  
      Console.WriteLine("  Duration: " + e.Result.Audio.Duration);  
      Console.WriteLine("  Format: " + e.Result.Audio.Format.EncodingFormat);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      </Docs>
    </Member>
    <Member MemberName="GetAudioForWordRange">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognizedAudio GetAudioForWordRange(class System.Speech.Recognition.RecognizedWordUnit firstWord, class System.Speech.Recognition.RecognizedWordUnit lastWord) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      <MemberSignature Language="VB.NET" Value="Public Function GetAudioForWordRange (firstWord As RecognizedWordUnit, lastWord As RecognizedWordUnit) As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognizedAudio ^ GetAudioForWordRange(System::Speech::Recognition::RecognizedWordUnit ^ firstWord, System::Speech::Recognition::RecognizedWordUnit ^ lastWord);" />
      <MemberSignature Language="F#" Value="member this.GetAudioForWordRange : System.Speech.Recognition.RecognizedWordUnit * System.Speech.Recognition.RecognizedWordUnit -&gt; System.Speech.Recognition.RecognizedAudio" Usage="recognitionResult.GetAudioForWordRange (firstWord, lastWord)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="firstWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
        <Parameter Name="lastWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
      </Parameters>
      <Docs>
        <param name="firstWord">La prima parola nell'intervallo.</param>
        <param name="lastWord">L'ultima parola nell'intervallo.</param>
        <summary>Ottiene una sezione dell'audio associato a un intervallo specifico di parole nel risultato del riconoscimento.</summary>
        <returns>La sezione dell'audio associata all'intervallo della parola.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Per ottenere l'audio completo associato al risultato del riconoscimento, usare il <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> proprietà.  
  
   
  
## Examples  
 Nell'esempio seguente crea una grammatica in modo da accettare l'input di nome e la collega a esso un gestore per il `SpeechRecognized` evento. La grammatica utilizza un carattere jolly per l'elemento del nome della frase. Il gestore eventi Usa l'audio dal carattere jolly per creare e riprodurre un messaggio di saluto.  
  
```csharp  
  
private Grammar CreateNameInputGrammar()  
{  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey nameKey =  
    new SemanticResultKey("Name", wildcardBuilder);  
  
  GrammarBuilder nameBuilder =  
    new GrammarBuilder("My name is");  
  nameBuilder.Append(nameKey);  
  
  Grammar nameGrammar = new Grammar(nameBuilder);  
  nameGrammar.Name = "Name input";  
  
  nameGrammar.SpeechRecognized +=  
    new EventHandler<SpeechRecognizedEventArgs>(  
      NameInputHandler);  
  
  return nameGrammar;  
}  
  
// Handle the SpeechRecognized event for the name grammar.  
private void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  SemanticValue semantics = e.Result.Semantics;  
  
  if (semantics.ContainsKey("Name"))  
  {  
    RecognizedAudio nameAudio =  
      result.GetAudioForWordRange(  
        result.Words[3], result.Words[result.Words.Count - 1]);  
  
    // Save the audio. Create a directory and file as necessary.  
    FileInfo fi = new FileInfo(@"C:\temp\temp.wav");  
    if (!fi.Directory.Exists)  
    {  
      fi.Directory.Create();  
    }  
    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  
    nameAudio.WriteToWaveStream(stream);  
    stream.Close();  
  
    // Greet the person using the saved audio.  
    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("Hello");  
    builder.AppendAudio(fi.FullName);  
    synthesizer.Speak(builder);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.NullReferenceException">Il riconoscimento genera il risultato da una chiamata ai metodi <see langword="EmulateRecognize" /> o <see langword="EmulateRecognizeAsync" /> degli oggetti di <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> o di <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> .</exception>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Audio" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="System.Runtime.Serialization.ISerializable.GetObjectData">
      <MemberSignature Language="C#" Value="void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);" />
      <MemberSignature Language="ILAsm" Value=".method hidebysig newslot virtual instance void System.Runtime.Serialization.ISerializable.GetObjectData(class System.Runtime.Serialization.SerializationInfo info, valuetype System.Runtime.Serialization.StreamingContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)" />
      <MemberSignature Language="VB.NET" Value="Sub GetObjectData (info As SerializationInfo, context As StreamingContext) Implements ISerializable.GetObjectData" />
      <MemberSignature Language="C++ CLI" Value=" virtual void System.Runtime.Serialization.ISerializable.GetObjectData(System::Runtime::Serialization::SerializationInfo ^ info, System::Runtime::Serialization::StreamingContext context) = System::Runtime::Serialization::ISerializable::GetObjectData;" />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.Runtime.Serialization.ISerializable.GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="info" Type="System.Runtime.Serialization.SerializationInfo" />
        <Parameter Name="context" Type="System.Runtime.Serialization.StreamingContext" />
      </Parameters>
      <Docs>
        <param name="info">Oggetto da popolare con i dati.</param>
        <param name="context">Destinazione della serializzazione.</param>
        <summary>Compila un'istanza <see cref="T:System.Runtime.Serialization.SerializationInfo" /> con i dati necessari per serializzare l'oggetto di destinazione.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Questo membro è un’implementazione esplicita di un membro di interfaccia. Può essere utilizzato solo quando si esegue il cast dell'istanza <xref:System.Speech.Recognition.RecognitionResult> a un'interfaccia <xref:System.Runtime.Serialization.ISerializable>.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Runtime.Serialization.ISerializable" />
        <altmember cref="T:System.Runtime.Serialization.SerializationInfo" />
        <altmember cref="T:System.Runtime.Serialization.StreamingContext" />
      </Docs>
    </Member>
  </Members>
</Type>