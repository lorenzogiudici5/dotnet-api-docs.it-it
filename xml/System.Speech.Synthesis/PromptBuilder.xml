<Type Name="PromptBuilder" FullName="System.Speech.Synthesis.PromptBuilder">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="b8a26980c3d1406c566920c945073878989ec4cb" />
    <Meta Name="ms.sourcegitcommit" Value="0e1f030650a307c745ee84ed547ef858acaea587" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="it-IT" />
    <Meta Name="ms.lasthandoff" Value="11/29/2018" />
    <Meta Name="ms.locfileid" Value="52598369" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class PromptBuilder" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit PromptBuilder extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Synthesis.PromptBuilder" />
  <TypeSignature Language="VB.NET" Value="Public Class PromptBuilder" />
  <TypeSignature Language="C++ CLI" Value="public ref class PromptBuilder" />
  <TypeSignature Language="F#" Value="type PromptBuilder = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Crea un oggetto <see cref="T:System.Speech.Synthesis.Prompt" /> vuoto e fornisce metodi per l'aggiunta di contenuto, la selezione di voci, il controllo degli attributi vocali e il controllo della pronuncia delle parole.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Con <xref:System.Speech.Synthesis.PromptBuilder>, è possibile aggiungere un'ampia gamma di tipi di contenuto da un prompt dei comandi, inclusi testo normale, il markup SSML (come una stringa o un file), registrata audio o anche un altro <xref:System.Speech.Synthesis.PromptBuilder> oggetto.  
  
 Per aggiungere un testo a un <xref:System.Speech.Synthesis.PromptBuilder> dell'oggetto e, facoltativamente, il controllo degli attributi vocali, ad esempio enfasi, frequenza e volume, usare uno del <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> metodi.  È inoltre possibile controllare gli attributi vocali come un gruppo con il <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> e <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> metodi.  
  
 È possibile aggiungere testo e parlato di controllo o come lo si pronuncia usando il <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A>, o <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> metodi.  
  
 Modificare la voce parlante attualmente selezionata nella finestra di richiesta usando uno degli overload <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> richiesto i metodi, una voce specifica per l'uso o la specifica di denominazione delle caratteristiche della voce, ad esempio età e sesso.  
  
 Per generare il riconoscimento vocale da una <xref:System.Speech.Synthesis.PromptBuilder> dell'oggetto, è possibile passarlo come argomento per il <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A> (metodo).  
  
 Per altre informazioni, vedere [costruzione di una richiesta complessa](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361616(v%3doffice.14)).  
  
 ]]></format>
    </remarks>
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Crea una nuova istanza della classe <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public PromptBuilder ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; PromptBuilder();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Crea una nuova istanza della classe <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 L'esempio seguente crea un nuovo <xref:System.Speech.Synthesis.PromptBuilder> dell'istanza e aggiungervi una stringa di testo.  
  
```csharp  
using System.Speech.Synthesis;  
  
public void MySimpleText ()  
{  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendText("Hello world!");  
}  
```  
  
 Il markup seguente illustra l'equivalente in sintesi della voce Markup Language (SSML), (`xml:lang` è un attributo obbligatorio del `speak` elemento):  
  
```xml  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">  
  Hello world!  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public PromptBuilder (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.#ctor(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; PromptBuilder(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="new System.Speech.Synthesis.PromptBuilder : System.Globalization.CultureInfo -&gt; System.Speech.Synthesis.PromptBuilder" Usage="new System.Speech.Synthesis.PromptBuilder culture" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Fornisce informazioni su impostazioni cultura specifiche, ad esempio lingua, nome delle impostazioni cultura, sistema di scrittura, calendario usato e modalità di formattazione delle date e ordinamento delle stringhe.</param>
        <summary>Crea una nuova istanza della classe <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica le impostazioni cultura.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Questo costruttore imposta il valore per il <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà. Il <xref:System.Speech.Synthesis.SpeechSynthesizer> oggetto tenterà di selezionare una voce installata che supporta la lingua specificata dal `culture` parametro per elaborare la richiesta. Se viene trovata una voce con le impostazioni cultura specificate, verrà utilizzato. Se non viene trovata una voce con le impostazioni cultura specificate, verrà utilizzata la voce predefinita.  
  
 Per pronunciare correttamente le parole nel linguaggio specificato per il `culture` parametro, un motore di sintesi (sintesi vocale o TTS) vocale che supporta il linguaggio deve essere installato. Un motore di sintesi vocale installato viene chiamato una voce. Per ottenere informazioni sulle voci vengono installate per impostazioni cultura specifiche, usare il <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> (metodo).  
  
 Microsoft Windows e l'API System. Speech accettano tutti i codici dei paesi di lingua validi come valori per `culture`. I motori di sintesi vocale fornita con Windows 7 supportano i seguenti codici di lingua paese:  
  
-   en-US. Inglese (Stati Uniti)  
  
-   zh-CN. Cinese (Cina)  
  
-   zh-TW. Cinese (Taiwan)  
  
 Sono inoltre consentiti i codici di lingua di due lettere, ad esempio "en".  
  
   
  
## Examples  
 L'esempio seguente crea una <xref:System.Speech.Synthesis.PromptBuilder> dell'istanza e specifica relativa <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A>.  
  
```csharp  
using System.Speech.Synthesis;  
  
public void MySimpleText ()  
{  
    PromptBuilder builder = new PromptBuilder(new System.Globalization.CultureInfo("en-US"));  
    builder.AppendText("Hello world!");  
}  
```  
  
 Il markup seguente illustra l'elemento SSML equivalente:  
  
```xml  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">  
  Hello world!  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendAudio">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Aggiunge un file audio specificato a un oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : string -&gt; unit" Usage="promptBuilder.AppendAudio path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">Percorso completo al file audio.</param>
        <summary>Aggiunge il file audio specificato a <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (Uri audioFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(class System.Uri audioFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.Uri)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (audioFile As Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(Uri ^ audioFile);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : Uri -&gt; unit" Usage="promptBuilder.AppendAudio audioFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioFile" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="audioFile">URI per il file audio.</param>
        <summary>Aggiunge il file audio nell'URI specificato a <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 L'esempio seguente Inizializza una nuova istanza di <xref:System.Speech.Synthesis.PromptBuilder> classe e quindi aggiunge il testo su di esso, seguito da un file audio.  
  
```csharp  
using System.Speech.PromptBuilder;  
  
public void SimpleConcatenation()  
{  
    // Add a prompt fragment from a .wav file.  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendText("How are you today?");  
    builder.AppendAudio(new Uri ("http://www.speech.microsoft.com/ding.wav"));  
}  
```  
  
 Il markup seguente illustra il markup SSML equivalente.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis"  
       xmlns:ms="http://www.microsoft.com/speech/synthesis" xml:lang="en">  
  
  How are you today?  
  <audio src="http://www.speech.microsoft.com/ding.wav" />  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendAudio">
      <MemberSignature Language="C#" Value="public void AppendAudio (Uri audioFile, string alternateText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendAudio(class System.Uri audioFile, string alternateText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendAudio(System.Uri,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendAudio (audioFile As Uri, alternateText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendAudio(Uri ^ audioFile, System::String ^ alternateText);" />
      <MemberSignature Language="F#" Value="member this.AppendAudio : Uri * string -&gt; unit" Usage="promptBuilder.AppendAudio (audioFile, alternateText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioFile" Type="System.Uri" />
        <Parameter Name="alternateText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="audioFile">URI per il file audio.</param>
        <param name="alternateText">Stringa contenente testo alternativo che rappresenta l'audio.</param>
        <summary>Aggiunge il file audio specificato e il testo alternativo a <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il motore di sintesi vocale verrà pronunciare il testo alternativo se non è possibile riprodurre file audio.  
  
   
  
## Examples  
 Nell'esempio seguente aggiunge un file audio da un <xref:System.Speech.Synthesis.PromptBuilder> dell'istanza e specifica il testo da pronunciare se non è possibile riprodurre file audio.  
  
```csharp  
using System.Speech.PromptBuilder;  
  
public void SimpleConcatenation()  
{  
  
    // Concatenate a prompt fragment from a .wav file.  
    PromptBuilder builder = new PromptBuilder ();  
    builder.AppendAudio(new Uri ("C:\\OnHold.wav"), "Your call will be answered in the order it was received");  
}  
```  
  
 Il markup seguente illustra il markup SSML equivalente.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis"  
       xmlns:ms="http://www.microsoft.com/speech/synthesis" xml:lang="en">  
  
  <audio src="C:\OnHold.wav"> Your call will be answered in the order it was received. </audio>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBookmark">
      <MemberSignature Language="C#" Value="public void AppendBookmark (string bookmarkName);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBookmark(string bookmarkName) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBookmark(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBookmark (bookmarkName As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBookmark(System::String ^ bookmarkName);" />
      <MemberSignature Language="F#" Value="member this.AppendBookmark : string -&gt; unit" Usage="promptBuilder.AppendBookmark bookmarkName" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="bookmarkName" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="bookmarkName">Stringa contenente il nome del computer segnalibro aggiunto.</param>
        <summary>Aggiunge un segnalibro all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Motore di sintesi vocale genererà una <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> evento che si verifica un segnalibro durante la pronuncia di un prompt dei comandi usando uno del <xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A>, <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A>, o <xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A> metodi.  
  
   
  
## Examples  
 L'esempio seguente crea una richiesta che include due segnalibri e invia l'output in un file WAV per la riproduzione. Il gestore per il <xref:System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached> eventi scrive il nome del segnalibro e la posizione nel flusso audio quando è stato generato l'evento nella console.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt and append bookmarks.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "The weather forecast for today is partly cloudy with some sun breaks.");  
        builder.AppendBookmark("Daytime forecast");  
        builder.AppendText(  
          "Tonight's weather will be cloudy with a 30% chance of showers.");  
        builder.AppendBookmark("Nightime forecast");  
  
        // Add a handler for the BookmarkReached event.  
        synth.BookmarkReached +=  
          new EventHandler<BookmarkReachedEventArgs>(synth_BookmarkReached);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Write the name and position of the bookmark to the console.  
    static void synth_BookmarkReached(object sender, BookmarkReachedEventArgs e)  
    {  
      Console.WriteLine("Bookmark ({0}) reached at: {1} ",  
        e.Bookmark, e.AudioPosition);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendBreak">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Inserisce un'interruzione (sospensione) nel contenuto di un oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak();" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : unit -&gt; unit" Usage="promptBuilder.AppendBreak " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Aggiunge un'interruzione all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Questo metodo non specifica una durata per l'interruzione. Il <xref:System.Speech.Synthesis.SpeechSynthesizer> determina un valore di durata in base al contesto linguistico.  
  
   
  
## Examples  
 Nell'esempio seguente crea una richiesta contenente due frasi separate da un'interruzione e legge il prompt dei comandi per il dispositivo audio predefinito nel computer.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45.");  
        builder.AppendBreak();  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:30, and 9:15.");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak (System.Speech.Synthesis.PromptBreak strength);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak(valuetype System.Speech.Synthesis.PromptBreak strength) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak(System.Speech.Synthesis.PromptBreak)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak (strength As PromptBreak)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak(System::Speech::Synthesis::PromptBreak strength);" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : System.Speech.Synthesis.PromptBreak -&gt; unit" Usage="promptBuilder.AppendBreak strength" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="strength" Type="System.Speech.Synthesis.PromptBreak" />
      </Parameters>
      <Docs>
        <param name="strength">Indica la durata dell'interruzione, con l'incremento di valori seguente:</param>
        <summary>Aggiunge un'interruzione all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e ne specifica la durata.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 I valori di <xref:System.Speech.Synthesis.PromptBreak> enumerazione rappresentano un intervallo di intervalli di separazione (in pausa) tra i delimitatori di parola. Il motore di sintesi vocale determina la durata esatta dell'intervallo. Quando viene richiesta un'interruzione, uno di questi valori viene passato al motore di sintesi vocale (TTS), che contiene un mapping tra questi valori e i corrispondenti valori interruzione millisecondo.  
  
   
  
## Examples  
 Nell'esempio seguente crea una richiesta contenente due frasi separate da un'interruzione e invia l'output a un file WAV per la riproduzione.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45");  
        builder.AppendBreak(PromptBreak.Medium);  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendBreak">
      <MemberSignature Language="C#" Value="public void AppendBreak (TimeSpan duration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendBreak(valuetype System.TimeSpan duration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendBreak(System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendBreak (duration As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendBreak(TimeSpan duration);" />
      <MemberSignature Language="F#" Value="member this.AppendBreak : TimeSpan -&gt; unit" Usage="promptBuilder.AppendBreak duration" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="duration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="duration">Tempo in tick, in cui un tick è uguale a 100 nanosecondi.</param>
        <summary>Aggiunge un'interruzione della durata specificata all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Un'interruzione di può essere utilizzata per controllare mette in pausa o altri limiti prosodica tra le parole. Un'interruzione è facoltativa. Se non è presenta un'interruzione, sintetizzatore determina l'interruzione tra le parole in base al contesto linguistico.  
  
   
  
## Examples  
 Nell'esempio seguente crea una richiesta contenente due frasi separate da un'interruzione di segni di 15,000,000 graduazione (1,5 secondi) e legge il prompt dei comandi per il dispositivo audio predefinito nel computer.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt with two sentences separated by a break.  
        PromptBuilder builder = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        builder.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 8:45");  
        builder.AppendBreak(new TimeSpan(15000000));  
        builder.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendPromptBuilder">
      <MemberSignature Language="C#" Value="public void AppendPromptBuilder (System.Speech.Synthesis.PromptBuilder promptBuilder);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendPromptBuilder(class System.Speech.Synthesis.PromptBuilder promptBuilder) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendPromptBuilder(System.Speech.Synthesis.PromptBuilder)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendPromptBuilder(System::Speech::Synthesis::PromptBuilder ^ promptBuilder);" />
      <MemberSignature Language="F#" Value="member this.AppendPromptBuilder : System.Speech.Synthesis.PromptBuilder -&gt; unit" Usage="promptBuilder.AppendPromptBuilder promptBuilder" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="promptBuilder" Type="System.Speech.Synthesis.PromptBuilder" />
      </Parameters>
      <Docs>
        <param name="promptBuilder">Il contenuto da aggiungere.</param>
        <summary>Aggiunge un oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> a un altro oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Nell'esempio seguente crea due <xref:System.Speech.Synthesis.PromptBuilder> istanze e quindi li aggiunge a un terzo <xref:System.Speech.Synthesis.PromptBuilder>.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\showtimes.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\showtimes.wav");  
  
        // Build child prompts.  
        PromptBuilder theatreA = new PromptBuilder();  
        theatreA.AppendText(  
          "Tonight's movie showings in theater A are at 5:45, 7:15, and 9:30");  
        theatreA.AppendBreak(PromptBreak.Large);  
        PromptBuilder theatreB = new PromptBuilder();  
        theatreB.AppendText(  
          "Tonight's movie showings in theater B are at 5:15, 7:15, and 9:15");  
  
        // Build the parent prompt and append the two child prompts.  
        PromptBuilder showTimes = new PromptBuilder(  
          new System.Globalization.CultureInfo("en-US"));  
        showTimes.AppendText(  
          "The following are the show times for tonight's movies:");  
        showTimes.AppendPromptBuilder(theatreA);  
        showTimes.AppendPromptBuilder(theatreB);  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(showTimes);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendSsml">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Aggiunge un file SSML a un oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : string -&gt; unit" Usage="promptBuilder.AppendSsml path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path">Percorso completo al file SSML da aggiungere.</param>
        <summary>Aggiunge il file SSML nel percorso specificato all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il file SSML deve essere un file di formato XML conforme al [linguaggio Markup sintesi della voce (SSML) versione 1.0](https://go.microsoft.com/fwlink/?LinkId=201763) specifica.  
  
 È anche possibile aggiungere il markup SSML di una stringa usando <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 L'esempio seguente crea una <xref:System.Speech.Synthesis.PromptBuilder> dell'oggetto e accoda il contenuto di un file SSML usando il <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> (metodo).  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a file that defines an SSML prompt.  
        PromptBuilder ssmlFile = new PromptBuilder();  
        ssmlFile.AppendSsml("c:\\test\\Weather.ssml");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(ssmlFile);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 Di seguito è riportato il file SSML che fa riferimento all'esempio precedente.  
  
```xml  
<?xml version="1.0" encoding="ISO-8859-1"?>  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis"  
 xml:lang="en-US">  
  
  <s> The weather forecast for today is partly cloudy with some sun breaks. </s>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (Uri ssmlFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(class System.Uri ssmlFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.Uri)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (ssmlFile As Uri)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(Uri ^ ssmlFile);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : Uri -&gt; unit" Usage="promptBuilder.AppendSsml ssmlFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlFile" Type="System.Uri" />
      </Parameters>
      <Docs>
        <param name="ssmlFile">URI completo del file SSML da aggiungere.</param>
        <summary>Aggiunge il file SSML nell'URI specificato all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il file SSML deve essere un file di formato XML conforme al [linguaggio Markup sintesi della voce (SSML) versione 1.0](https://www.w3.org/TR/speech-synthesis/) specifica.  
  
 È anche possibile aggiungere il markup SSML di una stringa usando <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 L'esempio seguente crea una <xref:System.Speech.Synthesis.PromptBuilder> dell'oggetto e accoda il contenuto di un file SSML usando il <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> (metodo).  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a file that defines an SSML prompt.  
        PromptBuilder ssmlFile = new PromptBuilder();  
        ssmlFile.AppendSsml(new Uri("c:\\test\\Weather.ssml"));  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(ssmlFile);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 Di seguito è riportato il file SSML che fa riferimento all'esempio precedente.  
  
```xml  
<?xml version="1.0" encoding="ISO-8859-1"?>  
<speak version="1.0"  
 xmlns="http://www.w3.org/2001/10/synthesis"  
 xml:lang="en-US">  
  
  <s> The weather forecast for today is partly cloudy with some sun breaks. </s>  
  
</speak>  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsml">
      <MemberSignature Language="C#" Value="public void AppendSsml (System.Xml.XmlReader ssmlFile);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsml(class System.Xml.XmlReader ssmlFile) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsml(System.Xml.XmlReader)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsml (ssmlFile As XmlReader)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsml(System::Xml::XmlReader ^ ssmlFile);" />
      <MemberSignature Language="F#" Value="member this.AppendSsml : System.Xml.XmlReader -&gt; unit" Usage="promptBuilder.AppendSsml ssmlFile" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlFile" Type="System.Xml.XmlReader" />
      </Parameters>
      <Docs>
        <param name="ssmlFile">Nome completo del file XML da aggiungere.</param>
        <summary>Aggiunge un oggetto <c>XMLReader</c> che fa riferimento a un prompt SSML all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il file SSML deve essere un file di formato XML conforme al [linguaggio Markup sintesi della voce (SSML) versione 1.0](https://www.w3.org/TR/speech-synthesis/) specifica.  
  
 È anche possibile aggiungere il markup SSML di una stringa usando <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 L'esempio seguente crea una <xref:System.Speech.Synthesis.PromptBuilder> dell'oggetto da un <xref:System.Xml.XmlReader> oggetto che fa riferimento a un file contenente il markup di linguaggio Markup sintesi della voce (SSML).  
  
```csharp  
using System;  
using System.Xml;  
using System.IO;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToWaveFile(@"C:\test\weather.wav");  
  
        // Create a SoundPlayer instance to play the output audio file.  
        System.Media.SoundPlayer m_SoundPlayer =  
          new System.Media.SoundPlayer(@"C:\test\weather.wav");  
  
        // Create the path to the SSML file.  
        string weatherFile = Path.GetFullPath("c:\\test\\Weather.xml");  
        PromptBuilder builder = null;  
  
        // Create an XML Reader from the file, create a PromptBuilder and   
        // append the XmlReader.  
        if (File.Exists(weatherFile))  
        {  
          XmlReader reader = XmlReader.Create(weatherFile);  
          builder = new PromptBuilder();  
          builder.AppendSsml(reader);  
          reader.Close();  
        }  
  
        // Speak the prompt and play back the output file.  
        synth.Speak(builder);  
        m_SoundPlayer.Play();  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendSsmlMarkup">
      <MemberSignature Language="C#" Value="public void AppendSsmlMarkup (string ssmlMarkup);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendSsmlMarkup(string ssmlMarkup) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendSsmlMarkup (ssmlMarkup As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendSsmlMarkup(System::String ^ ssmlMarkup);" />
      <MemberSignature Language="F#" Value="member this.AppendSsmlMarkup : string -&gt; unit" Usage="promptBuilder.AppendSsmlMarkup ssmlMarkup" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
          <AttributeName>System.ComponentModel.EditorBrowsable</AttributeName>
        </Attribute>
        <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5">
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="ssmlMarkup" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="ssmlMarkup">Stringa contenente markup SSML.</param>
        <summary>Aggiunge la stringa specificata che contiene il markup SSML all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 È necessario usare i caratteri di escape appropriata se si aggiunge il markup SSML. Si noti il rovesciate precedono le virgolette che racchiudono il valore della `interpret-as` attributo nell'esempio seguente:  
  
```csharp  
builder.AppendSsmlMarkup("<say-as interpret-as = \"characters\"> chair </say-as>");  
```  
  
> [!NOTE]
>  La stringa utilizzata come argomento al <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> non può includere un `speak` elemento.  
  
 Quando si usa <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A> per specificare le pronunce inline in un `phoneme` elemento, è possibile usare i telefoni da uno qualsiasi di alfabeti fonetici seguenti, forniti che supporti il motore di riconoscimento vocale corrente:  
  
-   Alfabeto fonetico internazionale (IPA)  
  
-   Universal Phone Set UPS)  
  
-   SAPI Phone Set  
  
 Qualsiasi motore di sintesi vocale SSML conformi leggerà i telefoni dal pacchetto IPA.  
  
 È anche possibile aggiungere un file contenente il markup SSML usando uno del <xref:System.Speech.Synthesis.PromptBuilder.AppendSsml%2A> metodi. Per aggiungere un testo da pronunciare che non è formattato con il linguaggio di markup, usare uno dei <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias%2A>, <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A>, o <xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A> metodi.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendText">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Aggiunge testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string -&gt; unit" Usage="promptBuilder.AppendText textToSpeak" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Stringa contenente il testo da usare come input vocale.</param>
        <summary>Specifica il testo da aggiungere all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Per aggiungere testo formattato come linguaggio di markup SSML, utilizzare <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
   
  
## Examples  
 L'esempio seguente crea una <xref:System.Speech.Synthesis.PromptBuilder> dell'oggetto e aggiunge una stringa di testo usando il <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> (metodo).  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and append a text string.  
        PromptBuilder speakText = new PromptBuilder();  
        speakText.AppendText("Say the name of the song you want to hear");  
  
        // Speak the contents of the prompt.  
        synth.Speak(speakText);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptEmphasis emphasis);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptEmphasis emphasis) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptEmphasis)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, emphasis As PromptEmphasis)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptEmphasis emphasis);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptEmphasis -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, emphasis)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="emphasis" Type="System.Speech.Synthesis.PromptEmphasis" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Stringa contenente il testo da usare come input vocale.</param>
        <param name="emphasis">Il valore per l'enfasi o l'accento da applicare al testo.</param>
        <summary>Aggiunge il testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il grado di enfasi per il testo.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 I motori di sintesi vocale in Windows non supportano il parametro di enfasi in questo momento. Impostazione dei valori per il parametro di enfasi non produrrà alcuna modifica acustico nell'output di sintesi vocale.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptRate rate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptRate rate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptRate)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, rate As PromptRate)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptRate rate);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptRate -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, rate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="rate" Type="System.Speech.Synthesis.PromptRate" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Stringa contenente il testo da usare come input vocale.</param>
        <param name="rate">Il valore per la velocità di pronuncia da applicare al testo.</param>
        <summary>Aggiunge il testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica la velocità di pronuncia per il testo.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 L'esempio seguente crea un <xref:System.Speech.Synthesis.PromptBuilder> dell'oggetto e aggiunge le stringhe di testo. Nell'esempio viene usato il <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> metodo per specificare un modo di parlare lenta frequenza per la stringa da aggiungere, che enumera il contenuto di un ordine.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder speakRate = new PromptBuilder();  
        speakRate.AppendText("Your order for");  
        speakRate.AppendText("one kitchen sink and one faucet", PromptRate.Slow);  
        speakRate.AppendText("has been confirmed.");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(speakRate);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendText">
      <MemberSignature Language="C#" Value="public void AppendText (string textToSpeak, System.Speech.Synthesis.PromptVolume volume);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendText(string textToSpeak, valuetype System.Speech.Synthesis.PromptVolume volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendText(System.String,System.Speech.Synthesis.PromptVolume)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendText (textToSpeak As String, volume As PromptVolume)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendText(System::String ^ textToSpeak, System::Speech::Synthesis::PromptVolume volume);" />
      <MemberSignature Language="F#" Value="member this.AppendText : string * System.Speech.Synthesis.PromptVolume -&gt; unit" Usage="promptBuilder.AppendText (textToSpeak, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="volume" Type="System.Speech.Synthesis.PromptVolume" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Stringa contenente il testo da usare come input vocale.</param>
        <param name="volume">Il valore per il volume della pronuncia da applicare al testo.</param>
        <summary>Aggiunge il testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il volume della pronuncia del testo.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il <xref:System.Speech.Synthesis.PromptVolume.Default> impostazione per <xref:System.Speech.Synthesis.PromptVolume> è il volume completo, ovvero lo stesso come <xref:System.Speech.Synthesis.PromptVolume.ExtraLoud>. Le altre impostazioni di diminuire il volume dell'output vocale rispetto all'intero volume.  
  
   
  
## Examples  
 L'esempio seguente usa il <xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A> metodo per specificare le impostazioni del volume che la <xref:System.Speech.Synthesis.SpeechSynthesizer> deve essere applicata all'output vocale.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Build a prompt that applies different volume settings.  
        PromptBuilder builder = new PromptBuilder();  
        builder.AppendText("This is the default speaking volume.", PromptVolume.Default);  
        builder.AppendBreak();  
        builder.AppendText("This is the extra loud speaking volume.", PromptVolume.ExtraLoud);  
        builder.AppendBreak();  
        builder.AppendText("This is the medium speaking volume.", PromptVolume.Medium);  
  
        // Speak the prompt.  
        synth.Speak(builder);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithAlias">
      <MemberSignature Language="C#" Value="public void AppendTextWithAlias (string textToSpeak, string substitute);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithAlias(string textToSpeak, string substitute) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithAlias(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithAlias (textToSpeak As String, substitute As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithAlias(System::String ^ textToSpeak, System::String ^ substitute);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithAlias : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithAlias (textToSpeak, substitute)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="substitute" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Stringa contenente la rappresentazione del testo.</param>
        <param name="substitute">Stringa contenente il testo da usare come input vocale.</param>
        <summary>Aggiunge il testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il testo alias da pronunciare al posto del testo aggiunto.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 In questo modo il documento contenga un parlato sia una forma scritta viene visualizzato un avviso. Ad esempio, la forma scritta potrebbe essere un acronimo, ad esempio SAPI, e la forma parlata potrebbe essere il testo espanso per l'acronimo, in questo Speech Application Programming Interface case.  
  
   
  
## Examples  
 Nell'esempio seguente aggiunge una stringa di testo ("vocale sintesi Markup Language") e il relativo alias "SSML (") a un <xref:System.Speech.Synthesis.PromptBuilder> oggetto. Sintetizzatore verrà pronunciare la "S S, M L".  
  
```  
PromptBuilder alias = new PromptBuilder();  
alias.AppendTextWithAlias("Speech Synthesis Markup Language","SSML");   
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="AppendTextWithHint">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Aggiunge il testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il tipo di contenuto del testo.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="AppendTextWithHint">
      <MemberSignature Language="C#" Value="public void AppendTextWithHint (string textToSpeak, System.Speech.Synthesis.SayAs sayAs);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithHint(string textToSpeak, valuetype System.Speech.Synthesis.SayAs sayAs) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint(System.String,System.Speech.Synthesis.SayAs)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithHint(System::String ^ textToSpeak, System::Speech::Synthesis::SayAs sayAs);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithHint : string * System.Speech.Synthesis.SayAs -&gt; unit" Usage="promptBuilder.AppendTextWithHint (textToSpeak, sayAs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="sayAs" Type="System.Speech.Synthesis.SayAs" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Stringa contenente il testo da usare come input vocale.</param>
        <param name="sayAs">Tipo di contenuto del testo.</param>
        <summary>Aggiunge il testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il tipo di contenuto con un membro dell'enumerazione <see cref="T:System.Speech.Synthesis.SayAs" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il tipo di contenuto specificato da `sayAs` possono fornire indicazioni per il motore di sintesi vocale di pronunciare il contenuto di `textToSpeak`.  
  
   
  
## Examples  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and define the data types for some of the added strings.  
        PromptBuilder sayAs = new PromptBuilder();  
        sayAs.AppendText("Your");  
        sayAs.AppendTextWithHint("1st", SayAs.NumberOrdinal);  
        sayAs.AppendText("request was for");  
        sayAs.AppendTextWithHint("1", SayAs.NumberCardinal);  
        sayAs.AppendText("room, on");  
        sayAs.AppendTextWithHint("10/19/2012,", SayAs.MonthDayYear);  
        sayAs.AppendText("with early arrival at");  
        sayAs.AppendTextWithHint("12:35pm", SayAs.Time12);  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(sayAs);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithHint">
      <MemberSignature Language="C#" Value="public void AppendTextWithHint (string textToSpeak, string sayAs);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithHint(string textToSpeak, string sayAs) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithHint (textToSpeak As String, sayAs As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithHint(System::String ^ textToSpeak, System::String ^ sayAs);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithHint : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithHint (textToSpeak, sayAs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="sayAs" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Stringa contenente il testo da usare come input vocale.</param>
        <param name="sayAs">Tipo di contenuto del testo.</param>
        <summary>Aggiunge il testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e un elemento <see cref="T:System.String" /> che specifica il tipo di contenuto del testo.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 È possibile usare questo metodo per specificare un tipo di contenuto che non è incluso nel <xref:System.Speech.Synthesis.SayAs> enumerazione. Tuttavia, il motore di sintesi vocale deve supportare il parametro specificato.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AppendTextWithPronunciation">
      <MemberSignature Language="C#" Value="public void AppendTextWithPronunciation (string textToSpeak, string pronunciation);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void AppendTextWithPronunciation(string textToSpeak, string pronunciation) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub AppendTextWithPronunciation (textToSpeak As String, pronunciation As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void AppendTextWithPronunciation(System::String ^ textToSpeak, System::String ^ pronunciation);" />
      <MemberSignature Language="F#" Value="member this.AppendTextWithPronunciation : string * string -&gt; unit" Usage="promptBuilder.AppendTextWithPronunciation (textToSpeak, pronunciation)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textToSpeak" Type="System.String" />
        <Parameter Name="pronunciation" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="textToSpeak">Stringa contenente la forma scritta della parola che usa l'alfabeto convenzionale per una lingua.</param>
        <param name="pronunciation">Stringa contenente i fonemi da pronunciare in base all'alfabeto fonetico internazionale (IPA).</param>
        <summary>Aggiunge il testo all'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica la pronuncia per il testo.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Sintetizzatore legge il contenuto del `pronunciation` parametro, non il contenuto del `textToSpeak` parametro.  
  
 Le pronunce specificati inline nelle istruzioni si applicano solo a singola occorrenza di una parola ed eseguire l'override la pronuncia del motore di riconoscimento vocale o uno qualsiasi dei relativi dizionari attualmente attivi. In genere, si userà la pronuncia inline per le pronunce personalizzate delle parole esistente o per la pronuncia delle parole non comuni, ad esempio nomi appropriati, quale il motore di sintesi vocale non può pronunciare così come previsto.  
  
 Le pronunce inline devono essere specificate tramite i telefoni dall'alfabeto fonetico internazionale (IPA). Un telefono è una lettera o un carattere che rappresenta un suono discreto di riconoscimento vocale. Motori di sintesi vocale conformi con la [linguaggio Markup sintesi della voce (SSML) versione 1.0](https://go.microsoft.com/fwlink/?LinkId=201763) specifica verrà pronunciare telefoni dal pacchetto IPA. Per specificare le pronunce inline usando altri alfabeti fonetici, vedere <xref:System.Speech.Synthesis.PromptBuilder.AppendSsmlMarkup%2A>.  
  
 Il file IPA pubblica un [grafico](https://go.microsoft.com/fwlink/?LinkId=58362) che elenca le telefoni e vengono mappati ai numeri di Unicode.  
  
 Alcuni telefoni nell'alfabeto IPA hanno le stesse rappresentazioni come lettere dell'alfabeto latino. In questi casi, è possibile digitare i caratteri latini e avere la rappresentazione corretta per un telefono. Poiché i caratteri latini viene comunemente utilizzati nel testo possono rappresentare i telefoni diverse del set telefonico IPA, è sufficiente digitare i caratteri latini non potrebbe telefono IPA preciso desiderato. Altri telefoni della necessità alfabeto IPA deve essere rappresentato nel codice come carattere riferimenti costituito da una e commerciale (&), il simbolo di cancelletto (#), e un numero di Unicode per il telefono desiderato in formato esadecimale o decimale, tutti seguiti da un punto e virgola (;). Ad esempio, un schwa (&\#x0259;) potrebbe essere rappresentato da `&#x0259;`.  
  
 Per aggiungere la pronuncia di nuova o personalizzata per più parole, ad esempio per i sottolinguaggi express a livello di area o per aggiungere nomi appropriati o un vocabolario specifico per una disciplina didattico o mediche, compilare un lessico e aggiungerlo al <xref:System.Speech.Synthesis.SpeechSynthesizer> usando <xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A>.  
  
   
  
## Examples  
 L'esempio seguente Inizializza una nuova istanza di <xref:System.Speech.Synthesis.PromptBuilder> classe. Viene quindi aggiunto la stringa di testo "il mio nome è" all'istanza. Infine, aggiunge una stringa contenente il nome appropriato "DuBois" e specifica la pronuncia del nome.  
  
```csharp  
public void ProperName()  
{  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("My name is");  
  
    // Add a proper name and its pronunciation.  
    builder.AppendTextWithPronunciation("DuBois", "duˈbwɑ");     
}  
```  
  
 Il markup seguente illustra l'elemento SSML da questo <xref:System.Speech.Synthesis.PromptBuilder> genera l'oggetto.  
  
```xml  
<speak xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-us">  
  My name is <phoneme ph="duˈbwɑ"> DuBois </phoneme>  
</speak>  
```  
  
 ]]></format>
        </remarks>
        <related type="ExternalDocumentation" href="https://go.microsoft.com/fwlink/?LinkId=58363">Associazione fonetico internazionale</related>
      </Docs>
    </Member>
    <Member MemberName="ClearContent">
      <MemberSignature Language="C#" Value="public void ClearContent ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void ClearContent() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.ClearContent" />
      <MemberSignature Language="VB.NET" Value="Public Sub ClearContent ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void ClearContent();" />
      <MemberSignature Language="F#" Value="member this.ClearContent : unit -&gt; unit" Usage="promptBuilder.ClearContent " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Cancella il contenuto dell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Culture">
      <MemberSignature Language="C#" Value="public System.Globalization.CultureInfo Culture { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Globalization.CultureInfo Culture" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.PromptBuilder.Culture" />
      <MemberSignature Language="VB.NET" Value="Public Property Culture As CultureInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Globalization::CultureInfo ^ Culture { System::Globalization::CultureInfo ^ get(); void set(System::Globalization::CultureInfo ^ value); };" />
      <MemberSignature Language="F#" Value="member this.Culture : System.Globalization.CultureInfo with get, set" Usage="System.Speech.Synthesis.PromptBuilder.Culture" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Globalization.CultureInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ottiene o imposta le informazioni sulle impostazioni cultura per l'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <value>To be added.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il <xref:System.Speech.Synthesis.SpeechSynthesizer> oggetto tenterà di selezionare una voce installata che supporta la lingua specificata dal <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà per elaborare la richiesta. Se viene trovata una voce con le impostazioni cultura specificate, verrà utilizzato. Se non viene trovata una voce con le impostazioni cultura specificate, verrà utilizzata la voce predefinita.  
  
 È anche possibile specificare le impostazioni cultura entro il prompt dei comandi per le sezioni distinte del contenuto usando il <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A>, <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>, e <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A> metodi. Le impostazioni cultura specificata per una parte del contenuto usando uno dei metodi sopra indicati eseguiranno l'override la <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà mentre in realtà e il <xref:System.Speech.Synthesis.SpeechSynthesizer> tenterà di selezionare una voce installata che supporta la lingua specificata dal `culture` parametro del metodo.  
  
 Per pronunciare correttamente le parole nel linguaggio specificato per il <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà, un motore di sintesi (sintesi vocale o TTS) vocale che supporta il linguaggio deve essere installato. Un motore di sintesi vocale installato viene chiamato una voce. Per ottenere informazioni sulle voci vengono installate per impostazioni cultura specifiche, usare il <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> (metodo).  
  
 Microsoft Windows e l'API System. Speech accettano tutti i codici dei paesi di lingua validi come valori per `culture`. I motori di sintesi vocale fornita con Windows 7 supportano i seguenti codici di lingua paese:  
  
-   en-US. Inglese (Stati Uniti)  
  
-   zh-CN. Cinese (Cina)  
  
-   zh-TW. Cinese (Taiwan)  
  
 Sono inoltre consentiti i codici di lingua di due lettere, ad esempio "en".  Visualizzare [costanti di identificatore di lingua e le stringhe](https://msdn.microsoft.com/library/dd318693\(VS.85\).aspx) per un elenco completo dei codici lingua.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndParagraph">
      <MemberSignature Language="C#" Value="public void EndParagraph ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndParagraph() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndParagraph" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndParagraph ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndParagraph();" />
      <MemberSignature Language="F#" Value="member this.EndParagraph : unit -&gt; unit" Usage="promptBuilder.EndParagraph " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Specifica la fine di un paragrafo nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Richieste di lunghe possono eseguire il rendering più come risorse umane vocale tali App vengono interrotte in frasi e paragrafi. Per un esempio, vedere <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndSentence">
      <MemberSignature Language="C#" Value="public void EndSentence ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndSentence() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndSentence" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndSentence ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndSentence();" />
      <MemberSignature Language="F#" Value="member this.EndSentence : unit -&gt; unit" Usage="promptBuilder.EndSentence " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Specifica la fine di un periodo nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Richieste di lunghe possono eseguire il rendering più come risorse umane vocale tali App vengono interrotte in frasi e paragrafi. Per un esempio, vedere <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndStyle">
      <MemberSignature Language="C#" Value="public void EndStyle ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndStyle() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndStyle" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndStyle ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndStyle();" />
      <MemberSignature Language="F#" Value="member this.EndStyle : unit -&gt; unit" Usage="promptBuilder.EndStyle " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Specifica la fine di uno stile nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> metodo arresta il modo di parlare corrente. Il modo di parlare viene ripristinata l'impostazione che è stato in vigore prima il <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> metodo avviato un nuovo modo di parlare. Per un esempio, vedere <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="EndVoice">
      <MemberSignature Language="C#" Value="public void EndVoice ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EndVoice() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.EndVoice" />
      <MemberSignature Language="VB.NET" Value="Public Sub EndVoice ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EndVoice();" />
      <MemberSignature Language="F#" Value="member this.EndVoice : unit -&gt; unit" Usage="promptBuilder.EndVoice " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Specifica la fine dell'uso di una voce nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A> metodo interrompe l'uso della voce corrente per l'output vocale. La voce viene ripristinata l'impostazione che era attivo prima di <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> metodo avviata una nuova voce.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="IsEmpty">
      <MemberSignature Language="C#" Value="public bool IsEmpty { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool IsEmpty" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Synthesis.PromptBuilder.IsEmpty" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property IsEmpty As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool IsEmpty { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.IsEmpty : bool" Usage="System.Speech.Synthesis.PromptBuilder.IsEmpty" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ottiene un valore che indica se l'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> è vuoto.</summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartParagraph">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Specifica l'inizio di un paragrafo nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e facoltativamente specifica una lingua.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Richieste di lunghe possono eseguire il rendering più come risorse umane vocale tali App vengono interrotte in frasi e paragrafi.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartParagraph">
      <MemberSignature Language="C#" Value="public void StartParagraph ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartParagraph() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartParagraph" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartParagraph ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartParagraph();" />
      <MemberSignature Language="F#" Value="member this.StartParagraph : unit -&gt; unit" Usage="promptBuilder.StartParagraph " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Specifica l'inizio di un paragrafo nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Richieste di lunghe possono eseguire il rendering più come risorse umane vocale tali App vengono interrotte in frasi e paragrafi.  
  
   
  
## Examples  
 L'esempio seguente crea un <xref:System.Speech.Synthesis.PromptBuilder> aggiunge contenuto oggetto e consente di organizzare il contenuto in paragrafi e le frasi.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content as paragraphs and sentences.  
        PromptBuilder parSent = new PromptBuilder();  
        parSent.StartParagraph();  
        parSent.StartSentence();  
        parSent.AppendText("Introducing the sentence element.");  
        parSent.EndSentence();  
        parSent.StartSentence();  
        parSent.AppendText("You can use it to mark individual sentences.");  
        parSent.EndSentence();  
        parSent.EndParagraph();  
        parSent.StartParagraph();  
        parSent.AppendText("Another simple paragraph. Sentence structure in this paragraph" +  
          "is not explicitly marked.");  
        parSent.EndParagraph();  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(parSent);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartParagraph">
      <MemberSignature Language="C#" Value="public void StartParagraph (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartParagraph(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartParagraph(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartParagraph (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartParagraph(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartParagraph : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartParagraph culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Fornisce informazioni su impostazioni cultura specifiche, ad esempio lingua, nome delle impostazioni cultura, sistema di scrittura, calendario usato e modalità di formattazione delle date e ordinamento delle stringhe.</param>
        <summary>Specifica l'inizio di un paragrafo nelle impostazioni cultura specificate nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Richieste di lunghe possono eseguire il rendering più come risorse umane vocale tali App vengono interrotte in frasi e paragrafi.  
  
 Il `culture` parametro per un paragrafo può essere diverso da quello di <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà del <xref:System.Speech.Synthesis.PromptBuilder> oggetto che lo contiene. In effetti, mentre il valore della `culture` parametro ignora il <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà. Il <xref:System.Speech.Synthesis.SpeechSynthesizer> tenterà di selezionare una voce installata che supporta la lingua specificata dal `culture` parametro parlare del paragrafo. Se viene trovata una voce con le impostazioni cultura specificate, verrà utilizzato. Se non viene trovata una voce con le impostazioni cultura specificate, verrà utilizzata la voce predefinita. Interrompere l'uso della voce specificata da <xref:System.Speech.Synthesis.PromptBuilder.StartParagraph%2A>, chiamare <xref:System.Speech.Synthesis.PromptBuilder.EndParagraph%2A>.  
  
 Per pronunciare correttamente le parole nel linguaggio specificato per il `culture` parametro, un motore di sintesi (sintesi vocale o TTS) vocale che supporta il linguaggio deve essere installato. Un motore di sintesi vocale installato viene chiamato una voce. Per ottenere informazioni sulle voci vengono installate per impostazioni cultura specifiche, usare il <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> (metodo).  
  
 Microsoft Windows e l'API System. Speech accettano tutti i codici dei paesi di lingua validi come valori per `culture`. I motori di sintesi vocale fornita con Windows 7 supportano i seguenti codici di lingua paese:  
  
-   en-US. Inglese (Stati Uniti)  
  
-   zh-CN. Cinese (Cina)  
  
-   zh-TW. Cinese (Taiwan)  
  
 Sono inoltre consentiti i codici di lingua di due lettere, ad esempio "en".  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartSentence">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Specifica l'inizio di una frase nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e facoltativamente specifica una lingua.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Richieste di lunghe possono eseguire il rendering più come risorse umane vocale tali App vengono interrotte in frasi e paragrafi.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartSentence">
      <MemberSignature Language="C#" Value="public void StartSentence ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartSentence() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartSentence" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartSentence ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartSentence();" />
      <MemberSignature Language="F#" Value="member this.StartSentence : unit -&gt; unit" Usage="promptBuilder.StartSentence " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Specifica l'inizio di una frase nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Richieste di lunghe possono eseguire il rendering più come risorse umane vocale tali App vengono interrotte in frasi e paragrafi.  
  
   
  
## Examples  
 L'esempio seguente crea un <xref:System.Speech.Synthesis.PromptBuilder> aggiunge contenuto oggetto e consente di organizzare il contenuto in paragrafi e le frasi.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content as paragraphs and sentences.  
        PromptBuilder parSent = new PromptBuilder();  
        parSent.StartParagraph();  
        parSent.StartSentence();  
        parSent.AppendText("Introducing the sentence element.");  
        parSent.EndSentence();  
        parSent.StartSentence();  
        parSent.AppendText("You can use it to mark individual sentences.");  
        parSent.EndSentence();  
        parSent.EndParagraph();  
        parSent.StartParagraph();  
        parSent.AppendText("Another simple paragraph. Sentence structure in this paragraph" +  
          "is not explicitly marked.");  
        parSent.EndParagraph();  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(parSent);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartSentence">
      <MemberSignature Language="C#" Value="public void StartSentence (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartSentence(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartSentence(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartSentence (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartSentence(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartSentence : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartSentence culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Fornisce informazioni su impostazioni cultura specifiche, ad esempio lingua, nome delle impostazioni cultura, sistema di scrittura, calendario usato e modalità di formattazione delle date e ordinamento delle stringhe.</param>
        <summary>Specifica l'inizio di una frase nelle impostazioni cultura specificate nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Richieste di lunghe possono eseguire il rendering più come risorse umane vocale tali App vengono interrotte in frasi e paragrafi.  
  
 Il `culture` parametro per una frase può essere diverso da quello di `culture` parametro per il paragrafo contenente la frase o il <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà del <xref:System.Speech.Synthesis.PromptBuilder> oggetti che li contiene.  
  
 In effetti, mentre il valore dei `culture` parametro eseguirà l'override di <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà e il `culture` parametro per il paragrafo contenente la frase. Il <xref:System.Speech.Synthesis.SpeechSynthesizer> tenterà di selezionare una voce installata che supporta la lingua specificata dal `culture` parametro da pronunciare la frase. Se viene trovata una voce con le impostazioni cultura specificate, verrà utilizzato. Se non viene trovata una voce con le impostazioni cultura specificate, verrà utilizzata la voce predefinita. Interrompere l'uso della voce specificata da <xref:System.Speech.Synthesis.PromptBuilder.StartSentence%2A>, chiamare <xref:System.Speech.Synthesis.PromptBuilder.EndSentence%2A>.  
  
 Per pronunciare correttamente le parole nel linguaggio specificato per il `culture` parametro, un motore di sintesi (sintesi vocale o TTS) vocale che supporta il linguaggio deve essere installato. Un motore di sintesi vocale installato viene chiamato una voce. Per ottenere informazioni sulle voci vengono installate per impostazioni cultura specifiche, usare il <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> (metodo).  
  
 Microsoft Windows e l'API System. Speech accettano tutti i codici dei paesi di lingua validi come valori per `culture`. I motori di sintesi vocale fornita con Windows 7 supportano i seguenti codici di lingua paese:  
  
-   en-US. Inglese (Stati Uniti)  
  
-   zh-CN. Cinese (Cina)  
  
-   zh-TW. Cinese (Taiwan)  
  
 Sono inoltre consentiti i codici di lingua di due lettere, ad esempio "en".  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartStyle">
      <MemberSignature Language="C#" Value="public void StartStyle (System.Speech.Synthesis.PromptStyle style);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartStyle(class System.Speech.Synthesis.PromptStyle style) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartStyle(System.Speech.Synthesis.PromptStyle)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartStyle (style As PromptStyle)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartStyle(System::Speech::Synthesis::PromptStyle ^ style);" />
      <MemberSignature Language="F#" Value="member this.StartStyle : System.Speech.Synthesis.PromptStyle -&gt; unit" Usage="promptBuilder.StartStyle style" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="style" Type="System.Speech.Synthesis.PromptStyle" />
      </Parameters>
      <Docs>
        <param name="style">Stile da avviare.</param>
        <summary>Specifica l'inizio di uno stile nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> metodo accetta un <xref:System.Speech.Synthesis.PromptStyle> oggetto come relativo argomento. È possibile usare le proprietà del <xref:System.Speech.Synthesis.PromptStyle> oggetto per impostare l'enfasi, velocità di pronuncia e volume (sonorità) da applicare al riconoscimento vocale mentre è in corso lo stile di output. Per arrestare usando lo stile corrente, chiamare il <xref:System.Speech.Synthesis.PromptBuilder.EndStyle%2A> (metodo).  
  
> [!NOTE]
>  -   I motori di sintesi vocale in Windows non supportano il parametro di enfasi in questo momento. Impostazione dei valori per il parametro di enfasi non produrrà alcuna modifica acustico nell'output di sintesi vocale.  
> -   Il <xref:System.Speech.Synthesis.PromptVolume.Default> impostazione per <xref:System.Speech.Synthesis.PromptVolume> è il volume completo, ovvero lo stesso come <xref:System.Speech.Synthesis.PromptVolume.ExtraLoud>. Le altre impostazioni di diminuire il volume dell'output vocale rispetto all'intero volume.  
  
   
  
## Examples  
 L'esempio seguente crea un <xref:System.Speech.Synthesis.PromptBuilder> dell'oggetto e aggiunge le stringhe di testo. Nell'esempio viene usato il <xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A> metodo per specificare un modo di parlare lenta frequenza per la stringa da aggiungere, che enumera il contenuto di un ordine.  
  
```csharp  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder style = new PromptBuilder();  
        style.AppendText("Your order for");  
        style.StartStyle(new PromptStyle(PromptRate.Slow));  
        style.AppendText("one kitchen sink and one faucet");  
        style.EndStyle();  
        style.AppendText("has been confirmed.");  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(style);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="StartVoice">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Indica al sintetizzatore di modificare la voce in un oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Una voce rappresenta un motore di sintesi vocale installato. Usare la <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metodi e <xref:System.Speech.Synthesis.VoiceInfo> installato di classe per ottenere i nomi e gli attributi di voci di sintesi vocale (TTS) che è possibile selezionare.  
  
 Quando un'applicazione chiama <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A>, il metodo verifica che ognuna delle voci trova nel Registro di sistema soddisfa determinati criteri minimi. Per qualsiasi voce che si verifica un errore di verifica <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> imposta relativi <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> proprietà `False`. Un'applicazione non è possibile chiamare tutte le <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> metodi su una voce cui <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> è di proprietà `False`. In genere, le applicazioni non verranno impostata una voce <xref:System.Speech.Synthesis.InstalledVoice.Enabled%2A> proprietà.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Globalization.CultureInfo -&gt; unit" Usage="promptBuilder.StartVoice culture" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture">Fornisce informazioni su impostazioni cultura specifiche, ad esempio lingua, nome delle impostazioni cultura, sistema di scrittura, calendario usato e modalità di formattazione delle date e ordinamento delle stringhe.</param>
        <summary>Indica al sintetizzatore di modificare la voce nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica le impostazioni cultura della nuova voce da usare.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il `culture` parametro per <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> può essere diverso da quello di <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà del <xref:System.Speech.Synthesis.PromptBuilder> oggetto che lo contiene.  In effetti, mentre il valore della `culture` parametro ignora il <xref:System.Speech.Synthesis.PromptBuilder.Culture%2A> proprietà. Il <xref:System.Speech.Synthesis.SpeechSynthesizer> tenterà di selezionare una voce installata che supporta la lingua specificata dal `culture` parametro per pronunciare il contenuto racchiuso <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> e <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>. Se viene trovata una voce con le impostazioni cultura specificate, verrà utilizzato. Se non viene trovata una voce con le impostazioni cultura specificate, verrà utilizzata la voce predefinita. Interrompere l'uso della voce specificata da <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A>, chiamare <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 Per pronunciare correttamente le parole nel linguaggio specificato per il `culture` parametro, un motore di sintesi (sintesi vocale o TTS) vocale che supporta il linguaggio deve essere installato. Un motore di sintesi vocale installato viene chiamato una voce. Per ottenere informazioni sulle voci vengono installate per impostazioni cultura specifiche, usare il <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> (metodo).  
  
 Microsoft Windows e l'API System. Speech accettano tutti i codici dei paesi di lingua validi come valori per `culture`. I motori di sintesi vocale fornita con Windows 7 supportano i seguenti codici di lingua paese:  
  
-   en-US. Inglese (Stati Uniti)  
  
-   zh-CN. Cinese (Cina)  
  
-   zh-TW. Cinese (Taiwan)  
  
 Sono inoltre consentiti i codici di lingua di due lettere, ad esempio "en".  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender -&gt; unit" Usage="promptBuilder.StartVoice gender" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
      </Parameters>
      <Docs>
        <param name="gender">Il genere della voce da usare.</param>
        <summary>Indica al sintetizzatore di modificare la voce nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il genere della voce da usare.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Usare la <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metodi e <xref:System.Speech.Synthesis.VoiceInfo> installato di classe per ottenere i nomi e gli attributi di voci di sintesi vocale (TTS) che è possibile selezionare.  
  
 Interrompere l'uso della voce specificata da <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> chiamare <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceInfo voice);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(class System.Speech.Synthesis.VoiceInfo voice) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (voice As VoiceInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceInfo ^ voice);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceInfo -&gt; unit" Usage="promptBuilder.StartVoice voice" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="voice" Type="System.Speech.Synthesis.VoiceInfo" />
      </Parameters>
      <Docs>
        <param name="voice">I criteri per la voce da usare.</param>
        <summary>Indica al sintetizzatore di modificare la voce nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica i criteri per la nuova voce.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Usare la <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metodi e <xref:System.Speech.Synthesis.VoiceInfo> installato di classe per ottenere i nomi e gli attributi di voci di sintesi vocale (TTS) che è possibile selezionare.  
  
 Interrompere l'uso della voce specificata da <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> chiamare <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (string name);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (name As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::String ^ name);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : string -&gt; unit" Usage="promptBuilder.StartVoice name" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name">Nome della voce da usare.</param>
        <summary>Indica al sintetizzatore di modificare la voce nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il nome della voce da usare.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Per ottenere informazioni su quali sono installate voci, usare uno del <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metodi.  
  
 Interrompere l'uso della voce specificata da <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> chiamare <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender, age As VoiceAge)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge -&gt; unit" Usage="promptBuilder.StartVoice (gender, age)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
      </Parameters>
      <Docs>
        <param name="gender">Il genere della nuova voce da usare.</param>
        <param name="age">L'età della voce da usare.</param>
        <summary>Indica al sintetizzatore di modificare la voce nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il genere e l'età della nuova voce.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Usare la <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metodi e <xref:System.Speech.Synthesis.VoiceInfo> installato di classe per ottenere i nomi e gli attributi di voci di sintesi vocale (TTS) che è possibile selezionare.  
  
 Interrompere l'uso della voce specificata da <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> chiamare <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="StartVoice">
      <MemberSignature Language="C#" Value="public void StartVoice (System.Speech.Synthesis.VoiceGender gender, System.Speech.Synthesis.VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void StartVoice(valuetype System.Speech.Synthesis.VoiceGender gender, valuetype System.Speech.Synthesis.VoiceAge age, int32 voiceAlternate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Sub StartVoice (gender As VoiceGender, age As VoiceAge, voiceAlternate As Integer)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void StartVoice(System::Speech::Synthesis::VoiceGender gender, System::Speech::Synthesis::VoiceAge age, int voiceAlternate);" />
      <MemberSignature Language="F#" Value="member this.StartVoice : System.Speech.Synthesis.VoiceGender * System.Speech.Synthesis.VoiceAge * int -&gt; unit" Usage="promptBuilder.StartVoice (gender, age, voiceAlternate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="gender" Type="System.Speech.Synthesis.VoiceGender" />
        <Parameter Name="age" Type="System.Speech.Synthesis.VoiceAge" />
        <Parameter Name="voiceAlternate" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="gender">Il genere della voce da usare.</param>
        <param name="age">L'età della voce da usare.</param>
        <param name="voiceAlternate">Numero intero che specifica una voce preferita quando più voci corrispondono ai parametri <paramref name="gender" /> e <paramref name="age" />.</param>
        <summary>Indica al sintetizzatore di modificare la voce nell'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> e specifica il genere, l'età e una voce preferita che corrisponde al genere e all'età specificati.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Motore di sintesi vocale conta le corrispondenze che trova per i parametri specificati e restituisce la vocale quando il conteggio è uguale al `voiceAlternate` parametro.  
  
 Usare la <xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A> metodi e <xref:System.Speech.Synthesis.VoiceInfo> installato di classe per ottenere i nomi e gli attributi di voci di sintesi vocale (TTS) che è possibile selezionare.  
  
 Interrompere l'uso della voce specificata da <xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A> chiamare <xref:System.Speech.Synthesis.PromptBuilder.EndVoice%2A>.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Synthesis.PromptBuilder.StartVoice(System.Speech.Synthesis.VoiceGender,System.Speech.Synthesis.VoiceAge)" />
      </Docs>
    </Member>
    <Member MemberName="ToXml">
      <MemberSignature Language="C#" Value="public string ToXml ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance string ToXml() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Synthesis.PromptBuilder.ToXml" />
      <MemberSignature Language="VB.NET" Value="Public Function ToXml () As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::String ^ ToXml();" />
      <MemberSignature Language="F#" Value="member this.ToXml : unit -&gt; string" Usage="promptBuilder.ToXml " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Restituisce l'elemento SSML generato dall'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" />.</summary>
        <returns>Restituisce l'elemento SSML generato dall'oggetto <see cref="T:System.Speech.Synthesis.PromptBuilder" /> come singola riga.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Il <xref:System.Speech.Synthesis.PromptBuilder.ToXml%2A> metodo non effettua alcun tentativo di formattare l'elemento SSML restituita in alcun modo.  
  
   
  
## Examples  
 L'esempio seguente crea un <xref:System.Speech.Synthesis.PromptBuilder> oggetto, aggiunge il testo e quindi scrive l'equivalente SSML del messaggio di richiesta alla console prima di parlare il contenuto del messaggio di richiesta.  
  
```csharp  
  
using System;  
using System.Speech.Synthesis;  
  
namespace SampleSynthesis  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize a new instance of the SpeechSynthesizer.  
      using (SpeechSynthesizer synth = new SpeechSynthesizer())  
      {  
  
        // Configure the audio output.   
        synth.SetOutputToDefaultAudioDevice();  
  
        // Create a PromptBuilder object and add content.  
        PromptBuilder style = new PromptBuilder();  
        style.AppendText("Your order for");  
        style.StartStyle(new PromptStyle(PromptRate.Slow));  
        style.AppendText("one kitchen sink and one faucet");  
        style.EndStyle();  
        style.AppendText("has been confirmed.");  
  
        // Write the contents of the PromptBuilder object to the console as  
        // an SSML-compatible XML file.  
        string myXml = style.ToXml();  
        Console.WriteLine("This is the SSML equivalent of the PromptBuilder: \n\n" + myXml);  
  
        // Speak the contents of the SSML prompt.  
        synth.Speak(style);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>